<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>LeNet-2</title>
      <link href="/2022/12/10/Pytorch_Demo/"/>
      <url>/2022/12/10/Pytorch_Demo/</url>
      
        <content type="html"><![CDATA[<h1 id="Pytorch官网入门Demo——实现一个图像分类器"><a href="#Pytorch官网入门Demo——实现一个图像分类器" class="headerlink" title="Pytorch官网入门Demo——实现一个图像分类器"></a>Pytorch官网入门Demo——实现一个图像分类器</h1><p>参考：</p><ol><li><a href="https://www.bilibili.com/video/BV187411T7Ye">哔哩哔哩：pytorch官方demo(Lenet)</a></li><li><a href="https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html#">pytorch官网demo</a>（<a href="https://pytorch.apachecn.org/docs/1.4/blitz/cifar10_tutorial.html">中文版戳这里</a>）</li><li><a href="https://blog.csdn.net/qq_37541097/article/details/102926037">pytorch中的卷积操作详解</a></li><li><a href="https://blog.csdn.net/m0_37867091/article/details/107136477">Fan的CSDN笔记</a></li></ol><h2 id="代码部分"><a href="#代码部分" class="headerlink" title="代码部分"></a>代码部分</h2><p>Model 模型构建</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">LeNet</span>(nn.Module):                     <span class="comment"># 继承于nn.Module这个父类</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):                     <span class="comment"># 初始化网络结构</span></span><br><span class="line">        <span class="built_in">super</span>(LeNet, self).__init__()       <span class="comment"># 多继承需用到super函数</span></span><br><span class="line">        self.conv1 = nn.Conv2d(<span class="number">3</span>, <span class="number">16</span>, <span class="number">5</span>)    <span class="comment">#构建卷积层1，深度3，卷积核个数为16，核大小为5*5 输出深度为卷积核个数</span></span><br><span class="line">        self.pool1 = nn.MaxPool2d(<span class="number">2</span>, <span class="number">2</span>)     <span class="comment">#构建池化层（下采样层）1，核大小为2*2，步长为2</span></span><br><span class="line">        self.conv2 = nn.Conv2d(<span class="number">16</span>, <span class="number">32</span>, <span class="number">5</span>)   <span class="comment">#构建卷积层2，深度16，卷积核个数为32，核大小为5*5</span></span><br><span class="line">        self.pool2 = nn.MaxPool2d(<span class="number">2</span>, <span class="number">2</span>)     <span class="comment">#构建池化层（下采样层）2，核大小为2*2，步长为2</span></span><br><span class="line">        self.fc1 = nn.Linear(<span class="number">32</span>*<span class="number">5</span>*<span class="number">5</span>, <span class="number">120</span>)   <span class="comment">#构建池全连接层1，输入为32*5*5，输出为120</span></span><br><span class="line">        self.fc2 = nn.Linear(<span class="number">120</span>, <span class="number">84</span>)       <span class="comment">#构建池全连接层2，输入为120，输出为84</span></span><br><span class="line">        self.fc3 = nn.Linear(<span class="number">84</span>, <span class="number">10</span>)        <span class="comment">#构建全连接层3，输入为84，输出为10</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):            <span class="comment"># 正向传播过程</span></span><br><span class="line">        x = F.relu(self.conv1(x))    <span class="comment"># input(3, 32, 32) output(16, 28, 28)</span></span><br><span class="line">        x = self.pool1(x)            <span class="comment"># output(16, 14, 14)</span></span><br><span class="line">        x = F.relu(self.conv2(x))    <span class="comment"># output(32, 10, 10)</span></span><br><span class="line">        x = self.pool2(x)            <span class="comment"># output(32, 5, 5)</span></span><br><span class="line">        x = x.view(-<span class="number">1</span>, <span class="number">32</span>*<span class="number">5</span>*<span class="number">5</span>)       <span class="comment"># output(32*5*5) 展开为一维数据</span></span><br><span class="line">        x = F.relu(self.fc1(x))      <span class="comment"># output(120)</span></span><br><span class="line">        x = F.relu(self.fc2(x))      <span class="comment"># output(84)</span></span><br><span class="line">        x = self.fc3(x)              <span class="comment"># output(10)</span></span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"><span class="comment"># import torch</span></span><br><span class="line"><span class="comment"># input1 = torch.rand([32,3,32,32])</span></span><br><span class="line"><span class="comment"># model = LeNet()</span></span><br><span class="line"><span class="comment"># print(model) #输出LeNet神经网络架构</span></span><br><span class="line"><span class="comment"># output = model(input1)</span></span><br></pre></td></tr></table></figure><p>Train训练（下载cifar-10官方训练集和测试集）</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">from</span> model <span class="keyword">import</span> LeNet</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="keyword">import</span> torchvision.transforms <span class="keyword">as</span> transforms</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    transform = transforms.Compose(</span><br><span class="line">        [transforms.ToTensor(),</span><br><span class="line">         transforms.Normalize((<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>), (<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>))])</span><br><span class="line"><span class="comment"># ToTensor将文件高*宽*深度转换诶 深度*高*宽 Normalize标准化 使用均值和标准差 标准化图像</span></span><br><span class="line">    <span class="comment"># 50000张训练图片</span></span><br><span class="line">    <span class="comment"># 第一次使用时要将download设置为True才会自动去下载数据集</span></span><br><span class="line">    train_set = torchvision.datasets.CIFAR10(root=<span class="string">&#x27;./data&#x27;</span>, train=<span class="literal">True</span>,</span><br><span class="line">                                             download=<span class="literal">False</span>, transform=transform) <span class="comment">#此行download改为True为下载数据集合，transform为预处理</span></span><br><span class="line"><span class="comment">#torchvision.datasets. 可以用于查看pytorch官方数据集</span></span><br><span class="line">    train_loader = torch.utils.data.DataLoader(train_set, batch_size=<span class="number">36</span>,</span><br><span class="line">                                               shuffle=<span class="literal">True</span>, num_workers=<span class="number">0</span>)<span class="comment">#shuffle为是否打乱数据集</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 10000张验证图片</span></span><br><span class="line">    <span class="comment"># 第一次使用时要将download设置为True才会自动去下载数据集</span></span><br><span class="line">    val_set = torchvision.datasets.CIFAR10(root=<span class="string">&#x27;./data&#x27;</span>, train=<span class="literal">False</span>,</span><br><span class="line">                                           download=<span class="literal">True</span>, transform=transform)</span><br><span class="line">    val_loader = torch.utils.data.DataLoader(val_set, batch_size=<span class="number">5000</span>,</span><br><span class="line">                                             shuffle=<span class="literal">False</span>, num_workers=<span class="number">0</span>)<span class="comment">#预览时可以把batchsize调低用于查看</span></span><br><span class="line">    val_data_iter = <span class="built_in">iter</span>(val_loader)<span class="comment">#转换为可迭代的迭代器</span></span><br><span class="line">    val_image, val_label = <span class="built_in">next</span>(val_data_iter)<span class="comment">#获取一批图像并赋值</span></span><br><span class="line"></span><br><span class="line">    classes = (<span class="string">&#x27;plane&#x27;</span>, <span class="string">&#x27;car&#x27;</span>, <span class="string">&#x27;bird&#x27;</span>, <span class="string">&#x27;cat&#x27;</span>,</span><br><span class="line">               <span class="string">&#x27;deer&#x27;</span>, <span class="string">&#x27;dog&#x27;</span>, <span class="string">&#x27;frog&#x27;</span>, <span class="string">&#x27;horse&#x27;</span>, <span class="string">&#x27;ship&#x27;</span>, <span class="string">&#x27;truck&#x27;</span>)<span class="comment">#导入标签</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># # 输出图像的函数</span></span><br><span class="line">    <span class="comment"># def imshow(img):</span></span><br><span class="line">    <span class="comment">#     img = img / 2 + 0.5  # unnormalize反标准化</span></span><br><span class="line">    <span class="comment">#     npimg = img.numpy() #转化为numpy格式</span></span><br><span class="line">    <span class="comment">#     plt.imshow(np.transpose(npimg, (1, 2, 0)))</span></span><br><span class="line">    <span class="comment">#     # 反标准化为原始格式高，款，深度</span></span><br><span class="line">    <span class="comment">#     plt.show()</span></span><br><span class="line">    <span class="comment"># # 打印图片标签</span></span><br><span class="line">    <span class="comment"># print(&#x27; &#x27;.join(&#x27;%5s&#x27; % classes[val_label[j]] for j in range(4)))</span></span><br><span class="line">    <span class="comment"># # 显示图片</span></span><br><span class="line">    <span class="comment"># imshow(torchvision.utils.make_grid(val_image))</span></span><br><span class="line"></span><br><span class="line">    net = LeNet()</span><br><span class="line">    loss_function = nn.CrossEntropyLoss()<span class="comment">#定义损失函数  包含softmax函数</span></span><br><span class="line">    optimizer = optim.Adam(net.parameters(), lr=<span class="number">0.001</span>)<span class="comment">#Adam优化器；net.parameters()将网络中所有可训练参数进行训练；lr(learning rate)学习率</span></span><br><span class="line">    <span class="comment">#以下为训练过程</span></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>):  <span class="comment"># loop over the dataset multiple times；epoch训练集迭代次数</span></span><br><span class="line"></span><br><span class="line">        running_loss = <span class="number">0.0</span><span class="comment">#累加损失</span></span><br><span class="line">        <span class="comment">#以下迭代损失</span></span><br><span class="line">        <span class="keyword">for</span> step, data <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_loader, start=<span class="number">0</span>):</span><br><span class="line">            <span class="comment"># get the inputs; data is a list of [inputs, labels] 获取输入 enumerate返回data和data的步数</span></span><br><span class="line">            inputs, labels = data</span><br><span class="line"></span><br><span class="line">            <span class="comment"># zero the parameter gradients 历史损失梯度清零</span></span><br><span class="line">            optimizer.zero_grad()</span><br><span class="line">            <span class="comment"># forward + backward + optimize</span></span><br><span class="line">            outputs = net(inputs)</span><br><span class="line">            loss = loss_function(outputs, labels)<span class="comment">#损失计算</span></span><br><span class="line">            loss.backward()<span class="comment">#反向传播</span></span><br><span class="line">            optimizer.step()<span class="comment">#利用优化器进行参数更新</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># print statistics</span></span><br><span class="line">            running_loss += loss.item()</span><br><span class="line">            <span class="keyword">if</span> step % <span class="number">500</span> == <span class="number">499</span>:    <span class="comment"># print every 500 mini-batches 每隔500步打印一次</span></span><br><span class="line">                <span class="keyword">with</span> torch.no_grad():<span class="comment">#减少计算损失梯度</span></span><br><span class="line">                    outputs = net(val_image)  <span class="comment"># [batch, 10]</span></span><br><span class="line">                    predict_y = torch.<span class="built_in">max</span>(outputs, dim=<span class="number">1</span>)[<span class="number">1</span>]<span class="comment">#在输出10个节点找到最大值 获得标签</span></span><br><span class="line">                    accuracy = torch.eq(predict_y, val_label).<span class="built_in">sum</span>().item() / val_label.size(<span class="number">0</span>)<span class="comment">#输出预测对了多少个样本，获得测试准确率</span></span><br><span class="line"></span><br><span class="line">                    <span class="built_in">print</span>(<span class="string">&#x27;[%d, %5d] train_loss: %.3f  test_accuracy: %.3f&#x27;</span> %</span><br><span class="line">                          (epoch + <span class="number">1</span>, step + <span class="number">1</span>, running_loss / <span class="number">500</span>, accuracy))<span class="comment">#打印训练轮数，训练多少步，累加误差，获得训练误差</span></span><br><span class="line">                    running_loss = <span class="number">0.0</span><span class="comment">#清零</span></span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Finished Training&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    save_path = <span class="string">&#x27;./Lenet.pth&#x27;</span><span class="comment">#保存参数和模型</span></span><br><span class="line">    torch.save(net.state_dict(), save_path)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    main()</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>输出结果：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">Files already downloaded and verified</span><br><span class="line">[1,   500] train_loss: 1.747  test_accuracy: 0.459</span><br><span class="line">[1,  1000] train_loss: 1.445  test_accuracy: 0.510</span><br><span class="line">[2,   500] train_loss: 1.230  test_accuracy: 0.575</span><br><span class="line">[2,  1000] train_loss: 1.173  test_accuracy: 0.601</span><br><span class="line">[3,   500] train_loss: 1.034  test_accuracy: 0.612</span><br><span class="line">[3,  1000] train_loss: 1.035  test_accuracy: 0.629</span><br><span class="line">[4,   500] train_loss: 0.941  test_accuracy: 0.645</span><br><span class="line">[4,  1000] train_loss: 0.928  test_accuracy: 0.649</span><br><span class="line">[5,   500] train_loss: 0.846  test_accuracy: 0.666</span><br><span class="line">[5,  1000] train_loss: 0.866  test_accuracy: 0.670</span><br><span class="line">Finished Training</span><br></pre></td></tr></table></figure><p>预测模块</p><p>输入图片</p><p><img src="https://s2.loli.net/2022/12/10/hloJP1QY3FDdcaK.jpg" alt="totest"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torchvision.transforms <span class="keyword">as</span> transforms</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> model <span class="keyword">import</span> LeNet</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    transform = transforms.Compose(</span><br><span class="line">        [transforms.Resize((<span class="number">32</span>, <span class="number">32</span>)),<span class="comment">#缩放图片</span></span><br><span class="line">         transforms.ToTensor(),</span><br><span class="line">         transforms.Normalize((<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>), (<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>))])</span><br><span class="line"></span><br><span class="line">    classes = (<span class="string">&#x27;plane&#x27;</span>, <span class="string">&#x27;car&#x27;</span>, <span class="string">&#x27;bird&#x27;</span>, <span class="string">&#x27;cat&#x27;</span>,</span><br><span class="line">               <span class="string">&#x27;deer&#x27;</span>, <span class="string">&#x27;dog&#x27;</span>, <span class="string">&#x27;frog&#x27;</span>, <span class="string">&#x27;horse&#x27;</span>, <span class="string">&#x27;ship&#x27;</span>, <span class="string">&#x27;truck&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    net = LeNet()</span><br><span class="line">    net.load_state_dict(torch.load(<span class="string">&#x27;Lenet.pth&#x27;</span>))</span><br><span class="line"></span><br><span class="line">    im = Image.<span class="built_in">open</span>(<span class="string">&#x27;totest.jpg&#x27;</span>)</span><br><span class="line">    im = transform(im)  <span class="comment"># [C, H, W]</span></span><br><span class="line">    im = torch.unsqueeze(im, dim=<span class="number">0</span>)  <span class="comment"># [N, C, H, W]增加维度 batch</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        outputs = net(im)</span><br><span class="line">        predict = torch.<span class="built_in">max</span>(outputs, dim=<span class="number">1</span>)[<span class="number">1</span>].numpy()</span><br><span class="line">    <span class="built_in">print</span>(classes[<span class="built_in">int</span>(predict)])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    main()</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>输出结果</p><pre><code>plane</code></pre><h2 id="学习"><a href="#学习" class="headerlink" title="学习"></a>学习</h2><h3 id="Demo流程"><a href="#Demo流程" class="headerlink" title="Demo流程"></a>Demo流程</h3><ol><li>model.py ——定义LeNet网络模型</li><li>train.py ——加载数据集并训练，训练集计算loss，测试集计算accuracy，保存训练好的网络参数</li><li>predict.py——得到训练好的网络参数后，用自己找的图像进行分类测试</li></ol><h3 id="model-py"><a href="#model-py" class="headerlink" title="model.py"></a>model.py</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">LeNet</span>(nn.Module):                     <span class="comment"># 继承于nn.Module这个父类</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):                     <span class="comment"># 初始化网络结构</span></span><br><span class="line">        <span class="built_in">super</span>(LeNet, self).__init__()       <span class="comment"># 多继承需用到super函数</span></span><br><span class="line">        self.conv1 = nn.Conv2d(<span class="number">3</span>, <span class="number">16</span>, <span class="number">5</span>)    <span class="comment">#构建卷积层1，深度3，卷积核个数为16，核大小为5*5 输出深度为卷积核个数</span></span><br><span class="line">        self.pool1 = nn.MaxPool2d(<span class="number">2</span>, <span class="number">2</span>)     <span class="comment">#构建池化层（下采样层）1，核大小为2*2，步长为2</span></span><br><span class="line">        self.conv2 = nn.Conv2d(<span class="number">16</span>, <span class="number">32</span>, <span class="number">5</span>)   <span class="comment">#构建卷积层2，深度16，卷积核个数为32，核大小为5*5</span></span><br><span class="line">        self.pool2 = nn.MaxPool2d(<span class="number">2</span>, <span class="number">2</span>)     <span class="comment">#构建池化层（下采样层）2，核大小为2*2，步长为2</span></span><br><span class="line">        self.fc1 = nn.Linear(<span class="number">32</span>*<span class="number">5</span>*<span class="number">5</span>, <span class="number">120</span>)   <span class="comment">#构建池全连接层1，输入为32*5*5，输出为120</span></span><br><span class="line">        self.fc2 = nn.Linear(<span class="number">120</span>, <span class="number">84</span>)       <span class="comment">#构建池全连接层2，输入为120，输出为84</span></span><br><span class="line">        self.fc3 = nn.Linear(<span class="number">84</span>, <span class="number">10</span>)        <span class="comment">#构建全连接层3，输入为84，输出为10</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):            <span class="comment"># 正向传播过程</span></span><br><span class="line">        x = F.relu(self.conv1(x))    <span class="comment"># input(3, 32, 32) output(16, 28, 28)</span></span><br><span class="line">        x = self.pool1(x)            <span class="comment"># output(16, 14, 14)</span></span><br><span class="line">        x = F.relu(self.conv2(x))    <span class="comment"># output(32, 10, 10)</span></span><br><span class="line">        x = self.pool2(x)            <span class="comment"># output(32, 5, 5)</span></span><br><span class="line">        x = x.view(-<span class="number">1</span>, <span class="number">32</span>*<span class="number">5</span>*<span class="number">5</span>)       <span class="comment"># output(32*5*5) 展开为一维数据</span></span><br><span class="line">        x = F.relu(self.fc1(x))      <span class="comment"># output(120)</span></span><br><span class="line">        x = F.relu(self.fc2(x))      <span class="comment"># output(84)</span></span><br><span class="line">        x = self.fc3(x)              <span class="comment"># output(10)</span></span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure><p><strong>Tips</strong>：</p><ul><li>pytorch中的卷积、池化、输入输出层中参数的含义与位置，可配合下图一起食用：</li></ul><p><img src="https://s2.loli.net/2022/12/10/vbmuFMxjCrGXWLO.png"></p><h4 id="卷积-Conv2d"><a href="#卷积-Conv2d" class="headerlink" title="卷积 Conv2d"></a>卷积 Conv2d</h4><p>我们常用的卷积（Conv2d）在pytorch中对应的函数是：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=<span class="number">1</span>, padding=<span class="number">0</span>, dilation=<span class="number">1</span>, groups=<span class="number">1</span>, bias=<span class="literal">True</span>, padding_mode=<span class="string">&#x27;zeros&#x27;</span>)</span><br></pre></td></tr></table></figure><p>一般使用时关注以下几个参数即可：</p><ul><li><strong>in_channels</strong>：输入特征矩阵的深度。如输入一张RGB彩色图像，那in_channels&#x3D;3</li><li><strong>out_channels</strong>：输入特征矩阵的深度。也等于卷积核的个数，使用n个卷积核输出的特征矩阵深度就是n</li><li><strong>kernel_size</strong>：卷积核的尺寸。可以是int类型，如3 代表卷积核的height&#x3D;width&#x3D;3，也可以是tuple类型如(3, 5)代表卷积核的height&#x3D;3，width&#x3D;5</li><li><strong>stride</strong>：卷积核的步长。默认为1，和kernel_size一样输入可以是int型，也可以是tuple类型</li><li><strong>padding</strong>：补零操作，默认为0。可以为int型如1即补一圈0，如果输入为tuple型如(2, 1) 代表在上下补2行，左右补1列。</li></ul><blockquote><p>附上pytorch官网上的公式：<img src="https://s2.loli.net/2022/12/10/Zp84TjmrdkEex3B.png"></p></blockquote><ul><li><img src="https://s2.loli.net/2022/12/10/MGygxue5QlJskb9.png"></li></ul><p>注：当通过<strong>N &#x3D; (W − F + 2P ) &#x2F; S + 1</strong>计算式得到的输出尺寸非整数时，会通过删除多余的行和列来保证卷积的输出尺寸为整数。</p><h4 id="池化-MaxPool2d"><a href="#池化-MaxPool2d" class="headerlink" title="池化 MaxPool2d"></a>池化 MaxPool2d</h4><p>最大池化（MaxPool2d）在 pytorch 中对应的函数是：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">MaxPool2d(kernel_size, stride) <span class="comment">#核大小;步长</span></span><br></pre></td></tr></table></figure><h4 id="Tensor的展平：view"><a href="#Tensor的展平：view" class="headerlink" title="Tensor的展平：view()"></a>Tensor的展平：view()</h4><p>注意到，在经过第二个池化层后，数据还是一个三维的Tensor (32, 5, 5)，需要先经过展平后(32*5*5)再传到全连接层：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">x = self.pool2(x)            <span class="comment"># output(32, 5, 5)</span></span><br><span class="line">x = x.view(-<span class="number">1</span>, <span class="number">32</span>*<span class="number">5</span>*<span class="number">5</span>)       <span class="comment"># output(32*5*5)</span></span><br><span class="line">x = F.relu(self.fc1(x))      <span class="comment"># output(120)</span></span><br></pre></td></tr></table></figure><h4 id="全连接-Linear"><a href="#全连接-Linear" class="headerlink" title="全连接 Linear"></a>全连接 Linear</h4><p>全连接（ Linear）在 pytorch 中对应的函数是：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Linear(in_features, out_features, bias=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><p><img src="https://s2.loli.net/2022/12/10/zENetyB4dPjvinO.png"></p><h3 id="Train-py"><a href="#Train-py" class="headerlink" title="Train.py"></a>Train.py</h3><h4 id="导入数据集"><a href="#导入数据集" class="headerlink" title="导入数据集"></a>导入数据集</h4><p>导入包</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">from</span> model <span class="keyword">import</span> LeNet</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="keyword">import</span> torchvision.transforms <span class="keyword">as</span> transforms</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> time</span><br></pre></td></tr></table></figure><p>####数据预处理</p><p>对输入的图像数据做预处理，即由shape (H x W x C) in the range [0, 255] → shape (C x H x W) in the range [0.0, 1.0]</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">transform = transforms.Compose(</span><br><span class="line">    [transforms.ToTensor(),</span><br><span class="line">     transforms.Normalize((<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>), (<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>))])</span><br></pre></td></tr></table></figure><h4 id="数据集介绍"><a href="#数据集介绍" class="headerlink" title="数据集介绍"></a>数据集介绍</h4><p>利用<code>torchvision.datasets</code>函数可以在线导入pytorch中的数据集，包含一些常见的数据集如MNIST等<br><img src="https://s2.loli.net/2022/12/10/3qdHunSgXamG5YJ.png"><br>此demo用的是CIFAR10数据集，也是一个很经典的图像分类数据集，由 Hinton 的学生 Alex Krizhevsky 和 Ilya Sutskever 整理的一个用于识别普适物体的小型数据集，一共包含 10 个类别的 RGB 彩色图片。<br><img src="https://s2.loli.net/2022/12/10/Ws63JIl1NgoafDn.png"></p><h4 id="导入、加载-训练集"><a href="#导入、加载-训练集" class="headerlink" title="导入、加载 训练集"></a>导入、加载 训练集</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 导入50000张训练图片</span></span><br><span class="line">train_set = torchvision.datasets.CIFAR10(root=<span class="string">&#x27;./data&#x27;</span>,  <span class="comment"># 数据集存放目录</span></span><br><span class="line"> train=<span class="literal">True</span>, <span class="comment"># 表示是数据集中的训练集</span></span><br><span class="line">                                        download=<span class="literal">True</span>,   <span class="comment"># 第一次运行时为True，下载数据集，下载完成后改为False</span></span><br><span class="line">                                        transform=transform) <span class="comment"># 预处理过程</span></span><br><span class="line"><span class="comment"># 加载训练集，实际过程需要分批次（batch）训练                                        </span></span><br><span class="line">train_loader = torch.utils.data.DataLoader(train_set,   <span class="comment"># 导入的训练集</span></span><br><span class="line">   batch_size=<span class="number">50</span>, <span class="comment"># 每批训练的样本数</span></span><br><span class="line">                                          shuffle=<span class="literal">False</span>,  <span class="comment"># 是否打乱训练集</span></span><br><span class="line">                                          num_workers=<span class="number">0</span>)  <span class="comment"># 使用线程数，在windows下设置为0</span></span><br></pre></td></tr></table></figure><h4 id="导入、加载-测试集"><a href="#导入、加载-测试集" class="headerlink" title="导入、加载 测试集"></a>导入、加载 测试集</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 导入10000张测试图片</span></span><br><span class="line">test_set = torchvision.datasets.CIFAR10(root=<span class="string">&#x27;./data&#x27;</span>, </span><br><span class="line">train=<span class="literal">False</span>,<span class="comment"># 表示是数据集中的测试集</span></span><br><span class="line">                                        download=<span class="literal">False</span>,transform=transform)</span><br><span class="line"><span class="comment"># 加载测试集</span></span><br><span class="line">test_loader = torch.utils.data.DataLoader(test_set, </span><br><span class="line">  batch_size=<span class="number">10000</span>, <span class="comment"># 每批用于验证的样本数</span></span><br><span class="line">  shuffle=<span class="literal">False</span>, num_workers=<span class="number">0</span>)</span><br><span class="line"><span class="comment"># 获取测试集中的图像和标签，用于accuracy计算</span></span><br><span class="line">test_data_iter = <span class="built_in">iter</span>(test_loader)</span><br><span class="line">test_image, test_label = test_data_iter.<span class="built_in">next</span>()</span><br><span class="line"><span class="number">1234567891011</span></span><br></pre></td></tr></table></figure><h4 id="训练过程"><a href="#训练过程" class="headerlink" title="训练过程"></a>训练过程</h4><table><thead><tr><th>名词</th><th>定义</th></tr></thead><tbody><tr><td>epoch</td><td>对训练集的全部数据进行一次完整的训练，称为 一次 epoch</td></tr><tr><td>batch</td><td>由于硬件算力有限，实际训练时将训练集分成多个批次训练，每批数据的大小为 batch_size</td></tr><tr><td>iteration 或 step</td><td>对一个batch的数据训练的过程称为 一个 iteration 或 step</td></tr></tbody></table><p>以本demo为例，训练集一共有50000个样本，batch_size&#x3D;50，那么完整的训练一次样本：iteration或step&#x3D;1000，epoch&#x3D;1</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">net = LeNet()  <span class="comment"># 定义训练的网络模型</span></span><br><span class="line">loss_function = nn.CrossEntropyLoss() <span class="comment"># 定义损失函数为交叉熵损失函数 </span></span><br><span class="line">optimizer = optim.Adam(net.parameters(), lr=<span class="number">0.001</span>)  <span class="comment"># 定义优化器（训练参数，学习率）</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>):  <span class="comment"># 一个epoch即对整个训练集进行一次训练</span></span><br><span class="line">    running_loss = <span class="number">0.0</span></span><br><span class="line">    time_start = time.perf_counter()</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> step, data <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_loader, start=<span class="number">0</span>):   <span class="comment"># 遍历训练集，step从0开始计算</span></span><br><span class="line">        inputs, labels = data <span class="comment"># 获取训练集的图像和标签</span></span><br><span class="line">        optimizer.zero_grad()   <span class="comment"># 清除历史梯度</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># forward + backward + optimize</span></span><br><span class="line">        outputs = net(inputs)    <span class="comment"># 正向传播</span></span><br><span class="line">        loss = loss_function(outputs, labels) <span class="comment"># 计算损失</span></span><br><span class="line">        loss.backward()   <span class="comment"># 反向传播</span></span><br><span class="line">        optimizer.step()   <span class="comment"># 优化器更新参数</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 打印耗时、损失、准确率等数据</span></span><br><span class="line">        running_loss += loss.item()</span><br><span class="line">        <span class="keyword">if</span> step % <span class="number">1000</span> == <span class="number">999</span>:    <span class="comment"># print every 1000 mini-batches，每1000步打印一次</span></span><br><span class="line">            <span class="keyword">with</span> torch.no_grad(): <span class="comment"># 在以下步骤中（验证过程中）不用计算每个节点的损失梯度，防止内存占用</span></span><br><span class="line">                outputs = net(test_image)  <span class="comment"># 测试集传入网络（test_batch_size=10000），output维度为[10000,10]</span></span><br><span class="line">                predict_y = torch.<span class="built_in">max</span>(outputs, dim=<span class="number">1</span>)[<span class="number">1</span>] <span class="comment"># 以output中值最大位置对应的索引（标签）作为预测输出</span></span><br><span class="line">                accuracy = (predict_y == test_label).<span class="built_in">sum</span>().item() / test_label.size(<span class="number">0</span>)</span><br><span class="line">                </span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&#x27;[%d, %5d] train_loss: %.3f  test_accuracy: %.3f&#x27;</span> %  <span class="comment"># 打印epoch，step，loss，accuracy</span></span><br><span class="line">                      (epoch + <span class="number">1</span>, step + <span class="number">1</span>, running_loss / <span class="number">500</span>, accuracy))</span><br><span class="line">                </span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&#x27;%f s&#x27;</span> % (time.perf_counter() - time_start))        <span class="comment"># 打印耗时</span></span><br><span class="line">                running_loss = <span class="number">0.0</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Finished Training&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 保存训练得到的参数</span></span><br><span class="line">save_path = <span class="string">&#x27;./Lenet.pth&#x27;</span></span><br><span class="line">torch.save(net.state_dict(), save_path)</span><br></pre></td></tr></table></figure><p>打印信息如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[<span class="number">1</span>,  <span class="number">1000</span>] train_loss: <span class="number">1.537</span>  test_accuracy: <span class="number">0.541</span></span><br><span class="line"><span class="number">35.345407</span> s</span><br><span class="line">[<span class="number">2</span>,  <span class="number">1000</span>] train_loss: <span class="number">1.198</span>  test_accuracy: <span class="number">0.605</span></span><br><span class="line"><span class="number">40.532376</span> s</span><br><span class="line">[<span class="number">3</span>,  <span class="number">1000</span>] train_loss: <span class="number">1.048</span>  test_accuracy: <span class="number">0.641</span></span><br><span class="line"><span class="number">44.144097</span> s</span><br><span class="line">[<span class="number">4</span>,  <span class="number">1000</span>] train_loss: <span class="number">0.954</span>  test_accuracy: <span class="number">0.647</span></span><br><span class="line"><span class="number">41.313228</span> s</span><br><span class="line">[<span class="number">5</span>,  <span class="number">1000</span>] train_loss: <span class="number">0.882</span>  test_accuracy: <span class="number">0.662</span></span><br><span class="line"><span class="number">41.860646</span> s</span><br><span class="line">Finished Training</span><br></pre></td></tr></table></figure><h4 id="使用GPU-x2F-CPU训练"><a href="#使用GPU-x2F-CPU训练" class="headerlink" title="使用GPU&#x2F;CPU训练"></a>使用GPU&#x2F;CPU训练</h4><p>使用下面语句可以在有GPU时使用GPU，无GPU时使用CPU进行训练</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">device = torch.device(<span class="string">&quot;cuda&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(device)</span><br></pre></td></tr></table></figure><p>也可以直接指定</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">device = torch.device(<span class="string">&quot;cuda&quot;</span>)</span><br><span class="line"><span class="comment"># 或者</span></span><br><span class="line"><span class="comment"># device = torch.device(&quot;cpu&quot;)</span></span><br></pre></td></tr></table></figure><p>对应的，需要用<code>to()</code>函数来将Tensor在CPU和GPU之间相互移动，分配到指定的device中计算</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">net = LeNet()</span><br><span class="line">net.to(device) <span class="comment"># 将网络分配到指定的device中</span></span><br><span class="line">loss_function = nn.CrossEntropyLoss() </span><br><span class="line">optimizer = optim.Adam(net.parameters(), lr=<span class="number">0.001</span>) </span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>): </span><br><span class="line"></span><br><span class="line">    running_loss = <span class="number">0.0</span></span><br><span class="line">    time_start = time.perf_counter()<span class="comment">#添加计时器</span></span><br><span class="line">    <span class="keyword">for</span> step, data <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_loader, start=<span class="number">0</span>):</span><br><span class="line">        inputs, labels = data</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        outputs = net(inputs.to(device))  <span class="comment"># 将inputs分配到指定的device中</span></span><br><span class="line">        loss = loss_function(outputs, labels.to(device))  <span class="comment"># 将labels分配到指定的device中</span></span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line">        running_loss += loss.item()</span><br><span class="line">        <span class="keyword">if</span> step % <span class="number">1000</span> == <span class="number">999</span>:    </span><br><span class="line">            <span class="keyword">with</span> torch.no_grad(): </span><br><span class="line">                outputs = net(test_image.to(device)) <span class="comment"># 将test_image分配到指定的device中</span></span><br><span class="line">                predict_y = torch.<span class="built_in">max</span>(outputs, dim=<span class="number">1</span>)[<span class="number">1</span>]</span><br><span class="line">                accuracy = (predict_y == test_label.to(device)).<span class="built_in">sum</span>().item() / test_label.size(<span class="number">0</span>) <span class="comment"># 将test_label分配到指定的device中</span></span><br><span class="line"></span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&#x27;[%d, %5d] train_loss: %.3f  test_accuracy: %.3f&#x27;</span> %</span><br><span class="line">                      (epoch + <span class="number">1</span>, step + <span class="number">1</span>, running_loss / <span class="number">1000</span>, accuracy))</span><br><span class="line"></span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&#x27;%f s&#x27;</span> % (time.perf_counter() - time_start))</span><br><span class="line">                running_loss = <span class="number">0.0</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Finished Training&#x27;</span>)</span><br><span class="line"></span><br><span class="line">save_path = <span class="string">&#x27;./Lenet.pth&#x27;</span></span><br><span class="line">torch.save(net.state_dict(), save_path)</span><br></pre></td></tr></table></figure><p>打印信息如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">cuda</span><br><span class="line">[<span class="number">1</span>,  <span class="number">1000</span>] train_loss: <span class="number">1.569</span>  test_accuracy: <span class="number">0.527</span></span><br><span class="line"><span class="number">18.727597</span> s</span><br><span class="line">[<span class="number">2</span>,  <span class="number">1000</span>] train_loss: <span class="number">1.235</span>  test_accuracy: <span class="number">0.595</span></span><br><span class="line"><span class="number">17.367685</span> s</span><br><span class="line">[<span class="number">3</span>,  <span class="number">1000</span>] train_loss: <span class="number">1.076</span>  test_accuracy: <span class="number">0.623</span></span><br><span class="line"><span class="number">17.654908</span> s</span><br><span class="line">[<span class="number">4</span>,  <span class="number">1000</span>] train_loss: <span class="number">0.984</span>  test_accuracy: <span class="number">0.639</span></span><br><span class="line"><span class="number">17.861825</span> s</span><br><span class="line">[<span class="number">5</span>,  <span class="number">1000</span>] train_loss: <span class="number">0.917</span>  test_accuracy: <span class="number">0.649</span></span><br><span class="line"><span class="number">17.733115</span> s</span><br><span class="line">Finished Training</span><br></pre></td></tr></table></figure><p>可以看到，用GPU训练时，速度提升明显，耗时缩小。</p><hr><h3 id="Predict-py"><a href="#Predict-py" class="headerlink" title="Predict.py"></a>Predict.py</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 导入包</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torchvision.transforms <span class="keyword">as</span> transforms</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">from</span> model <span class="keyword">import</span> LeNet</span><br><span class="line"></span><br><span class="line"><span class="comment"># 数据预处理</span></span><br><span class="line">transform = transforms.Compose(</span><br><span class="line">    [transforms.Resize((<span class="number">32</span>, <span class="number">32</span>)), <span class="comment"># 首先需resize成跟训练集图像一样的大小</span></span><br><span class="line">     transforms.ToTensor(),</span><br><span class="line">     transforms.Normalize((<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>), (<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>))])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 导入要测试的图像（自己找的，不在数据集中），放在源文件目录下</span></span><br><span class="line">im = Image.<span class="built_in">open</span>(<span class="string">&#x27;horse.jpg&#x27;</span>)</span><br><span class="line">im = transform(im)  <span class="comment"># [C, H, W]</span></span><br><span class="line">im = torch.unsqueeze(im, dim=<span class="number">0</span>)  <span class="comment"># 对数据增加一个新维度，因为tensor的参数是[batch, channel, height, width] </span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 实例化网络，加载训练好的模型参数</span></span><br><span class="line">net = LeNet()</span><br><span class="line">net.load_state_dict(torch.load(<span class="string">&#x27;Lenet.pth&#x27;</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 预测</span></span><br><span class="line">classes = (<span class="string">&#x27;plane&#x27;</span>, <span class="string">&#x27;car&#x27;</span>, <span class="string">&#x27;bird&#x27;</span>, <span class="string">&#x27;cat&#x27;</span>,</span><br><span class="line">           <span class="string">&#x27;deer&#x27;</span>, <span class="string">&#x27;dog&#x27;</span>, <span class="string">&#x27;frog&#x27;</span>, <span class="string">&#x27;horse&#x27;</span>, <span class="string">&#x27;ship&#x27;</span>, <span class="string">&#x27;truck&#x27;</span>)</span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    outputs = net(im)</span><br><span class="line">    predict = torch.<span class="built_in">max</span>(outputs, dim=<span class="number">1</span>)[<span class="number">1</span>].data.numpy()</span><br><span class="line"><span class="built_in">print</span>(classes[<span class="built_in">int</span>(predict)])</span><br></pre></td></tr></table></figure><p>输出即为预测的标签。</p><p>其实预测结果也可以用 <strong>softmax</strong> 表示，输出10个概率：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    outputs = net(im)</span><br><span class="line">    predict = torch.softmax(outputs, dim=<span class="number">1</span>)</span><br><span class="line"><span class="built_in">print</span>(predict)</span><br></pre></td></tr></table></figure><p>输出结果中最大概率值对应的索引即为 预测标签 的索引。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tensor([[<span class="number">2.2782e-06</span>, <span class="number">2.1008e-07</span>, <span class="number">1.0098e-04</span>, <span class="number">9.5135e-05</span>, <span class="number">9.3220e-04</span>, <span class="number">2.1398e-04</span>,</span><br><span class="line">         <span class="number">3.2954e-08</span>, <span class="number">9.9865e-01</span>, <span class="number">2.8895e-08</span>, <span class="number">2.8820e-07</span>]])</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 人工智能 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>贪吃蛇大作战分析</title>
      <link href="/2022/12/10/%E8%B4%AA%E5%90%83%E8%9B%87%E5%A4%A7%E4%BD%9C%E6%88%98%E5%88%86%E6%9E%90/"/>
      <url>/2022/12/10/%E8%B4%AA%E5%90%83%E8%9B%87%E5%A4%A7%E4%BD%9C%E6%88%98%E5%88%86%E6%9E%90/</url>
      
        <content type="html"><![CDATA[<h1 id="与对象玩游戏的思考-1"><a href="#与对象玩游戏的思考-1" class="headerlink" title="与对象玩游戏的思考-1"></a>与对象玩游戏的思考-1</h1><img src="https://s2.loli.net/2022/12/10/UxC3Bh7DOsmAtMK.png" alt="贪吃蛇大作战LOGO" style="zoom:33%;" /><p>贪吃蛇大作战是一款对象爱玩的游戏，我也经常陪她一起玩，一开始觉得这个游戏些许幼稚，但一段时间发先此游戏确实有些独特之处，我仅站在我的角度对此款游戏进行分析。</p><h2 id="游戏操作"><a href="#游戏操作" class="headerlink" title="游戏操作"></a>游戏操作</h2><p>作为一款IO型游戏（.io域名网页移植型游戏）它必定轻量化且易上手。左侧摇杆进行方向控制，右侧控制加速按钮和道具&#x2F;技能按钮。玩家通过操控贪吃蛇食取地图上的粒子和大粒子以及道具，延长自身长度。通过灵活操作让别的贪吃蛇撞到自身身体部分达成击杀。对象作为一个讨厌复杂操作的游戏玩家很容易掌握，其上手门槛极低，老少咸宜。</p><h2 id="游戏模式"><a href="#游戏模式" class="headerlink" title="游戏模式"></a>游戏模式</h2><p>实际上分为两类：</p><ul><li>人机模式（无尽模式及其衍生）</li><li>PvP模式（团战模式，击杀模式）</li></ul><p>前者对应了需要打发时间的休闲玩家，后者对应了有对战需求的竞技玩家。其各个模式都含有玩家的排行榜，鼓励玩家游玩。</p><h2 id="运营思路"><a href="#运营思路" class="headerlink" title="运营思路"></a>运营思路</h2><p>作为一款运营6年的游戏，微派网络的运营显然是成功的。但于此同时，观察微派网络官方的产品介绍，微派至今未能拿出较为重量的游戏产品…</p><p>贪吃蛇的运营思路：广告＋效果付费+礼物</p><p>对于免费玩家，通过看广告奖励游戏道具创收。对于付费玩家，通过游戏皮肤，击杀效果等场上道具，以及社群属性的赠送礼物，以及诸多例如show值，魅力值等系统排行展示，诱导消费。</p><h2 id="游戏弊端"><a href="#游戏弊端" class="headerlink" title="游戏弊端"></a>游戏弊端</h2><p>游戏的弊端大多存在于PvP模式下。</p><ul><li><p>网络平衡和链接稳定性差：网络稳定性是作为IO游戏能愉快游玩的关键因素，在不同网络条件下，同一局能一起愉快游玩必须做好网络平衡，否则对部分玩家，体验极差。然而贪吃蛇大作战的解决方案既不是增加链接更近的服务器，降低网络延迟。也不是交出满意的游戏网络平衡方案。而是通过减少网络质量差玩家的加速按钮使用来控制。不止到读者是否遇到加速按钮按不动没有效果的情况，极其影响竞技体验。（补充：同样的网络环境跑腾讯系游戏40ms EA平台94ms 但在贪吃蛇游戏中要么140+ 要么就是绿色信号的但卡按钮）</p></li><li><p>游戏皮肤平衡未完善；游戏皮肤不应该成为影响竞技体验的要素，但经过较长时间的游玩发现，不同皮肤的头部碰撞箱判定是不同的，导致对无皮肤玩家的不公平。</p></li><li><p>游戏判定问题：完全正碰无法计算。随机给一方？</p></li><li><p>游戏机型优化：苹果系设备在promotion高刷支持下游戏对局流畅度明显高于安卓机型，此外在PvP模式下此类特殊优化体验甚至高于网络优化令人唏嘘。</p></li></ul>]]></content>
      
      
      <categories>
          
          <category> 杂谈 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 贪吃蛇大作战 </tag>
            
            <tag> 游戏分析 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>神经网络基础模型学习资源</title>
      <link href="/2022/12/08/%E8%B5%84%E6%BA%90%E5%88%97%E8%A1%A8/"/>
      <url>/2022/12/08/%E8%B5%84%E6%BA%90%E5%88%97%E8%A1%A8/</url>
      
        <content type="html"><![CDATA[<h1 id="神经网络基础模型学习资源"><a href="#神经网络基础模型学习资源" class="headerlink" title="神经网络基础模型学习资源"></a>神经网络基础模型学习资源</h1><h2 id="视频课"><a href="#视频课" class="headerlink" title="视频课"></a>视频课</h2><ul><li><p><a href="https://space.bilibili.com/18161609/"><strong>霹雳吧啦Wz基础教程</strong></a></p></li><li><p><a href="https://space.bilibili.com/21241234"><strong>刘二大人</strong></a></p></li></ul><h2 id="博客笔记"><a href="#博客笔记" class="headerlink" title="博客笔记"></a>博客笔记</h2><ul><li><p><a href="https://blog.csdn.net/m0_37867091?type=blog"><strong>CSDN神经网络</strong></a></p></li><li><p><a href="https://redstonewill.com/category/ai-notes/"><strong>红色石头</strong></a></p></li><li><p><a href="http://www.ai-start.com/"><strong>吴恩达笔记</strong></a></p></li></ul><h2 id="可视化"><a href="#可视化" class="headerlink" title="可视化"></a>可视化</h2><p>部分摘自<a href="https://cloud.tencent.com/developer/article/1882674">数据studio</a>，部分自行收集</p><h3 id="1、PlotNeuralNet"><a href="#1、PlotNeuralNet" class="headerlink" title="1、PlotNeuralNet"></a><strong>1、PlotNeuralNet</strong></h3><p>使用<strong>Latex</strong>绘制神经网络。传送门：<a href="https://github.com/HarisIqbal88/PlotNeuralNet">https://github.com/HarisIqbal88/PlotNeuralNet</a></p><p><img src="https://s2.loli.net/2022/12/10/zCPAx53wpQiryVj.png"></p><p>FCN-8模型</p><p>overleaf上Latex代码：<a href="https://www.overleaf.com/read/kkqntfxnvbsk">https://www.overleaf.com/read/kkqntfxnvbsk</a></p><p><img src="https://s2.loli.net/2022/12/10/Qy4pCEc7GMR6jnP.png"></p><p>FCN-32模型</p><p>overleaf上Latex代码：<a href="https://www.overleaf.com/read/wsxpmkqvjnbs">https://www.overleaf.com/read/wsxpmkqvjnbs</a></p><p><img src="https://s2.loli.net/2022/12/10/Izuf4rYX8WbwaCj.png"></p><p>Holistically-Nested Edge Detection</p><p>overleaf上Latex代码：<a href="https://www.overleaf.com/read/jxhnkcnwhfxp">https://www.overleaf.com/read/jxhnkcnwhfxp</a></p><hr><h3 id="2、Matlab"><a href="#2、Matlab" class="headerlink" title="2、Matlab"></a><strong>2、Matlab</strong></h3><p><a href="https://www.mathworks.com/help/deeplearning/ref/view.html;jsessionid=bd77484ba149c98d4d410abed983">https://www.mathworks.com/help/deeplearning/ref/view.html;jsessionid=bd77484ba149c98d4d410abed983</a></p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[x,t] = iris_dataset;</span><br><span class="line">net = patternnet;</span><br><span class="line">net = <span class="title function_">configure</span>(net,x,t);</span><br><span class="line"><span class="title function_">view</span>(net)</span><br></pre></td></tr></table></figure><p>复制</p><p><img src="https://s2.loli.net/2022/12/10/y1eJVsHdMI2mDUA.png"></p><hr><h3 id="3、NN-SVG"><a href="#3、NN-SVG" class="headerlink" title="3、NN-SVG"></a><strong>3、NN-SVG</strong></h3><p>一个在线工具，点点就阔以了：<a href="http://alexlenail.me/NN-SVG/LeNet.html">http://alexlenail.me/NN-SVG/LeNet.html</a></p><p><img src="https://s2.loli.net/2022/12/10/8Xfd1VzRA3iI5gG.png"></p><p>AlexNet模型</p><p><img src="https://s2.loli.net/2022/12/10/A5TNwfOHscE4yBr.png"></p><p>LeNet模型</p><hr><h3 id="4、graphcore"><a href="#4、graphcore" class="headerlink" title="4、graphcore"></a><strong>4、graphcore</strong></h3><p>回到神经网络最初的地方，<strong>像生物细胞神经元neurons一样展示神经网络</strong>。<a href="https://www.graphcore.ai/posts/what-does-machine-learning-look-like">https://www.graphcore.ai/posts/what-does-machine-learning-look-like</a></p><p><img src="https://s2.loli.net/2022/12/10/t4LcPpaTgr7doCk.png"></p><p>生物细胞神经元模式图</p><p>AlexNet模型</p><p><img src="https://s2.loli.net/2022/12/10/MFJdwH2nvSX3RIb.png"></p><p>Resnet 50模型</p><hr><h3 id="5、graphviz"><a href="#5、graphviz" class="headerlink" title="5、graphviz"></a><strong>5、graphviz</strong></h3><p><a href="http://www.graphviz.org/">http://www.graphviz.org/</a></p><p>之前介绍过一个类似绘制网络关系的工具👉<a href="https://mp.weixin.qq.com/s?__biz=MzUwOTg0MjczNw==&mid=2247492450&idx=1&sn=045f3fad7573bef525c972b4e91e76c3&chksm=f90ea73cce792e2a92430c0eff73415380efce970f2641814f321fc2260a70ea686369925f3c&token=1079425073&lang=zh_CN&scene=21#wechat_redirect"><strong>盘一盘社交网络分析常用networks</strong></a></p><p><img src="https://s2.loli.net/2022/12/10/GZtAEw8HQUjRNeC.png"></p><p>4层网络</p><hr><h3 id="6、Keras"><a href="#6、Keras" class="headerlink" title="6、Keras"></a><strong>6、Keras</strong></h3><p><strong>深度学习框架Keras</strong>下的一个小模块，</p><p><a href="https://keras.io/api/utils/model_plotting_utils/">https://keras.io/api/utils/model_plotting_utils/</a></p><p><img src="https://s2.loli.net/2022/12/10/u9INipoZPFWMv37.png"></p><hr><h3 id="7、neataptic"><a href="#7、neataptic" class="headerlink" title="7、neataptic"></a><strong>7、neataptic</strong></h3><p><a href="https://github.com/wagenaartje/neataptic">https://github.com/wagenaartje/neataptic</a></p><p><img src="https://s2.loli.net/2022/12/10/M4s7r1JSgIKnFVf.png"></p><hr><h3 id="8、Quiver"><a href="#8、Quiver" class="headerlink" title="8、Quiver"></a><strong>8、Quiver</strong></h3><p><a href="https://github.com/keplr-io/quiver">https://github.com/keplr-io/quiver</a></p><p><img src="https://s2.loli.net/2022/12/10/klFsLSt7u4OfiXP.png"></p><hr><h3 id="9、Keras-js"><a href="#9、Keras-js" class="headerlink" title="9、Keras.js"></a><strong>9、Keras.js</strong></h3><p>在线工具</p><p><a href="https://transcranial.github.io/keras-js/#/inception-v3">https://transcranial.github.io/keras-js/#/inception-v3</a></p><p><img src="https://s2.loli.net/2022/12/10/lDbWQ4d7kZsVoRe.png"></p><p><img src="https://s2.loli.net/2022/12/10/XuzvrIKjty7lF6E.png"></p><hr><h3 id="10、Netscope-CNN-Analyzer"><a href="#10、Netscope-CNN-Analyzer" class="headerlink" title="10、Netscope CNN Analyzer"></a><strong>10、Netscope CNN Analyzer</strong></h3><p><a href="http://dgschwend.github.io/netscope/quickstart.html">http://dgschwend.github.io/netscope/quickstart.html</a></p><p><img src="https://s2.loli.net/2022/12/10/l2tK6oys9UZgOan.png"></p><hr><h3 id="11、keras-sequential-ascii"><a href="#11、keras-sequential-ascii" class="headerlink" title="11、keras-sequential-ascii"></a><strong>11、keras-sequential-ascii</strong></h3><p><a href="https://github.com/stared/keras-sequential-ascii/">https://github.com/stared/keras-sequential-ascii/</a></p><p>VGG 16 Architecture</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line">     <span class="variable constant_">OPERATION</span>           <span class="variable constant_">DATA</span> <span class="variable constant_">DIMENSIONS</span>   <span class="title function_">WEIGHTS</span>(N)   <span class="title function_">WEIGHTS</span>(%)</span><br><span class="line"></span><br><span class="line">        <span class="title class_">Input</span>   #####      <span class="number">3</span>  <span class="number">224</span>  <span class="number">224</span></span><br><span class="line">   <span class="title class_">InputLayer</span>     |   -------------------         <span class="number">0</span>     <span class="number">0.0</span>%</span><br><span class="line">                #####      <span class="number">3</span>  <span class="number">224</span>  <span class="number">224</span></span><br><span class="line"><span class="title class_">Convolution2D</span>    \|/  -------------------      <span class="number">1792</span>     <span class="number">0.0</span>%</span><br><span class="line">         relu   #####     <span class="number">64</span>  <span class="number">224</span>  <span class="number">224</span></span><br><span class="line"><span class="title class_">Convolution2D</span>    \|/  -------------------     <span class="number">36928</span>     <span class="number">0.0</span>%</span><br><span class="line">         relu   #####     <span class="number">64</span>  <span class="number">224</span>  <span class="number">224</span></span><br><span class="line"> <span class="title class_">MaxPooling2D</span>   Y max -------------------         <span class="number">0</span>     <span class="number">0.0</span>%</span><br><span class="line">                #####     <span class="number">64</span>  <span class="number">112</span>  <span class="number">112</span></span><br><span class="line"><span class="title class_">Convolution2D</span>    \|/  -------------------     <span class="number">73856</span>     <span class="number">0.1</span>%</span><br><span class="line">         relu   #####    <span class="number">128</span>  <span class="number">112</span>  <span class="number">112</span></span><br><span class="line"><span class="title class_">Convolution2D</span>    \|/  -------------------    <span class="number">147584</span>     <span class="number">0.1</span>%</span><br><span class="line">         relu   #####    <span class="number">128</span>  <span class="number">112</span>  <span class="number">112</span></span><br><span class="line"> <span class="title class_">MaxPooling2D</span>   Y max -------------------         <span class="number">0</span>     <span class="number">0.0</span>%</span><br><span class="line">                #####    <span class="number">128</span>   <span class="number">56</span>   <span class="number">56</span></span><br><span class="line"><span class="title class_">Convolution2D</span>    \|/  -------------------    <span class="number">295168</span>     <span class="number">0.2</span>%</span><br><span class="line">         relu   #####    <span class="number">256</span>   <span class="number">56</span>   <span class="number">56</span></span><br><span class="line"><span class="title class_">Convolution2D</span>    \|/  -------------------    <span class="number">590080</span>     <span class="number">0.4</span>%</span><br><span class="line">         relu   #####    <span class="number">256</span>   <span class="number">56</span>   <span class="number">56</span></span><br><span class="line"><span class="title class_">Convolution2D</span>    \|/  -------------------    <span class="number">590080</span>     <span class="number">0.4</span>%</span><br><span class="line">         relu   #####    <span class="number">256</span>   <span class="number">56</span>   <span class="number">56</span></span><br><span class="line"> <span class="title class_">MaxPooling2D</span>   Y max -------------------         <span class="number">0</span>     <span class="number">0.0</span>%</span><br><span class="line">                #####    <span class="number">256</span>   <span class="number">28</span>   <span class="number">28</span></span><br><span class="line"><span class="title class_">Convolution2D</span>    \|/  -------------------   <span class="number">1180160</span>     <span class="number">0.9</span>%</span><br><span class="line">         relu   #####    <span class="number">512</span>   <span class="number">28</span>   <span class="number">28</span></span><br><span class="line"><span class="title class_">Convolution2D</span>    \|/  -------------------   <span class="number">2359808</span>     <span class="number">1.7</span>%</span><br><span class="line">         relu   #####    <span class="number">512</span>   <span class="number">28</span>   <span class="number">28</span></span><br><span class="line"><span class="title class_">Convolution2D</span>    \|/  -------------------   <span class="number">2359808</span>     <span class="number">1.7</span>%</span><br><span class="line">         relu   #####    <span class="number">512</span>   <span class="number">28</span>   <span class="number">28</span></span><br><span class="line"> <span class="title class_">MaxPooling2D</span>   Y max -------------------         <span class="number">0</span>     <span class="number">0.0</span>%</span><br><span class="line">                #####    <span class="number">512</span>   <span class="number">14</span>   <span class="number">14</span></span><br><span class="line"><span class="title class_">Convolution2D</span>    \|/  -------------------   <span class="number">2359808</span>     <span class="number">1.7</span>%</span><br><span class="line">         relu   #####    <span class="number">512</span>   <span class="number">14</span>   <span class="number">14</span></span><br><span class="line"><span class="title class_">Convolution2D</span>    \|/  -------------------   <span class="number">2359808</span>     <span class="number">1.7</span>%</span><br><span class="line">         relu   #####    <span class="number">512</span>   <span class="number">14</span>   <span class="number">14</span></span><br><span class="line"><span class="title class_">Convolution2D</span>    \|/  -------------------   <span class="number">2359808</span>     <span class="number">1.7</span>%</span><br><span class="line">         relu   #####    <span class="number">512</span>   <span class="number">14</span>   <span class="number">14</span></span><br><span class="line"> <span class="title class_">MaxPooling2D</span>   Y max -------------------         <span class="number">0</span>     <span class="number">0.0</span>%</span><br><span class="line">                #####    <span class="number">512</span>    <span class="number">7</span>    <span class="number">7</span></span><br><span class="line">      <span class="title class_">Flatten</span>   ||||| -------------------         <span class="number">0</span>     <span class="number">0.0</span>%</span><br><span class="line">                #####       <span class="number">25088</span></span><br><span class="line">        <span class="title class_">Dense</span>   <span class="variable constant_">XXXXX</span> ------------------- <span class="number">102764544</span>    <span class="number">74.3</span>%</span><br><span class="line">         relu   #####        <span class="number">4096</span></span><br><span class="line">        <span class="title class_">Dense</span>   <span class="variable constant_">XXXXX</span> -------------------  <span class="number">16781312</span>    <span class="number">12.1</span>%</span><br><span class="line">         relu   #####        <span class="number">4096</span></span><br><span class="line">        <span class="title class_">Dense</span>   <span class="variable constant_">XXXXX</span> -------------------   <span class="number">4097000</span>     <span class="number">3.0</span>%</span><br><span class="line">      softmax   #####        <span class="number">1000</span></span><br></pre></td></tr></table></figure><p>复制</p><hr><h3 id="12、TensorBoard"><a href="#12、TensorBoard" class="headerlink" title="12、TensorBoard"></a><strong>12、TensorBoard</strong></h3><p>一个评估<strong>深度学习框架TensorFlow</strong>模型的强力工具。</p><p><a href="https://www.tensorflow.org/tensorboard/graphs">https://www.tensorflow.org/tensorboard/graphs</a></p><p><img src="https://s2.loli.net/2022/12/10/2t4CA6bsEfDwJrP.png"></p><hr><h3 id="13、Caffe"><a href="#13、Caffe" class="headerlink" title="13、Caffe"></a><strong>13、Caffe</strong></h3><p>同样是<strong>深度学习框架Caffe</strong>下的一个小工具，</p><p><a href="https://github.com/BVLC/caffe/blob/master/python/caffe/draw.py">https://github.com/BVLC/caffe/blob/master/python/caffe/draw.py</a></p><p><img src="https://s2.loli.net/2022/12/10/FCp5ri67XHos8kd.png"></p><hr><h3 id="14、TensorSpace"><a href="#14、TensorSpace" class="headerlink" title="14、TensorSpace"></a><strong>14、TensorSpace</strong></h3><p><strong>3D模式展示神经网络</strong>，</p><p><a href="https://tensorspace.org/">https://tensorspace.org/</a></p><p><img src="https://s2.loli.net/2022/12/10/sH7plYeB3qMA982.png"></p><hr><h3 id="15、CNN-Explainer"><a href="#15、CNN-Explainer" class="headerlink" title="15、CNN Explainer"></a><strong>15、CNN Explainer</strong></h3><p>CNN解释器是 CNN可视化的工具，对于小白而言，CNN可视化对于理解CNN有非常的帮助，因此，花了几天的时间，将CNN解释器网站做了一个翻译，还包括安装CNN解释器的过程和相关资料。<br>CNN解释器地址：<a href="https://poloclub.github.io/cnn-explainer">CNN Explainer</a></p><p>CNN解释器文献：<a href="https://arxiv.org/abs/2004.15004">CNN Explainer: Learning Convolutional Neural Networks with Interactive Visualization</a></p><p>CNN github地址：<a href="https://github.com/poloclub/cnn-explainer">https://github.com/poloclub/cnn-explainer</a></p><p>CNN解释器安装：<a href="https://zhuanlan.zhihu.com/p/141537738">https://zhuanlan.zhihu.com/p/141537738</a> </p><p><img src="https://s2.loli.net/2022/12/10/IXrZRDbckK71hW6.png"></p><h3 id="15、基本操作-人工智能的诞生"><a href="#15、基本操作-人工智能的诞生" class="headerlink" title="15、基本操作-人工智能的诞生"></a><strong>15、基本操作-人工智能的诞生</strong></h3><p>交互视频课程，极其适合初学者，就是有点贵，运营歪屁股<br><a href="https://jibencaozuo.com/zh-Hans/videoSeries/1/episode/0">人工智能的诞生</a></p><p><img src="https://s2.loli.net/2022/12/10/MsajcZUqnVoYAHd.png"></p>]]></content>
      
      
      <categories>
          
          <category> 学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 人工智能 </tag>
            
            <tag> 学习资源 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>LeNet-1</title>
      <link href="/2022/12/08/CNN%E5%9F%BA%E7%A1%80/"/>
      <url>/2022/12/08/CNN%E5%9F%BA%E7%A1%80/</url>
      
        <content type="html"><![CDATA[<h1 id="CNN基础"><a href="#CNN基础" class="headerlink" title="CNN基础"></a>CNN基础</h1><h2 id="计算机视觉"><a href="#计算机视觉" class="headerlink" title="计算机视觉"></a>计算机视觉</h2><ol><li><p><strong>图像分类（Image Classification）</strong></p></li><li><p><strong>目标识别（Object detection）</strong></p></li><li><p><strong>神经风格转换（Neural Style Transfer）</strong></p></li></ol><p><strong>使用传统神经网络处理机器视觉的一个主要问题是输入层维度很大</strong>。如果图片尺寸较大，例如一张1000x1000x3的图片，神经网络输入层的维度将达到3百万，使得<strong>网络权重W非常庞大</strong>。这样会造成两个后果，一是神经网络结构复杂，数据量相对不够，容易出现过拟合；二是所需内存、计算量较大。<strong>解决这一问题的方法就是使用卷积神经网络（CNN）。</strong></p><p><strong>CNN做的事情其实是，来简化这个neural network的架构，我们根据自己的知识和对图像处理的理解，一开始就把某些实际上用不到的参数给过滤掉</strong>，我们一开始就想一些办法，不要用fully connected network，而是用比较少的参数，来做图像处理这件事情，所以CNN其实是比一般的DNN还要更简单的。</p><hr><h2 id="卷积操作：以边缘检测举例"><a href="#卷积操作：以边缘检测举例" class="headerlink" title="卷积操作：以边缘检测举例"></a>卷积操作：以边缘检测举例</h2><p>（Edge Detection）</p><p>图片边缘检测的方式</p><ol><li>垂直边缘检测（Vertical edges）</li><li>水平边缘检测（Horizontal edges）</li></ol><p><img src="https://s2.loli.net/2022/12/07/ADTrBFMpjeycq4l.png"></p><p>边缘检测通过相应的滤波器（卷积核）卷积实现。</p><h3 id="【示例】垂直检测"><a href="#【示例】垂直检测" class="headerlink" title="【示例】垂直检测"></a>【示例】垂直检测</h3><p><img src="http://www.ai-start.com/dl2017/images/9aa008335e8a229d3818a61aaccc7173.png" alt="垂直检测1"></p><p><img src="https://img-blog.csdnimg.cn/2020042210323963.png#pic_center" alt="垂直检测2"></p><p>图片的边缘检测可以通过与相应滤波器进行卷积来实现。以垂直边缘检测为例，原始图片尺寸为6×6，滤波器filter尺寸为3×3，卷积后的图片尺寸为4×4</p><p>其中 *****代表卷积 上图只显示了卷积后的第一个值和最后一个值，其余值可自行计算。</p><h2 id="边缘检测补充"><a href="#边缘检测补充" class="headerlink" title="边缘检测补充"></a>边缘检测补充</h2><p>图像边缘有两种渐变方式，一种是由明变暗，另一种是由暗变明。以垂直边缘检测为例，下图展示了两种方式的区别。实际应用中，这两种渐变方式并不影响边缘检测结果，可以对输出图像取绝对值操作，得到同样的结果。</p><p><img src="https://img-blog.csdnimg.cn/20200422104421714.png#pic_center" alt="在这里插入图片描述"><br>下图展示一个水平边缘检测的例子：</p><p><img src="https://img-blog.csdnimg.cn/20200422104724389.png#pic_center" alt="在这里插入图片描述"></p><p>垂直边缘检测和水平边缘检测的滤波器<a href="https://so.csdn.net/so/search?q=%E7%AE%97%E5%AD%90&spm=1001.2101.3001.7020">算子</a>如下所示：</p><p><img src="https://img-blog.csdnimg.cn/20200422104617695.png#pic_center" alt="在这里插入图片描述"><br>除了上面提到的这种简单的Vertical、Horizontal滤波器之外，还有其它常用的filters，例如Sobel filter和Scharr filter。这两种滤波器的特点是增加图片中心区域的权重。（下图展示的是垂直边缘检测算子，水平边缘检测算子只需将上图顺时针翻转90度即可。）</p><p><img src="https://img-blog.csdnimg.cn/20200422105237527.png#pic_center" alt="在这里插入图片描述"><br>在深度学习中，如果我们想检测图像的各种边缘特征，而不仅限于垂直边缘和水平边缘，那么 filter 的数值一般需要通过模型训练得到，类似于标准神经网络中的权重 w ww 一样由反向传播算法迭代求得。CNN的主要目的就是计算出这些 filter 的数值。确定得到了这些 filter 后，CNN浅层网络也就实现了对图片所有边缘特征的检测。<br><img src="https://img-blog.csdnimg.cn/2020042210550658.png#pic_center" alt="在这里插入图片描述"></p><h2 id="Padding"><a href="#Padding" class="headerlink" title="Padding"></a>Padding</h2><p>按照我们上面讲的图片卷积，如果原始图片尺寸为 n × n，filter尺寸为 f × f，则卷积后的图片尺寸为 ( n − f + 1 ) × ( n − f + 1 ) ，注意 f 一般为奇数。这样会带来两个问题：</p><ol><li>卷积运算后，输出图片尺寸缩小</li><li>原始图片边缘信息对输出贡献得少，输出图片丢失边缘信息</li></ol><p>为了解决图片缩小的问题，可以 <strong>使用padding方法，即把原始图片尺寸进行扩展，扩展区域补零</strong>，用 p pp 来表示每个方向扩展的宽度。<br><img src="https://img-blog.csdnimg.cn/20200422110159369.png#pic_center" alt="在这里插入图片描述"><br>经过padding之后:</p><table><thead><tr><th>原始图像padding后尺寸</th><th>filter尺寸</th><th>卷积后的图像尺寸</th></tr></thead><tbody><tr><td>( n + 2 p ) × ( n + 2 p )</td><td>f × f</td><td>( n + 2 p − f + 1 ) × ( n + 2 p − f + 1 )</td></tr></tbody></table><p>稍作总结：</p><ul><li>无padding操作，p &#x3D; 0，我们称之为 <strong>Valid convolutions</strong> （不填充）</li><li>有padding操作，$\ p&#x3D;\frac{f-1}{2}$我们称之为 <strong>Same convolutions</strong> （填充，输入输出大小相等）</li></ul><hr><h2 id="卷积步长"><a href="#卷积步长" class="headerlink" title="卷积步长"></a>卷积步长</h2><p><img src="https://img-blog.csdnimg.cn/20200422111528803.png#pic_center" alt="卷积步长"></p><p>我们用s 表示stride长度，p 表示padding长度，如果原始图片尺寸为 n × n，filter（卷积核）尺寸为 f × f ，则卷积后的图片尺寸为：</p><p><img src="https://s2.loli.net/2022/12/07/HwfI68tMDunColL.png"></p><p>注：商不是整数的情况下，向下取整</p><h3 id="数学上卷积与人工智能卷积的区别："><a href="#数学上卷积与人工智能卷积的区别：" class="headerlink" title="数学上卷积与人工智能卷积的区别："></a>数学上卷积与人工智能卷积的区别：</h3><ul><li>数学意义上的卷积（<strong>convolutions</strong>））运算会先将filter绕其中心旋转180度，然后再将旋转后的filter在原始图片上进行滑动计算。filter旋转如下所示：<br><img src="https://img-blog.csdnimg.cn/20200422112729414.png#pic_center" alt="在这里插入图片描述"></li><li>人工智能意义上卷积：相关系数（<strong>cross-correlations</strong>）的计算过程则不会对filter进行旋转，而是直接在原始图片上进行滑动计算。</li></ul><p><strong>总的来说，忽略旋转运算可以大大提高CNN网络运算速度，而且不影响模型性能。</strong></p><p>注：卷积运算服从结合率不服从交换律</p><hr><h2 id="三维卷积"><a href="#三维卷积" class="headerlink" title="三维卷积"></a>三维卷积</h2><p>同二维卷积多了一个维度</p><ul><li><p>卷积核 channel（深度&#x2F;通道数）与输入特征层 的channel 相同</p></li><li><p>输出的特征矩阵channel与卷积核个数相同</p></li></ul><p>（Convolutions over volumes）</p><p>对于3通道的RGB图像，其对应的滤波器算子同样也是3通道的。例如一个图像是6 x 6 x 3，分别表示图像的高度（height）、宽度（weight）和通道（channel）。</p><p>3通道图像的卷积运算与单通道图像的卷积运算基本一致。过程是将每个单通道（R，G，B）与对应的filter进行卷积运算求和，然后再<strong>将3通道的和相加</strong>，得到输出图像的<strong>一个</strong>像素值。</p><p><img src="https://img-blog.csdnimg.cn/20200422113610810.png#pic_center" alt="在这里插入图片描述"><br>不同通道的滤波算子可以不相同。例如R通道filter实现垂直边缘检测，G和B通道不进行边缘检测，全部置零，或者将R，G，B三通道filter全部设置为水平边缘检测。</p><p>为了实现更多边缘检测，可以增加更多的滤波器组，进行多个卷积运算。例如设置第一个滤波器组实现垂直边缘检测，第二个滤波器组实现水平边缘检测。这样，不同滤波器组卷积得到不同的输出，个数由滤波器组决定。</p><p><img src="https://img-blog.csdnimg.cn/20200422113807669.png#pic_center" alt="在这里插入图片描述"></p><p><img src="https://s2.loli.net/2022/12/07/sBoEdSWhqKINkc4.png"></p><h2 id="单层卷积网络"><a href="#单层卷积网络" class="headerlink" title="单层卷积网络"></a>单层卷积网络</h2><p>卷积神经网络的单层结构如下所示：<br><img src="https://img-blog.csdnimg.cn/20200422151012841.png#pic_center" alt="卷积神经网络的单层结构如下所示："></p><p><img src="https://s2.loli.net/2022/12/07/BkVoKx69ZDuY8PF.png"></p><p>总结</p><p><img src="https://s2.loli.net/2022/12/07/tXxq1EfkgDBvYeT.png"></p>]]></content>
      
      
      <categories>
          
          <category> 学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 人工智能 </tag>
            
            <tag> LeNet </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
