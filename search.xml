<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>VGG-2</title>
      <link href="/2022/12/21/VGG%E5%AE%9E%E8%B7%B5%E7%BB%83%E4%B9%A0/"/>
      <url>/2022/12/21/VGG%E5%AE%9E%E8%B7%B5%E7%BB%83%E4%B9%A0/</url>
      
        <content type="html"><![CDATA[<h1 id="VGG实践练习"><a href="#VGG实践练习" class="headerlink" title="VGG实践练习"></a>VGG实践练习</h1><p>#代码部分</p><h3 id="model-py"><a href="#model-py" class="headerlink" title="model.py"></a>model.py</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"><span class="comment"># 官方权重下载地址</span></span><br><span class="line">model_urls = &#123;</span><br><span class="line">    <span class="string">&#x27;vgg11&#x27;</span>: <span class="string">&#x27;https://download.pytorch.org/models/vgg11-bbd30ac9.pth&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;vgg13&#x27;</span>: <span class="string">&#x27;https://download.pytorch.org/models/vgg13-c768596a.pth&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;vgg16&#x27;</span>: <span class="string">&#x27;https://download.pytorch.org/models/vgg16-397923af.pth&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;vgg19&#x27;</span>: <span class="string">&#x27;https://download.pytorch.org/models/vgg19-dcbb9e9d.pth&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">VGG</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, features, num_classes=<span class="number">1000</span>, init_weights=<span class="literal">False</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(VGG, self).__init__()</span><br><span class="line">        self.features = features<span class="comment"># 卷积层提取特征</span></span><br><span class="line">        self.classifier = nn.Sequential(<span class="comment"># 全连接层进行分类</span></span><br><span class="line">            nn.Dropout(p=<span class="number">0.5</span>),<span class="comment">#随机失活0.5减少过拟合</span></span><br><span class="line">            nn.Linear(<span class="number">512</span>*<span class="number">7</span>*<span class="number">7</span>, <span class="number">2048</span>),<span class="comment">#全连接层 注：这里用2048的原因是示例减少跑到数量</span></span><br><span class="line">            nn.ReLU(<span class="literal">True</span>),<span class="comment">#Relu激活函数</span></span><br><span class="line">            nn.Dropout(p=<span class="number">0.5</span>),<span class="comment">#随机失活0.5减少过拟合</span></span><br><span class="line">            nn.Linear(<span class="number">2048</span>, <span class="number">2048</span>),<span class="comment">#全连接层</span></span><br><span class="line">            nn.ReLU(<span class="literal">True</span>),<span class="comment">#Relu激活函数</span></span><br><span class="line">            nn.Linear(<span class="number">2048</span>, num_classes)<span class="comment">#全连接层</span></span><br><span class="line">            <span class="comment"># #原版本</span></span><br><span class="line">            <span class="comment"># nn.Dropout(p=0.5),  # 随机失活0.5减少过拟合</span></span><br><span class="line">            <span class="comment"># nn.Linear(512 * 7 * 7, 4096),  # 全连接层</span></span><br><span class="line">            <span class="comment"># nn.ReLU(True),  # Relu激活函数</span></span><br><span class="line">            <span class="comment"># nn.Dropout(p=0.5),  # 随机失活0.5减少过拟合</span></span><br><span class="line">            <span class="comment"># nn.Linear(4096, 40968),  # 全连接层</span></span><br><span class="line">            <span class="comment"># nn.ReLU(True),  # Relu激活函数</span></span><br><span class="line">            <span class="comment"># nn.Linear(4096, num_classes)</span></span><br><span class="line">            <span class="comment"># # 全连接层</span></span><br><span class="line">        )</span><br><span class="line">        <span class="keyword">if</span> init_weights:</span><br><span class="line">            self._initialize_weights()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="comment"># N x 3 x 224 x 224</span></span><br><span class="line">        x = self.features(x)</span><br><span class="line">        <span class="comment"># N x 512 x 7 x 7</span></span><br><span class="line">        x = torch.flatten(x, start_dim=<span class="number">1</span>)<span class="comment">#展平处理</span></span><br><span class="line">        <span class="comment"># N x 512*7*7</span></span><br><span class="line">        x = self.classifier(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"><span class="comment">#初始化函数</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_initialize_weights</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">for</span> m <span class="keyword">in</span> self.modules():</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">isinstance</span>(m, nn.Conv2d):</span><br><span class="line">                <span class="comment"># nn.init.kaiming_normal_(m.weight, mode=&#x27;fan_out&#x27;, nonlinearity=&#x27;relu&#x27;)</span></span><br><span class="line">                nn.init.xavier_uniform_(m.weight)</span><br><span class="line">                <span class="keyword">if</span> m.bias <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                    nn.init.constant_(m.bias, <span class="number">0</span>)<span class="comment">#初始化偏置为0</span></span><br><span class="line">            <span class="keyword">elif</span> <span class="built_in">isinstance</span>(m, nn.Linear):</span><br><span class="line">                nn.init.xavier_uniform_(m.weight)</span><br><span class="line">                <span class="comment"># nn.init.normal_(m.weight, 0, 0.01)</span></span><br><span class="line">                nn.init.constant_(m.bias, <span class="number">0</span>)<span class="comment">#初始化偏置为0</span></span><br><span class="line"><span class="comment">#定义层</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">make_features</span>(<span class="params">cfg: <span class="built_in">list</span></span>):<span class="comment">#传入变量</span></span><br><span class="line">    layers = []</span><br><span class="line">    in_channels = <span class="number">3</span></span><br><span class="line">    <span class="keyword">for</span> v <span class="keyword">in</span> cfg:</span><br><span class="line">        <span class="keyword">if</span> v == <span class="string">&quot;M&quot;</span>:</span><br><span class="line">            layers += [nn.MaxPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>)]<span class="comment">#池化层</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            conv2d = nn.Conv2d(in_channels, v, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">            layers += [conv2d, nn.ReLU(<span class="literal">True</span>)]<span class="comment">#ReLu函数</span></span><br><span class="line">            in_channels = v<span class="comment">#深度更新</span></span><br><span class="line">    <span class="keyword">return</span> nn.Sequential(*layers)<span class="comment">#以元组（非关键字参数）传入</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># vgg网络模型配置列表（字典），数字表示卷积核个数，&#x27;M&#x27;表示最大池化层</span></span><br><span class="line">cfgs = &#123;</span><br><span class="line">    <span class="string">&#x27;vgg11&#x27;</span>: [<span class="number">64</span>, <span class="string">&#x27;M&#x27;</span>, <span class="number">128</span>, <span class="string">&#x27;M&#x27;</span>, <span class="number">256</span>, <span class="number">256</span>, <span class="string">&#x27;M&#x27;</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="string">&#x27;M&#x27;</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="string">&#x27;M&#x27;</span>],<span class="comment"># 模型A</span></span><br><span class="line">    <span class="string">&#x27;vgg13&#x27;</span>: [<span class="number">64</span>, <span class="number">64</span>, <span class="string">&#x27;M&#x27;</span>, <span class="number">128</span>, <span class="number">128</span>, <span class="string">&#x27;M&#x27;</span>, <span class="number">256</span>, <span class="number">256</span>, <span class="string">&#x27;M&#x27;</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="string">&#x27;M&#x27;</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="string">&#x27;M&#x27;</span>],<span class="comment"># 模型B</span></span><br><span class="line">    <span class="string">&#x27;vgg16&#x27;</span>: [<span class="number">64</span>, <span class="number">64</span>, <span class="string">&#x27;M&#x27;</span>, <span class="number">128</span>, <span class="number">128</span>, <span class="string">&#x27;M&#x27;</span>, <span class="number">256</span>, <span class="number">256</span>, <span class="number">256</span>, <span class="string">&#x27;M&#x27;</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="string">&#x27;M&#x27;</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="string">&#x27;M&#x27;</span>],<span class="comment"># 模型D</span></span><br><span class="line">    <span class="string">&#x27;vgg19&#x27;</span>: [<span class="number">64</span>, <span class="number">64</span>, <span class="string">&#x27;M&#x27;</span>, <span class="number">128</span>, <span class="number">128</span>, <span class="string">&#x27;M&#x27;</span>, <span class="number">256</span>, <span class="number">256</span>, <span class="number">256</span>, <span class="number">256</span>, <span class="string">&#x27;M&#x27;</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="string">&#x27;M&#x27;</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="string">&#x27;M&#x27;</span>], <span class="comment"># 模型E</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 卷积层提取特征</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">make_features</span>(<span class="params">cfg: <span class="built_in">list</span></span>): <span class="comment"># 传入的是具体某个模型的参数列表</span></span><br><span class="line">    layers = []</span><br><span class="line">    in_channels = <span class="number">3</span><span class="comment"># 输入的原始图像(rgb三通道)</span></span><br><span class="line">    <span class="keyword">for</span> v <span class="keyword">in</span> cfg:</span><br><span class="line">        <span class="comment"># 最大池化层</span></span><br><span class="line">        <span class="keyword">if</span> v == <span class="string">&quot;M&quot;</span>:</span><br><span class="line">            layers += [nn.MaxPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>)]</span><br><span class="line">        <span class="comment"># 卷积层</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            conv2d = nn.Conv2d(in_channels, v, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">            layers += [conv2d, nn.ReLU(<span class="literal">True</span>)]</span><br><span class="line">            in_channels = v</span><br><span class="line">    <span class="keyword">return</span> nn.Sequential(*layers)  <span class="comment"># 单星号(*)将参数以元组(tuple)的形式导入</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">vgg</span>(<span class="params">model_name=<span class="string">&quot;vgg16&quot;</span>, **kwargs</span>):  <span class="comment"># 双星号(**)将参数以字典的形式导入</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        cfg = cfgs[model_name]</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Warning: model number &#123;&#125; not in cfgs dict!&quot;</span>.<span class="built_in">format</span>(model_name))</span><br><span class="line">        exit(-<span class="number">1</span>)</span><br><span class="line">    model = VGG(make_features(cfg), **kwargs)</span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="train-py"><a href="#train-py" class="headerlink" title="train.py"></a>train.py</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> model <span class="keyword">import</span> vgg</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    device = torch.device(<span class="string">&quot;cuda:0&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br><span class="line"></span><br><span class="line">    data_transform = transforms.Compose(</span><br><span class="line">        [transforms.Resize((<span class="number">224</span>, <span class="number">224</span>)),</span><br><span class="line">         transforms.ToTensor(),</span><br><span class="line">         transforms.Normalize((<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>), (<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>))])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># load image</span></span><br><span class="line">    img_path = <span class="string">&quot;totest.jpg&quot;</span></span><br><span class="line">    <span class="keyword">assert</span> os.path.exists(img_path), <span class="string">&quot;file: &#x27;&#123;&#125;&#x27; dose not exist.&quot;</span>.<span class="built_in">format</span>(img_path)</span><br><span class="line">    img = Image.<span class="built_in">open</span>(img_path)</span><br><span class="line">    plt.imshow(img)</span><br><span class="line">    <span class="comment"># [N, C, H, W]</span></span><br><span class="line">    img = data_transform(img)</span><br><span class="line">    <span class="comment"># expand batch dimension</span></span><br><span class="line">    img = torch.unsqueeze(img, dim=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># read class_indict</span></span><br><span class="line">    json_path = <span class="string">&#x27;./class_indices.json&#x27;</span></span><br><span class="line">    <span class="keyword">assert</span> os.path.exists(json_path), <span class="string">&quot;file: &#x27;&#123;&#125;&#x27; dose not exist.&quot;</span>.<span class="built_in">format</span>(json_path)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(json_path, <span class="string">&quot;r&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        class_indict = json.load(f)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># create model</span></span><br><span class="line">    model = vgg(model_name=<span class="string">&quot;vgg16&quot;</span>, num_classes=<span class="number">5</span>).to(device)</span><br><span class="line">    <span class="comment"># load model weights</span></span><br><span class="line">    weights_path = <span class="string">&quot;./vgg16Net.pth&quot;</span></span><br><span class="line">    <span class="keyword">assert</span> os.path.exists(weights_path), <span class="string">&quot;file: &#x27;&#123;&#125;&#x27; dose not exist.&quot;</span>.<span class="built_in">format</span>(weights_path)</span><br><span class="line">    model.load_state_dict(torch.load(weights_path, map_location=device))</span><br><span class="line"></span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="comment"># predict class</span></span><br><span class="line">        output = torch.squeeze(model(img.to(device))).cpu()</span><br><span class="line">        predict = torch.softmax(output, dim=<span class="number">0</span>)</span><br><span class="line">        predict_cla = torch.argmax(predict).numpy()</span><br><span class="line">    <span class="comment">#此处为预测输出多种可能</span></span><br><span class="line">    print_res = <span class="string">&quot;class: &#123;&#125;   prob: &#123;:.3&#125;&quot;</span>.<span class="built_in">format</span>(class_indict[<span class="built_in">str</span>(predict_cla)],</span><br><span class="line">                                                 predict[predict_cla].numpy())</span><br><span class="line">    plt.title(print_res)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;可能性为：&quot;</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(predict)):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;class: &#123;:10&#125;   prob: &#123;:.3&#125;&quot;</span>.<span class="built_in">format</span>(class_indict[<span class="built_in">str</span>(i)],</span><br><span class="line">                                                  predict[i].numpy()))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;最大可能为：&quot;</span>,class_indict[<span class="built_in">str</span>(predict_cla)], predict[predict_cla].item())<span class="comment">#输出最大可能</span></span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    main()</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="predict-py"><a href="#predict-py" class="headerlink" title="predict,py"></a>predict,py</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms, datasets</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> model <span class="keyword">import</span> vgg</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    device = torch.device(<span class="string">&quot;cuda:0&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;using &#123;&#125; device.&quot;</span>.<span class="built_in">format</span>(device))</span><br><span class="line"><span class="comment">#数据集预处理</span></span><br><span class="line">    data_transform = &#123;</span><br><span class="line">        <span class="string">&quot;train&quot;</span>: transforms.Compose([transforms.RandomResizedCrop(<span class="number">224</span>),</span><br><span class="line">                                     transforms.RandomHorizontalFlip(),</span><br><span class="line">                                     transforms.ToTensor(),</span><br><span class="line">                                     transforms.Normalize((<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>), (<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>))]),</span><br><span class="line">        <span class="string">&quot;val&quot;</span>: transforms.Compose([transforms.Resize((<span class="number">224</span>, <span class="number">224</span>)),</span><br><span class="line">                                   transforms.ToTensor(),</span><br><span class="line">                                   transforms.Normalize((<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>), (<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>))])&#125;</span><br><span class="line"></span><br><span class="line">    data_root = os.path.abspath(os.path.join(os.getcwd(), <span class="string">&quot;../..&quot;</span>))  <span class="comment"># get data root path</span></span><br><span class="line">    image_path = os.path.join(data_root, <span class="string">&quot;data_set&quot;</span>, <span class="string">&quot;flower_data&quot;</span>)  <span class="comment"># flower data set path</span></span><br><span class="line">    <span class="keyword">assert</span> os.path.exists(image_path), <span class="string">&quot;&#123;&#125; path does not exist.&quot;</span>.<span class="built_in">format</span>(image_path)</span><br><span class="line">    train_dataset = datasets.ImageFolder(root=os.path.join(image_path, <span class="string">&quot;train&quot;</span>),</span><br><span class="line">                                         transform=data_transform[<span class="string">&quot;train&quot;</span>])</span><br><span class="line">    train_num = <span class="built_in">len</span>(train_dataset)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># &#123;&#x27;daisy&#x27;:0, &#x27;dandelion&#x27;:1, &#x27;roses&#x27;:2, &#x27;sunflower&#x27;:3, &#x27;tulips&#x27;:4&#125;</span></span><br><span class="line">    flower_list = train_dataset.class_to_idx</span><br><span class="line">    cla_dict = <span class="built_in">dict</span>((val, key) <span class="keyword">for</span> key, val <span class="keyword">in</span> flower_list.items())</span><br><span class="line">    <span class="comment"># write dict into json file</span></span><br><span class="line">    json_str = json.dumps(cla_dict, indent=<span class="number">4</span>)</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;class_indices.json&#x27;</span>, <span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> json_file:</span><br><span class="line">        json_file.write(json_str)</span><br><span class="line"></span><br><span class="line">    batch_size = <span class="number">32</span></span><br><span class="line">    nw = <span class="built_in">min</span>([os.cpu_count(), batch_size <span class="keyword">if</span> batch_size &gt; <span class="number">1</span> <span class="keyword">else</span> <span class="number">0</span>, <span class="number">8</span>])  <span class="comment"># number of workers</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Using &#123;&#125; dataloader workers every process&#x27;</span>.<span class="built_in">format</span>(nw))</span><br><span class="line"></span><br><span class="line">    train_loader = torch.utils.data.DataLoader(train_dataset,</span><br><span class="line">                                               batch_size=batch_size, shuffle=<span class="literal">True</span>,</span><br><span class="line">                                               num_workers=nw)</span><br><span class="line"></span><br><span class="line">    validate_dataset = datasets.ImageFolder(root=os.path.join(image_path, <span class="string">&quot;val&quot;</span>),</span><br><span class="line">                                            transform=data_transform[<span class="string">&quot;val&quot;</span>])</span><br><span class="line">    val_num = <span class="built_in">len</span>(validate_dataset)</span><br><span class="line">    validate_loader = torch.utils.data.DataLoader(validate_dataset,</span><br><span class="line">                                                  batch_size=batch_size, shuffle=<span class="literal">False</span>,</span><br><span class="line">                                                  num_workers=nw)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;using &#123;&#125; images for training, &#123;&#125; images for validation.&quot;</span>.<span class="built_in">format</span>(train_num,</span><br><span class="line">                                                                           val_num))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># test_data_iter = iter(validate_loader)</span></span><br><span class="line">    <span class="comment"># test_image, test_label = test_data_iter.next()</span></span><br><span class="line"><span class="comment">#实例化网络</span></span><br><span class="line">    model_name = <span class="string">&quot;vgg16&quot;</span></span><br><span class="line">    net = vgg(model_name=model_name, num_classes=<span class="number">5</span>, init_weights=<span class="literal">True</span>)</span><br><span class="line">    net.to(device)</span><br><span class="line">    loss_function = nn.CrossEntropyLoss()</span><br><span class="line">    optimizer = optim.Adam(net.parameters(), lr=<span class="number">0.0001</span>)</span><br><span class="line"></span><br><span class="line">    epochs = <span class="number">30</span></span><br><span class="line">    best_acc = <span class="number">0.0</span></span><br><span class="line">    save_path = <span class="string">&#x27;./&#123;&#125;Net.pth&#x27;</span>.<span class="built_in">format</span>(model_name)<span class="comment">#保存路径</span></span><br><span class="line">    train_steps = <span class="built_in">len</span>(train_loader)</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(epochs):</span><br><span class="line">        <span class="comment"># train</span></span><br><span class="line">        net.train()</span><br><span class="line">        running_loss = <span class="number">0.0</span></span><br><span class="line">        train_bar = tqdm(train_loader, file=sys.stdout)</span><br><span class="line">        <span class="keyword">for</span> step, data <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_bar):</span><br><span class="line">            images, labels = data</span><br><span class="line">            optimizer.zero_grad()<span class="comment">#清空梯度</span></span><br><span class="line">            outputs = net(images.to(device))<span class="comment">#正向传播</span></span><br><span class="line">            loss = loss_function(outputs, labels.to(device))<span class="comment">#代价函数</span></span><br><span class="line">            loss.backward()<span class="comment">#反向传播</span></span><br><span class="line">            optimizer.step()<span class="comment"># 优化器更新参数</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># 打印进度</span></span><br><span class="line">            running_loss += loss.item()</span><br><span class="line"></span><br><span class="line">            train_bar.desc = <span class="string">&quot;train epoch[&#123;&#125;/&#123;&#125;] loss:&#123;:.3f&#125;&quot;</span>.<span class="built_in">format</span>(epoch + <span class="number">1</span>,</span><br><span class="line">                                                                     epochs,</span><br><span class="line">                                                                     loss)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 验证</span></span><br><span class="line">        net.<span class="built_in">eval</span>()<span class="comment"># 验证过程中关闭 Dropout</span></span><br><span class="line">        acc = <span class="number">0.0</span>  <span class="comment"># accumulate accurate number / epoch</span></span><br><span class="line">        <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">            val_bar = tqdm(validate_loader, file=sys.stdout)</span><br><span class="line">            <span class="keyword">for</span> val_data <span class="keyword">in</span> val_bar:</span><br><span class="line">                val_images, val_labels = val_data</span><br><span class="line">                outputs = net(val_images.to(device))</span><br><span class="line">                predict_y = torch.<span class="built_in">max</span>(outputs, dim=<span class="number">1</span>)[<span class="number">1</span>]<span class="comment"># 以output中值最大位置对应的索引（标签）作为预测输出</span></span><br><span class="line">                acc += torch.eq(predict_y, val_labels.to(device)).<span class="built_in">sum</span>().item()<span class="comment">#预测正确个数统计</span></span><br><span class="line"></span><br><span class="line">        val_accurate = acc / val_num<span class="comment">#计算准确率</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;[epoch %d] train_loss: %.3f  val_accuracy: %.3f&#x27;</span> %</span><br><span class="line">              (epoch + <span class="number">1</span>, running_loss / train_steps, val_accurate))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> val_accurate &gt; best_acc:</span><br><span class="line">            best_acc = val_accurate</span><br><span class="line">            torch.save(net.state_dict(), save_path)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Finished Training&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    main()</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="知识点"><a href="#知识点" class="headerlink" title="知识点"></a>知识点</h2><h3 id="model-py-1"><a href="#model-py-1" class="headerlink" title="model.py"></a>model.py</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#定义层</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">make_features</span>(<span class="params">cfg: <span class="built_in">list</span></span>):<span class="comment">#传入变量</span></span><br><span class="line">    layers = []</span><br><span class="line">    in_channels = <span class="number">3</span></span><br><span class="line">    <span class="keyword">for</span> v <span class="keyword">in</span> cfg:</span><br><span class="line">        <span class="keyword">if</span> v == <span class="string">&quot;M&quot;</span>:</span><br><span class="line">            layers += [nn.MaxPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>)]<span class="comment">#池化层</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            conv2d = nn.Conv2d(in_channels, v, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">            layers += [conv2d, nn.ReLU(<span class="literal">True</span>)]<span class="comment">#ReLu函数</span></span><br><span class="line">            in_channels = v<span class="comment">#深度更新</span></span><br><span class="line">    <span class="keyword">return</span> nn.Sequential(*layers)<span class="comment">#以元组（非关键字参数）传入</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># vgg网络模型配置列表（字典），数字表示卷积核个数，&#x27;M&#x27;表示最大池化层</span></span><br><span class="line">cfgs = &#123;</span><br><span class="line">    <span class="string">&#x27;vgg11&#x27;</span>: [<span class="number">64</span>, <span class="string">&#x27;M&#x27;</span>, <span class="number">128</span>, <span class="string">&#x27;M&#x27;</span>, <span class="number">256</span>, <span class="number">256</span>, <span class="string">&#x27;M&#x27;</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="string">&#x27;M&#x27;</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="string">&#x27;M&#x27;</span>],<span class="comment"># 模型A</span></span><br><span class="line">    <span class="string">&#x27;vgg13&#x27;</span>: [<span class="number">64</span>, <span class="number">64</span>, <span class="string">&#x27;M&#x27;</span>, <span class="number">128</span>, <span class="number">128</span>, <span class="string">&#x27;M&#x27;</span>, <span class="number">256</span>, <span class="number">256</span>, <span class="string">&#x27;M&#x27;</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="string">&#x27;M&#x27;</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="string">&#x27;M&#x27;</span>],<span class="comment"># 模型B</span></span><br><span class="line">    <span class="string">&#x27;vgg16&#x27;</span>: [<span class="number">64</span>, <span class="number">64</span>, <span class="string">&#x27;M&#x27;</span>, <span class="number">128</span>, <span class="number">128</span>, <span class="string">&#x27;M&#x27;</span>, <span class="number">256</span>, <span class="number">256</span>, <span class="number">256</span>, <span class="string">&#x27;M&#x27;</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="string">&#x27;M&#x27;</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="string">&#x27;M&#x27;</span>],<span class="comment"># 模型D</span></span><br><span class="line">    <span class="string">&#x27;vgg19&#x27;</span>: [<span class="number">64</span>, <span class="number">64</span>, <span class="string">&#x27;M&#x27;</span>, <span class="number">128</span>, <span class="number">128</span>, <span class="string">&#x27;M&#x27;</span>, <span class="number">256</span>, <span class="number">256</span>, <span class="number">256</span>, <span class="number">256</span>, <span class="string">&#x27;M&#x27;</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="string">&#x27;M&#x27;</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="string">&#x27;M&#x27;</span>], <span class="comment"># 模型E</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li><p>利用字典<strong>批量定义层</strong></p></li><li><p><strong>并使用make_features进行定义</strong></p></li></ul><h3 id="train-py函数调用"><a href="#train-py函数调用" class="headerlink" title="train.py函数调用"></a>train.py函数调用</h3><p>训练脚本与AlexNet基本一致，需要注意的是实例化网络的过程：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">model_name = <span class="string">&quot;vgg16&quot;</span></span><br><span class="line">net = vgg(model_name=model_name, num_classes=<span class="number">5</span>, init_weights=<span class="literal">True</span>)</span><br><span class="line"><span class="number">12</span></span><br></pre></td></tr></table></figure><p>函数调用关系：</p><p><img src="https://s2.loli.net/2022/12/21/Uxk6fRPKEXGmJVc.png"></p><ul><li>注：VGG网络模型较深，需要使用GPU进行训练(而且要内存大一点的GPU，显存过小（小于2G），pytorch会报错GPU内存不足)</li></ul><h2 id="遇到问题以及解决方法"><a href="#遇到问题以及解决方法" class="headerlink" title="遇到问题以及解决方法"></a>遇到问题以及解决方法</h2><ul><li><p>与AlexNet差不多</p></li><li><p>如果你的显存不过请<strong>降低batch和epoch以及model中全连接节点数</strong>试一试</p></li></ul>]]></content>
      
      
      <categories>
          
          <category> 学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 人工智能 </tag>
            
            <tag> VGG </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>VGG-1</title>
      <link href="/2022/12/21/VGG%E7%BB%93%E6%9E%84%E7%90%86%E8%AE%BA/"/>
      <url>/2022/12/21/VGG%E7%BB%93%E6%9E%84%E7%90%86%E8%AE%BA/</url>
      
        <content type="html"><![CDATA[<h1 id="VGG理论结构"><a href="#VGG理论结构" class="headerlink" title="VGG理论结构"></a>VGG理论结构</h1><h1 id="VGG详解"><a href="#VGG详解" class="headerlink" title="VGG详解"></a>VGG详解</h1><p>VGG 在2014年由牛津大学著名研究组 <strong>VGG</strong>（<strong>Visual Geometry Group</strong>）提出，斩获该年 ImageNet 竞赛中 Localization Task（定位任务）第一名和 Classification Task（分类任务）第二名。<br>原论文地址：<a href="https://arxiv.org/abs/1409.1556">Very Deep Convolutional Networks for Large-Scale Image Recognition</a></p><p>VGG网络的创新点：通过堆叠多个小卷积核来替代大尺度卷积核，可以减少训练参数，同时能保证相同的感受野。<br>论文中提到，可以通过堆叠两个3×3的卷积核替代5x5的卷积核，堆叠三个3×3的卷积核替代7x7的卷积核。</p><h2 id="CNN感受野"><a href="#CNN感受野" class="headerlink" title="CNN感受野"></a>CNN感受野</h2><p>在卷积神经网络中，决定某一层输出结果中一个元素所对应的输入层的区域大小，被称作<strong>感受野</strong>（<strong>receptive field</strong>）。<br>通俗的解释是，<strong>输出feature map上的一个单元 对应 输入层上的区域大小。</strong></p><p>以下图为例，输出层 layer3 中一个单元 对应 输入层 layer2 上区域大小为2×2（池化操作），对应输入层 layer1 上大小为5×5<br>（可以这么理解，layer2中 2×2区域中的每一块对应一个3×3的卷积核，又因为 stride&#x3D;2，所以layer1的感受野为5×5）<br><img src="https://s2.loli.net/2022/12/16/hPRJXLiv3KqM6eF.png" alt="在这里插入图片描述"><br>感受野的计算公式为：<br>                                                        F(i)&#x3D;(F(i+1)−1)×Stride +Ksize</p><ul><li>F(i) 为第 i 层感受野</li><li>Stride 为第 i 层的步距</li><li>Ksize 为 卷积核 或 池化核 尺寸</li></ul><p>即为：下层感受野&#x3D;（上层感受野-1）*步距+卷积核尺寸</p><p>以上图为例：</p><ul><li>Feature map: F ( 3 ) &#x3D; 1 </li><li>Pool1：F ( 2 ) &#x3D; ( 1 − 1 ) × 2 + 2 &#x3D; 2 </li><li>Conv1: F ( 1 ) &#x3D; ( 2 − 1 ) × 2 + 3 &#x3D; 5</li></ul><h2 id="小卷积核"><a href="#小卷积核" class="headerlink" title="小卷积核"></a>小卷积核</h2><p>现在，我们来验证下VGG论文中的两点结论：</p><p><strong>1.堆叠两个3×3的卷积核替代5x5的卷积核，堆叠三个3×3的卷积核替代7x7的卷积核。替代前后感受野是否相同？</strong></p><p>（注：VGG网络中卷积的Stride默认为1）</p><ul><li>Feature map: F &#x3D; 1 F&#x3D;1F&#x3D;1</li><li>Conv3x3(3): F &#x3D; ( 1 − 1 ) × 1 + 3 &#x3D; 3 </li><li>Conv3x3(2): F &#x3D; ( 3 − 1 ) × 1 + 3 &#x3D; 5  （5×5卷积核感受野）</li><li>Conv3x3(1): F &#x3D; ( 5 − 1 ) × 1 + 3 &#x3D; 7 （7×7卷积核感受野）</li></ul><p><strong>2.堆叠3×3卷积核后训练参数是否真的减少了？</strong></p><p>注：CNN参数个数 &#x3D; 卷积核尺寸×卷积核深度 × 卷积核组数 &#x3D; 卷积核尺寸 × <strong>输入特征矩阵深度</strong> × <strong>输出特征矩阵深度</strong><br>现假设 输入特征矩阵深度 &#x3D; 输出特征矩阵深度 &#x3D; C</p><ul><li>使用7×7卷积核所需参数个数：$ 7×7×C×C&#x3D;49C^2$</li><li>堆叠三个3×3的卷积核所需参数个数：$3×3×C×C+3×3×C×C+3×3×C×C&#x3D;27C^2$</li></ul><h2 id="VGG-16"><a href="#VGG-16" class="headerlink" title="VGG-16"></a>VGG-16</h2><p>VGG网络有多个版本，一般常用的是VGG-16模型，其网络结构如下如所示：<br><img src="https://s2.loli.net/2022/12/16/QAdOBTv2oz9LFpl.png" alt="在这里插入图片描述"></p><p><strong>图中是针对D层来写的</strong></p><p>稍作计算可以发现，经3×3卷积的特征矩阵的尺寸是不改变的：</p><p><img src="https://s2.loli.net/2022/12/16/s9JAebzyhDXWHIa.png"></p><p><img src="https://s2.loli.net/2022/12/21/2RlUiSzkmNHcv7j.png" alt="在这里插入图片描述"></p><p>VGG-16网络，<strong>其参数多达1亿3千万，模型更加复杂一些</strong>，一般情况下，其CONV layer和POOL layer设置如下：</p><ul><li>CONV &#x3D; 3×3 filters, s &#x3D; 1, same</li><li>MAX-POOL &#x3D; 2×2, s &#x3D; 2</li></ul><p><img src="https://img-blog.csdnimg.cn/20200423121435776.png#pic_center" alt="在这里插入图片描述"></p>]]></content>
      
      
      <categories>
          
          <category> 学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 人工智能 </tag>
            
            <tag> VGG </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>5G网络频谱划分预备知识-1</title>
      <link href="/2022/12/21/5G%E7%BD%91%E7%BB%9C%E9%A2%91%E8%B0%B1%E5%88%92%E5%88%86%E9%A2%84%E5%A4%87%E7%9F%A5%E8%AF%86/"/>
      <url>/2022/12/21/5G%E7%BD%91%E7%BB%9C%E9%A2%91%E8%B0%B1%E5%88%92%E5%88%86%E9%A2%84%E5%A4%87%E7%9F%A5%E8%AF%86/</url>
      
        <content type="html"><![CDATA[<h1 id="预备知识"><a href="#预备知识" class="headerlink" title="预备知识"></a>预备知识</h1><h2 id="名词汇总"><a href="#名词汇总" class="headerlink" title="名词汇总"></a>名词汇总</h2><h3 id="5G的业务类型"><a href="#5G的业务类型" class="headerlink" title="5G的业务类型"></a>5G的业务类型</h3><table><thead><tr><th>名词</th><th>定义</th></tr></thead><tbody><tr><td>eMBB</td><td>增强型移动宽带，就是现有4G网络的升级版，要求传输速率大于1Gbps</td></tr><tr><td>URLLC</td><td>超可靠低时延通信，适用于无人驾驶，远程手术等场景，要求传输时延小于1ms</td></tr><tr><td>mMTC</td><td>海量机器类通信，适用于物联网，要求每平方公里有100万个连接</td></tr></tbody></table><h3 id="5G网络工作频段与带宽"><a href="#5G网络工作频段与带宽" class="headerlink" title="5G网络工作频段与带宽"></a>5G网络工作频段与带宽</h3><table><thead><tr><th>名词</th><th>定义</th></tr></thead><tbody><tr><td>UL</td><td>up link 上行</td></tr><tr><td>DL</td><td>down link 下行</td></tr><tr><td>FDD</td><td>频分双工</td></tr><tr><td>TDD</td><td>时分双工</td></tr><tr><td>SUL</td><td>Uplink Supplementary Bands 上行辅助频段</td></tr><tr><td>SDL</td><td>Downlink Supplementary Bands 下行辅助频段</td></tr><tr><td>SCS</td><td>sub-carrier space，子载波间隔</td></tr><tr><td>RB</td><td>resource block，资源块，频率上连续12个子载波，时域上一个slot，称为1个RB</td></tr><tr><td>SSB</td><td>Synchronization Signal and PBCH block， 同步信号和PBCH块</td></tr></tbody></table><h3 id="5G频谱划分及应用"><a href="#5G频谱划分及应用" class="headerlink" title="5G频谱划分及应用"></a>5G频谱划分及应用</h3><table><thead><tr><th>名词</th><th>定义</th></tr></thead><tbody><tr><td>NB</td><td>Narrow Band 窄带</td></tr><tr><td>NB-IoT</td><td>Narrow Band Internet of Things 蜂窝窄带物联网</td></tr><tr><td>DCS1800</td><td>1800MHz数字蜂窝系统</td></tr><tr><td>RRU</td><td>Remote Radio Unit 射频拉远单元</td></tr><tr><td>RSRP</td><td>Reference Signal Receiving Power 参考信号接收功率</td></tr></tbody></table><h2 id="二、5G网络工作频段"><a href="#二、5G网络工作频段" class="headerlink" title="二、5G网络工作频段"></a>二、5G网络工作频段</h2><h3 id="5G总频段"><a href="#5G总频段" class="headerlink" title="5G总频段"></a>5G总频段</h3><table><thead><tr><th>指定频段</th><th>对应频率范围</th></tr></thead><tbody><tr><td>FR1</td><td>450 MHz - 7125 MHz</td></tr><tr><td>FR2</td><td>24250 MHz - 52600 MHz</td></tr></tbody></table><h3 id="FR1部分对应频段"><a href="#FR1部分对应频段" class="headerlink" title="FR1部分对应频段"></a>FR1部分对应频段</h3><table><thead><tr><th>频段号</th><th>上行频段</th><th>下行频段</th><th>双工模式</th></tr></thead><tbody><tr><td>n1</td><td>1920MHz-1980MHz</td><td>2110MHz-2170MHz</td><td>频分双工</td></tr><tr><td>n2</td><td>1850MHz-1910MHz</td><td>1930MHz-1990MHz</td><td>频分双工</td></tr><tr><td>n29</td><td>N&#x2F;A</td><td>717MHz-728MHz</td><td>下行辅助频段</td></tr><tr><td>n41</td><td>2496MHz-2690MHz</td><td>2496MHz-2690MHz</td><td>时分双工</td></tr><tr><td>n77</td><td>3300MHz-4200MHz</td><td>3300MHz-4200MHz</td><td>时分双工</td></tr><tr><td>n78</td><td>3300MHz-3800MHz</td><td>3300MHz-3800MHz</td><td>时分双工</td></tr><tr><td>n79</td><td>4400MHz-5000MHz</td><td>4400MHz-5000MHz</td><td>时分双工</td></tr><tr><td>n98</td><td>1880MHz-1920MHz</td><td>N&#x2F;A</td><td>上行辅助频段</td></tr></tbody></table><h3 id="FR2部分对应频段"><a href="#FR2部分对应频段" class="headerlink" title="FR2部分对应频段"></a>FR2部分对应频段</h3><table><thead><tr><th>频段号</th><th>上行频段</th><th>下行频段</th><th>双工模式</th></tr></thead><tbody><tr><td>n257</td><td>26500MHz-29500MHz</td><td>26500MHz-29500MHz</td><td>时分双工</td></tr><tr><td>n258</td><td>24250MHz-27500MHz</td><td>24250MHz-27500MHz</td><td>时分双工</td></tr></tbody></table><h2 id="5G网络信道带宽"><a href="#5G网络信道带宽" class="headerlink" title="5G网络信道带宽"></a>5G网络信道带宽</h2><h3 id="信道带宽，保护带宽和传输带宽"><a href="#信道带宽，保护带宽和传输带宽" class="headerlink" title="信道带宽，保护带宽和传输带宽"></a>信道带宽，保护带宽和传输带宽</h3><p><img src="https://s2.loli.net/2022/12/21/kAUWf5ZF9zOMwP3.png" alt="在这里插入图片描述"></p><h3 id="FR1最大传输带宽配置"><a href="#FR1最大传输带宽配置" class="headerlink" title="FR1最大传输带宽配置"></a>FR1最大传输带宽配置</h3><p><img src="https://s2.loli.net/2022/12/21/L5F6a3ynzlOWgps.png" alt="在这里插入图片描述"><br><img src="https://s2.loli.net/2022/12/21/HgmiqxkXGFz4BVj.png" alt="在这里插入图片描述"><br><img src="https://s2.loli.net/2022/12/21/BsJrUEM1pw8LQke.png" alt="在这里插入图片描述"><br><img src="https://s2.loli.net/2022/12/21/pkzJFg4vVNACOh8.png" alt="在这里插入图片描述"><br><img src="https://s2.loli.net/2022/12/21/y6rKbmoNc2G5zxA.png" alt="在这里插入图片描述"></p><h3 id="最小保护带宽计算公式"><a href="#最小保护带宽计算公式" class="headerlink" title="最小保护带宽计算公式"></a>最小保护带宽计算公式</h3><p><img src="https://s2.loli.net/2022/12/21/J2YZM1S8zQ5yhu3.png"></p><p>注：</p><ol><li>12个子载波为一个RB。</li><li>FR2的240kHz的SCS为SSB使用。</li></ol><h2 id="四、国外5G网络工作频段"><a href="#四、国外5G网络工作频段" class="headerlink" title="四、国外5G网络工作频段"></a>四、国外5G网络工作频段</h2><p><img src="https://s2.loli.net/2022/12/21/YJvLDog1ye4iq7H.png" alt="在这里插入图片描述"><br>这是全球频谱的一个概况，但是5G的FR1频段是从400多MHz开始的，还有部分600MHz的频段并没有在表上，可能是2G&#x2F;3G&#x2F;4G的原有频段，准备更换到5G。</p><p>下面是为5G的FR2新分配的频段。</p><h3 id="北美"><a href="#北美" class="headerlink" title="北美"></a>北美</h3><table><thead><tr><th>频段</th><th>备注</th></tr></thead><tbody><tr><td>27.5GHz - 28.35GHz</td><td>授权频谱</td></tr><tr><td>37GHz - 38.6GHz</td><td>授权频谱</td></tr><tr><td>38.6GHz - 40GHz</td><td>授权频谱</td></tr><tr><td>64GHz - 71GHz</td><td>非授权频谱</td></tr></tbody></table><h3 id="欧洲"><a href="#欧洲" class="headerlink" title="欧洲"></a>欧洲</h3><table><thead><tr><th>频段</th><th>备注</th></tr></thead><tbody><tr><td>700MHz</td><td>5G广覆盖</td></tr><tr><td>3400Hz - 3800GHz</td><td>利用抢占先机</td></tr><tr><td>24.25GHz - 27.5GHz</td><td>5G先行频段</td></tr><tr><td>31.8GHz - 33.4GHz</td><td>5G潜在频段</td></tr></tbody></table><h2 id="国内5G网络工作频段"><a href="#国内5G网络工作频段" class="headerlink" title="国内5G网络工作频段"></a>国内5G网络工作频段</h2><h3 id="概况"><a href="#概况" class="headerlink" title="概况"></a>概况</h3><table><thead><tr><th>厂商</th><th>频段号</th><th>频段</th><th>带宽</th></tr></thead><tbody><tr><td>中国移动</td><td>n41</td><td>2515MHz-2675MHz</td><td>160M</td></tr><tr><td>中国电信</td><td>n78</td><td>3400MHz-3500MHz</td><td>100M</td></tr><tr><td>中国联通</td><td>n78</td><td>3500MHz-3600MHz</td><td>100M</td></tr><tr><td>中国移动（未建设）</td><td>n79</td><td>4800MHz-4900MHz</td><td>100M</td></tr></tbody></table><h3 id="中国移动频谱划分及应用"><a href="#中国移动频谱划分及应用" class="headerlink" title="中国移动频谱划分及应用"></a>中国移动频谱划分及应用</h3><p><img src="https://s2.loli.net/2022/12/21/KHwExypu198Ds7M.png" alt="在这里插入图片描述"></p><h3 id="中国移动900M频谱的演进过程"><a href="#中国移动900M频谱的演进过程" class="headerlink" title="中国移动900M频谱的演进过程"></a>中国移动900M频谱的演进过程</h3><p><img src="https://s2.loli.net/2022/12/21/Fj865YTqRN4lXnd.png" alt="在这里插入图片描述"><br>900MHz原有GSM（2G）业务，等用户更替设备之后逐渐减少2G设备，建设5G，重新利用这个频段。</p><h3 id="中国联通频谱划分及应用"><a href="#中国联通频谱划分及应用" class="headerlink" title="中国联通频谱划分及应用"></a>中国联通频谱划分及应用</h3><p><img src="https://s2.loli.net/2022/12/21/kYRpWbr5dqINKUl.png" alt="在这里插入图片描述"></p><h3 id="中国电信频谱划分及应用"><a href="#中国电信频谱划分及应用" class="headerlink" title="中国电信频谱划分及应用"></a>中国电信频谱划分及应用</h3><p><img src="https://s2.loli.net/2022/12/21/Ar7FBDJSbYfWldo.png" alt="在这里插入图片描述"></p><h3 id="中国广电频谱划分及应用"><a href="#中国广电频谱划分及应用" class="headerlink" title="中国广电频谱划分及应用"></a>中国广电频谱划分及应用</h3><p><img src="https://s2.loli.net/2022/12/21/HZr63dC8Se5nmPQ.png" alt="在这里插入图片描述"></p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul><li><a href="https://blog.csdn.net/Obs_cure/article/details/122953443">大唐杯学习笔记(2)—— 5G网络频谱划分与应用</a></li><li><a href="https://blog.csdn.net/wangkai_123456/article/details/77948540">LTE中RB、RE、CP、REG、CCE、子载波等基础概念</a></li><li><a href="https://baijiahao.baidu.com/s?id=1655333604026847789&wfr=spider&for=pc">NR 频带分类及SCS,信道带宽，传输带宽，保护带关系</a></li><li><a href="https://blog.csdn.net/qq_33206497/article/details/99209559">5G&#x2F;NR SSB学习总结</a></li><li><a href="https://www.pianshen.com/article/2874128611/">全球各地5G频谱分配情况如何？最全无线通信频率分配表</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> 学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 通信工程 </tag>
            
            <tag> 大唐杯 </tag>
            
            <tag> 5G </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>5G基站开通与调试-1</title>
      <link href="/2022/12/21/5G%E5%9F%BA%E7%AB%99%E5%BC%80%E9%80%9A%E4%B8%8E%E8%B0%83%E8%AF%95/"/>
      <url>/2022/12/21/5G%E5%9F%BA%E7%AB%99%E5%BC%80%E9%80%9A%E4%B8%8E%E8%B0%83%E8%AF%95/</url>
      
        <content type="html"><![CDATA[<h1 id="5G基站开通与调试"><a href="#5G基站开通与调试" class="headerlink" title="5G基站开通与调试"></a>5G基站开通与调试</h1><h2 id="5G网络概述"><a href="#5G网络概述" class="headerlink" title="5G网络概述"></a>5G网络概述</h2><h3 id="5G网络发展技术背景"><a href="#5G网络发展技术背景" class="headerlink" title="5G网络发展技术背景"></a>5G网络发展技术背景</h3><ul><li>2G，3G和4G技术主导应用，场景应用单一;5G应用主导技术，<strong>一个标准满足所有的应用场景。</strong></li><li>5G全<strong>面提升网络的速率</strong>、容量、<strong>可靠性</strong>和<strong>低延时</strong>，实现包括3D通信、4K+超高清视频观看、在线AR&#x2F;VR、云办公、云游戏等全新体验。此外，5G将实现物联网(IoT)，自动驾驶汽车，工业自动化，电子医疗和AR&#x2F;VR等一系列新的适用于移动互联网和物联网的应用场景</li></ul><p><img src="https://s2.loli.net/2022/12/20/baBugRMHUjoYpvW.png"></p><p><img src="https://s2.loli.net/2022/12/20/an86ulmfHbTocMV.png"></p><p><img src="https://s2.loli.net/2022/12/20/9JlY3VkXDLCwMbj.png"></p><p><img src="https://s2.loli.net/2022/12/20/9cEo7hCD3ZWyHFI.png"></p><h2 id="5G基站勘查与规划"><a href="#5G基站勘查与规划" class="headerlink" title="5G基站勘查与规划"></a>5G基站勘查与规划</h2><h3 id="5G基站勘查概述"><a href="#5G基站勘查概述" class="headerlink" title="5G基站勘查概述"></a>5G基站勘查概述</h3><p>勘查分类:根据项目的不同阶段，勘察可分为<strong>初勘（即网络规划现场勘察）</strong>和<strong>复勘（即工程设计现场勘察）</strong>两个阶段。</p><ul><li><strong>网络规划</strong>现场勘察**(初勘)**<ul><li>站点周围地形地貌</li><li>站点周围环境安装配套（电源、走线、物业)</li></ul></li><li><strong>工程设计</strong>现场勘察**(复勘)**<ul><li>站点<strong>室内</strong>&#x2F;室外的<strong>现场勘察</strong></li><li>网络数据采集工作汛房设备、天馈系统的布置方法(站高、方位角、下倾角、射频单元选型、射频功率、频段)</li></ul></li></ul><h3 id="机房内勘查"><a href="#机房内勘查" class="headerlink" title="机房内勘查"></a>机房内勘查</h3><h4 id="整体环境"><a href="#整体环境" class="headerlink" title="整体环境"></a>整体环境</h4><ul><li><strong>门窗</strong>：较好的密封防尘功能和防盗装置;机房的主要通道门高2.0m，宽1.0m，以不妨―碍设备的搬运为宜，室内净高不低于2.8m。太阳光不宜直射进机房。如果机房有窗户，必须用具备防火性能的不透明建材封闭;</li><li><strong>墙面和天花板</strong>：机房内墙面和顶棚面的面层材料，应采用光洁，耐久，不起尘，防滑，不燃烧的材料</li><li><strong>地面</strong>：机房的地面应铺设防静电地板，地板下面为混凝土基础，要求混凝土的标号大于250号，能够固定钢膨胀螺栓</li><li><strong>空调</strong>：机房内应具备空调设施，并且运行良好，满足设备正常运行;室内温度和湿度应符合工程设计要求。</li><li><strong>用电</strong>：机房引入交流市电，开关电源工作正常,机房照明系统正常，<strong>具备220V电源插座（三芯)﹔设备机房需配置-48V直流供电电源</strong>，电源容量和空开大小满足要求，蓄电池组满足设备备电时长要求。</li><li><strong>安全</strong>：监控系统、消防系统良好。机房内安装烟感告警探头，机房耐火等级为二级，机房内及其附近严禁存放易燃易爆等危险品;抗震等级按8度设防烈度考虑。</li></ul><p><img src="https://s2.loli.net/2022/12/20/fCJLkqGOz4YPFmB.png"></p><p>机柜分类：</p><ul><li>OMC机箱</li><li>核心网机箱</li><li>BBU机柜</li><li>电源柜 </li><li>传输柜</li></ul><h3 id="天面室外勘查"><a href="#天面室外勘查" class="headerlink" title="天面室外勘查"></a>天面室外勘查</h3><h4 id="天面环拍"><a href="#天面环拍" class="headerlink" title="天面环拍"></a>天面环拍</h4><p>找一个相对较高的地方，以磁北为0度，<strong>从0度开始每隔45度</strong>拍摄图片一张，相邻两张图片应该有少许交叠:</p><p><img src="https://s2.loli.net/2022/12/20/aTFhZruiU9lbJ4d.png"></p><h4 id="特殊情况"><a href="#特殊情况" class="headerlink" title="特殊情况"></a>特殊情况</h4><p>观察本基站天面或者站址周围<strong>是否有其他通信设备</strong>的天馈系统，并作出详细的记录:</p><p><img src="https://s2.loli.net/2022/12/20/qemrBJfPUTdy4VI.png"></p><h4 id="天线参数"><a href="#天线参数" class="headerlink" title="天线参数"></a>天线参数</h4><p><img src="https://s2.loli.net/2022/12/20/OXoMT9DYlk7FPbf.png"></p><h4 id="GPS时钟"><a href="#GPS时钟" class="headerlink" title="GPS时钟"></a>GPS时钟</h4><p><img src="https://s2.loli.net/2022/12/20/nMo26kAixF8VJH9.png"></p><ul><li>GPS天线需要在避雷针保护范围内(45°) </li><li>周围对天线的遮挡不超过30度，天线竖直向上的视角应大于120度</li><li>GPS 安装时远离如电梯、空调电子设备或其他电器。天线位置应当至少远离20cm的金属物体(20cm金属物体为长度×宽度&#x3D;20cm×20cm) 2米远</li><li>在塔上安装GPS天线，应使GPS天线位于铁塔最面向南方一角并保持与铁塔2米间距.</li><li>多个GPS天线之间的间距不能过近，否则天线之间可能会产生反射干扰,两个GPS天线间距大于2米</li><li>严禁将GPS天线安装在基站等系统的辐射天线主瓣面内，不能和全向天线安装在同一水平面内</li></ul><h4 id="AAU位置"><a href="#AAU位置" class="headerlink" title="AAU位置"></a>AAU位置</h4><p><img src="https://s2.loli.net/2022/12/20/EnK3ojZzmdeqfPh.png"></p><ul><li>AAU<strong>底部</strong>应预留<strong>600mm布线空间</strong>，为方便维护建议<strong>底部距地面</strong>至少<strong>1200mm</strong></li><li>AAU<strong>顶部</strong>应预留<strong>300mm布线和维护空间</strong></li><li>AAU<strong>左侧</strong>应预留<strong>300mm布线和维护空间</strong></li><li>AAU<strong>右侧</strong>应预留<strong>300mm布线和维护空间</strong></li><li><strong>前方应无遮挡</strong></li><li>安装位置通风要求：确保安装位置<strong>通风良好</strong>，利于设备散热</li></ul><h4 id="美化"><a href="#美化" class="headerlink" title="美化"></a>美化</h4><img src="https://s2.loli.net/2022/12/20/zZMWE38GUFefXhN.png" style="zoom:33%;" /><ul><li>美化罩尺寸影响AAU方位角调整</li><li>美化罩尺寸影响AAU下倾角调整</li><li>美化罩封闭不满足散热要求</li></ul><img src="https://s2.loli.net/2022/12/20/kvNKW1R2sj6xDcQ.png" style="zoom:33%;" /><p><strong>现网美化罩改造</strong>措施</p><ul><li>散热改造:拆除后门，顶部拆除,确保AAU背部全部可视</li><li>角度调整改造:如果需增加角度调整范围，调整抱杆位置或整体调整美化罩角度</li><li>排水措施改造:底部需有排水孔</li></ul><img src="https://s2.loli.net/2022/12/20/5nUbK6FoeiEL238.png" style="zoom:33%;" /><ul><li>美化塔<strong>安装空间不足</strong>，<strong>影响AAU角度调整</strong></li><li>美化塔<strong>罩体通透率不足</strong>，<strong>影响设备散热</strong></li></ul><img src="https://s2.loli.net/2022/12/20/5OvXBt7JGMQCpWb.png" style="zoom:33%;" /><ul><li><strong>拆除美化置</strong>，增加安装空间;</li><li><strong>改造美化罩</strong>，增加通透率到60%</li><li>在<strong>美化罩底部安装设备</strong>;更换美化置，满足设备安装要求。</li></ul><h4 id="电源"><a href="#电源" class="headerlink" title="电源"></a>电源</h4><ul><li>如果是<strong>拉远站点</strong>，确认电源空开的容量是否满足设备供电要求。</li><li><strong>防雷箱上级</strong>输入空开建议:<strong>选用-48V直流空开</strong>，<strong>BBU典型功耗400W</strong>，<strong>AAU典型功耗800w</strong></li></ul><p><img src="https://s2.loli.net/2022/12/20/P2dKOArnEg1BVXx.png"></p><h4 id="天线挂高"><a href="#天线挂高" class="headerlink" title="天线挂高"></a>天线挂高</h4><p><img src="https://s2.loli.net/2022/12/20/7ObUatvFlf4CJKP.png"></p><h4 id="倾角-x2F-方位角"><a href="#倾角-x2F-方位角" class="headerlink" title="倾角&#x2F;方位角"></a>倾角&#x2F;方位角</h4><p><img src="https://s2.loli.net/2022/12/20/DaKeS4o3ts6LW78.png"></p><h3 id="AAU配套设备辅材"><a href="#AAU配套设备辅材" class="headerlink" title="AAU配套设备辅材"></a>AAU配套设备辅材</h3><h4 id="AAU配套设备辅材-光纤"><a href="#AAU配套设备辅材-光纤" class="headerlink" title="AAU配套设备辅材-光纤"></a>AAU配套设备辅材-光纤</h4><p><img src="https://s2.loli.net/2022/12/20/cLCESmKgwaD5I9U.png"></p><h4 id="AAU配套辅材-光模块"><a href="#AAU配套辅材-光模块" class="headerlink" title="AAU配套辅材-光模块"></a>AAU配套辅材-光模块</h4><p><img src="https://s2.loli.net/2022/12/20/PRUXI7DjEMNkiw8.png"></p><h4 id="AAU电源接口"><a href="#AAU电源接口" class="headerlink" title="AAU电源接口"></a>AAU电源接口</h4><p><img src="https://s2.loli.net/2022/12/20/JCwzgthSjsb4Tue.png"></p><h2 id="5G设备安装"><a href="#5G设备安装" class="headerlink" title="5G设备安装"></a>5G设备安装</h2><h3 id="基站整体安装图示"><a href="#基站整体安装图示" class="headerlink" title="基站整体安装图示"></a>基站整体安装图示</h3><p><img src="https://s2.loli.net/2022/12/20/dcVYXyZvB61N4C3.png"></p><h3 id="主设备介绍-EMB6216"><a href="#主设备介绍-EMB6216" class="headerlink" title="主设备介绍-EMB6216"></a>主设备介绍-EMB6216</h3><p><img src="https://s2.loli.net/2022/12/20/SLmilvMpUaFVbNZ.png"></p><h4 id="EMB6216前面板视图"><a href="#EMB6216前面板视图" class="headerlink" title="EMB6216前面板视图"></a>EMB6216前面板视图</h4><p><img src="https://s2.loli.net/2022/12/20/OZwWDoeac1nVA8d.png"></p><h4 id="EMB6216主要接口"><a href="#EMB6216主要接口" class="headerlink" title="EMB6216主要接口"></a>EMB6216主要接口</h4><p><img src="https://s2.loli.net/2022/12/20/1yipahl4TYHFgSc.png"></p><h3 id="AAU接口"><a href="#AAU接口" class="headerlink" title="AAU接口"></a>AAU接口</h3><p><img src="https://s2.loli.net/2022/12/20/TAXQCdFyqwz2Hu3.png"></p><h3 id="5G核心网-通用服务器"><a href="#5G核心网-通用服务器" class="headerlink" title="5G核心网(通用服务器)"></a>5G核心网(通用服务器)</h3><p><img src="https://s2.loli.net/2022/12/20/SoycYJ4x1agjND8.png"></p><h4 id="安装方式"><a href="#安装方式" class="headerlink" title="安装方式"></a>安装方式</h4><p><img src="https://s2.loli.net/2022/12/20/GQyTMxUH1OvCtNm.png"></p><h4 id="基站安装"><a href="#基站安装" class="headerlink" title="基站安装"></a>基站安装</h4><p><img src="https://s2.loli.net/2022/12/20/hgdYRrpU3FGPX4b.png"></p><h4 id="GPS系统"><a href="#GPS系统" class="headerlink" title="GPS系统"></a>GPS系统</h4><p><img src="https://s2.loli.net/2022/12/20/9cD7xihH846kRON.png"></p><h4 id="时钟级联"><a href="#时钟级联" class="headerlink" title="时钟级联"></a>时钟级联</h4><p><img src="https://s2.loli.net/2022/12/20/XqcDgHmiQw7jY4b.png"></p><h3 id="BBU辅材"><a href="#BBU辅材" class="headerlink" title="BBU辅材"></a>BBU辅材</h3><h4 id="BBU辅材-光纤"><a href="#BBU辅材-光纤" class="headerlink" title="BBU辅材-光纤"></a>BBU辅材-光纤</h4><p><img src="https://s2.loli.net/2022/12/20/OpgGl1YanEd9h4i.png"></p><h4 id="BBU辅材-光模块"><a href="#BBU辅材-光模块" class="headerlink" title="BBU辅材-光模块"></a>BBU辅材-光模块</h4><p><img src="https://s2.loli.net/2022/12/20/UaRiVtYcnTpyKgO.png"></p><h4 id="BBU-电源"><a href="#BBU-电源" class="headerlink" title="BBU-电源"></a>BBU-电源</h4><p><img src="https://s2.loli.net/2022/12/20/Yo4miKP32Ox8Hfk.png"></p><h2 id="5G基站开通调测与车联网"><a href="#5G基站开通调测与车联网" class="headerlink" title="5G基站开通调测与车联网"></a>5G基站开通调测与车联网</h2><h3 id="5G网络发展技术背景-1"><a href="#5G网络发展技术背景-1" class="headerlink" title="5G网络发展技术背景"></a>5G网络发展技术背景</h3><p><img src="https://s2.loli.net/2022/12/20/RqZ9jWOVgynmuBo.png"></p><p><img src="https://s2.loli.net/2022/12/20/X4Icn6ae7NjMdVu.png"></p><p><img src="https://s2.loli.net/2022/12/20/7J3GjfPNt4dsp6M.png"></p><p><img src="https://s2.loli.net/2022/12/20/g9zt5JZbGSFH6mx.png"></p><h3 id="传输参数配置"><a href="#传输参数配置" class="headerlink" title="传输参数配置"></a>传输参数配置</h3><p><img src="https://s2.loli.net/2022/12/20/n3cSVsqLmI895Ze.png"></p><p><img src="https://s2.loli.net/2022/12/20/Fsv6caU7nGfh8qp.png"></p><p><img src="https://s2.loli.net/2022/12/20/OkFBtpG6eyaIclX.png"></p><h3 id="业务验证"><a href="#业务验证" class="headerlink" title="业务验证"></a>业务验证</h3><p><img src="https://s2.loli.net/2022/12/20/8KrbgndTXf5EjvD.png"></p><p><img src="https://s2.loli.net/2022/12/20/f7URm8TwdbJFip1.png"></p><h2 id="5G-车联网"><a href="#5G-车联网" class="headerlink" title="5G+车联网"></a>5G+车联网</h2><h3 id="车联网背景"><a href="#车联网背景" class="headerlink" title="车联网背景"></a>车联网背景</h3><p>基于电信级服务质量的蜂窝通信关键技术，演进形成车用无线通信技术，C-V2X是基于3GPP全球统一标准的通信技术,包含LTE-V2X和NR V2x，目前正在研究和使用的是:LTE-V2x:</p><p><img src="https://s2.loli.net/2022/12/20/y5tW4ZiJ6qmGDEC.png"></p><h3 id="车联网概述"><a href="#车联网概述" class="headerlink" title="车联网概述"></a>车联网概述</h3><p>C-V2X可提供两种通信接口(如下图)，分别为<strong>Uu接口（蜂窝通信接口）</strong>和<strong>PC5接口（直连通信)</strong></p><ul><li><strong>PC5</strong>：车、人、路之间的<strong>短距离、低时延、高可靠直接通信</strong>;</li><li><strong>Uu</strong>：<strong>终端和基站</strong>之间的通信接口，<strong>可实现长距离、大数据量、时延不敏感通信;</strong></li></ul><p><img src="https://s2.loli.net/2022/12/20/8Qe5DxCXWts4Ko2.png"></p><p><img src="https://s2.loli.net/2022/12/20/dlB2axEpSIAzfiP.png"></p><p><img src="https://s2.loli.net/2022/12/20/FnakjVoIrxyMp5H.png"></p><ul><li>FCW: Forward Collision Warning (FCW)前方碰撞预警系统</li><li>前车:RV (remote Vehicle)远端车辆</li><li>后车:HV (host Vehicle)本端车辆</li><li>车与车之间的接口:V2V</li><li>FCW应用分类:低时延高频率</li></ul><h3 id="5G网络发展技术背景-2"><a href="#5G网络发展技术背景-2" class="headerlink" title="5G网络发展技术背景"></a>5G网络发展技术背景</h3><p><img src="https://s2.loli.net/2022/12/20/vaHsOzNS5br1cDB.png"></p><p>有以下结果:</p><ol><li>碰撞则两车在行驶过程相撞（注意相撞时机不同)</li><li>永不碰撞（则从启动开始两车距离拉开)</li><li>不碰撞（30S前距离拉大，30S后距离缩短，但仍足够大)</li><li>紧急防碰撞（收到预警提示，后车及时减速，保持安全距离)</li></ol><p>防碰撞时间判定</p><ol><li>防碰撞时间**(3.1s&lt;T&lt;&#x3D;4s)<strong>：</strong>最紧急**，不碰撞，发起预警及时调整，安全抵达。(两车车距保持安全距离)</li><li>防碰撞时间**(T&lt;3.1S)<strong>：</strong>发起预警**，但无法及时制动，将产生碰撞</li><li>防碰撞时间**(T&gt;4S)**：非最紧急防碰撞，两车距离拉得较远，但可安全抵达。</li></ol>]]></content>
      
      
      <categories>
          
          <category> 学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 通信工程 </tag>
            
            <tag> 大唐杯 </tag>
            
            <tag> 5G </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>5G网络架构和组网部署-2</title>
      <link href="/2022/12/20/5G%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84%E5%92%8C%E7%BB%84%E7%BD%91%E9%83%A8%E7%BD%B2/"/>
      <url>/2022/12/20/5G%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84%E5%92%8C%E7%BB%84%E7%BD%91%E9%83%A8%E7%BD%B2/</url>
      
        <content type="html"><![CDATA[<h1 id="5G网络架构和组网部署"><a href="#5G网络架构和组网部署" class="headerlink" title="5G网络架构和组网部署"></a>5G网络架构和组网部署</h1><h2 id="课程目标"><a href="#课程目标" class="headerlink" title="课程目标"></a>课程目标</h2><ul><li>5G网络整体架构组成</li><li>主要网元功能</li><li>网元接口关系</li><li>5G网络组网部署策略</li></ul><h2 id="5G网络架构的演进趋势"><a href="#5G网络架构的演进趋势" class="headerlink" title="5G网络架构的演进趋势"></a>5G网络架构的演进趋势</h2><h3 id="网络架构概述"><a href="#网络架构概述" class="headerlink" title="网络架构概述"></a>网络架构概述</h3><h4 id="5G网络架构"><a href="#5G网络架构" class="headerlink" title="5G网络架构"></a>5G网络架构</h4><p>5G移动通信系统包括**5GC(5G Core Network，5G核心网)<strong>和</strong>NG-RAN(Next Generation Radio Access Network，5G无线接入网)**。</p><p><strong>5G核心网与5G接入网</strong>通过<strong>NG接口</strong>连接，实现控制面和用户面功能;</p><p><strong>5G无线接入网之间</strong>通过<strong>Xn接口</strong>连接，实现控制面和用户面功能。</p><p>5G移动通信系统整体架构如图所示。</p><p><img src="https://s2.loli.net/2022/12/18/TYIg9iNkGKcRBtx.png" alt="5G移动通信系统整体架构"></p><blockquote><p>知识点：</p><ul><li>5GC 5G<strong>核心网</strong></li><li>NG-RAN 5G<strong>无线接入网</strong></li><li>gNB 5G基站 （g-node-B）<strong>【NA组网只包含gNB】</strong></li><li>ng-eNB 4G增强基站可用于5G信号（next-generation-eNodeB）</li><li>UPF-用户面网元</li><li>AMF&#x2F;SMF-控制面网元</li><li>5G核心与5G接入网<strong>（有线）-NG接口</strong></li><li>5G<strong>无线</strong>接入网之间-<strong>Xn接口</strong></li></ul></blockquote><h4 id="4G网络架构"><a href="#4G网络架构" class="headerlink" title="4G网络架构"></a>4G网络架构</h4><p>4G移动通信系统包括<strong>EPC (Evolved Packet Core network，演进分组核心网）</strong>和**E-UTRAN (Evolved UniversaTerrestrial Radio Access Network，演进通用陆地无线接入网络)**。</p><p>4G移动通信系统整体架构如下图所示:</p><p><img src="https://s2.loli.net/2022/12/18/4XYHJcVgBO5qe1h.png" alt="4G移动通信系统整体架构"></p><blockquote><p>知识点：</p><ul><li>EPC 4G（演进分组）<strong>核心网</strong></li><li>E-UTRAN 4G（演进通用陆地）<strong>无线接入网络</strong></li><li>eNB 4G基站</li><li>MME网元（与AMF功能大致相似）</li><li>S-GW网元</li><li>4G核心与4G接入网<strong>（有线） S1接口</strong></li><li>4G<strong>无线</strong>接入网之间 <strong>X2接口</strong></li></ul></blockquote><h4 id="5G与4G网络架构比较"><a href="#5G与4G网络架构比较" class="headerlink" title="5G与4G网络架构比较"></a>5G与4G网络架构比较</h4><p>5G移动通信系统整体架构与4G<strong>整体架构类似</strong>。</p><p>4G与5G移动通信系统整体架构对比如下图所示:</p><p><img src="https://s2.loli.net/2022/12/18/JilcNwTZUnYqCML.png" alt="5G与4G网络架构比较"></p><p><strong>RAN网络引入CU、DU，组网更灵活，利于多小区的集中控制，利于多功能的实现。</strong></p><p><strong>MEC(Multi-access Edge Connection，多接入边缘计算）</strong>是支撑5G系统运行的<strong>关键技术</strong>。（将5GC的部分功能下放到MEC，就近部署到靠近基站的位置，减少时延）</p><p>虚线部分为接入网，上方为核心网</p><blockquote><p>知识点：</p><ul><li>BBU  (Baseband Unit) <strong>基带单元</strong> 指基站系统中负责处理基带信号的单元。</li><li>RRU (Radio Remote Unit ) <strong>无线远端单元&#x2F;基站射频拉远单元</strong>(射频单元)</li><li>CU (Centralized Unit) <strong>中央单元</strong> </li><li>DU (Distributed Unit) <strong>分布式单元</strong></li><li>CU+DU 为合设；CU➡DU 为分离</li><li>实际上，每个gNB有一个CU，但一个CU<strong>控制多个DU</strong>，例如一个CU可以连接超过1oo 个DU。</li><li>了解 前传 中传 回传</li><li>AAU (Active Antenna Unit) <strong>有源天线单元</strong>（射频+天线单元 有利于大规模天线 ）</li><li>改变<ol><li>CU；DU灵活组网</li><li>RRU变为AAU</li><li>MEC 多接入边缘计算的引入</li></ol></li></ul></blockquote><h3 id="核心网架构的演进"><a href="#核心网架构的演进" class="headerlink" title="核心网架构的演进"></a>核心网架构的演进</h3><h4 id="网络架构演进的核心目标："><a href="#网络架构演进的核心目标：" class="headerlink" title="网络架构演进的核心目标："></a>网络架构演进的核心目标：</h4><ul><li>实现从“互联网应用<strong>被动适应</strong>网络”向“网络<strong>主动、快速、灵活适应</strong>互联网应用”</li><li>网络和资源的部署将打破行政管理体制和传统组网思路的制约，转向<strong>以IDC为核心</strong>的新格局。</li></ul><p>不同阶段核心网技术特征与代表技术如下图所示:</p><p><img src="https://s2.loli.net/2022/12/18/vSUrZqHPxskfMWI.png" alt="不同阶段核心网技术特征与代表技术如下图"></p><blockquote><p>知识点：</p><ul><li><strong>核心网的本质的是路由交换</strong></li><li>2G数字通信：分组交换技术</li><li>3G互联网：IP化；控制和承载分离</li><li>4G：CS域取消，引入IMS域</li><li>5G：基于服务的 网络架构 SBA；云元生（微服务架构）；实现控制转发完全分离，网元虚拟化易于扩容（模块化，软件化）</li></ul></blockquote><h4 id="移动通信系统核心网从3G到4G的演进特点："><a href="#移动通信系统核心网从3G到4G的演进特点：" class="headerlink" title="移动通信系统核心网从3G到4G的演进特点："></a>移动通信系统核心网从3G到4G的演进特点：</h4><p>取消了<strong>CS域(Circuit Switch，电路交换域）</strong>只保留<strong>PS域(Packet Switch,分组交换域）</strong>。4G移动通信系统<strong>实现了控制和承载相分离</strong>。4G核心网架构如下图所示:</p><p><img src="https://s2.loli.net/2022/12/18/kSH6UdCzvp9jJmM.png" alt="4G核心网架构"></p><p>注：</p><ul><li><p>框中引入一个IMS域：语音会话处理；</p></li><li><p>框中为控制面，其它为承载面。</p></li></ul><blockquote><p>知识点：</p><ul><li><p>SGW 路由转发 </p></li><li><p>PGW  IP地址分配</p></li><li><p>PCRF 计费策略</p></li></ul></blockquote><h4 id="5G核心网颠覆了4G核心网的设计思路。"><a href="#5G核心网颠覆了4G核心网的设计思路。" class="headerlink" title="5G核心网颠覆了4G核心网的设计思路。"></a>5G核心网颠覆了4G核心网的设计思路。</h4><p>5G核心网基于<strong>SBA实现(Service Based Architecture，基于服务架构)<strong>，使用</strong>NFV技术灵活重构网络功能</strong>，使用S<strong>DN技术灵活构建数据转发通道</strong>，使用切片技术实现业务保障与资源利用率最大化，完全实现**CUPS (Control and User Plane Separation，控制与用户面分离)**，结合云技术全面支撑5G应用场景需求。为了应对5G网络的发展要求，基于服务的5G核心网架构如下图所示:</p><p><img src="https://s2.loli.net/2022/12/18/AyEIR2dW17ToGqb.png" alt="5G核心网架构"></p><p>注：</p><ul><li>框中为控制面，其它为承载面。</li></ul><blockquote><p>知识点：</p><ul><li>完全实现控制与用户面分离</li></ul></blockquote><h3 id="无线接入网的演进"><a href="#无线接入网的演进" class="headerlink" title="无线接入网的演进"></a>无线接入网的演进</h3><p>从2G(第二代移动通信系统）开始到现在的5G(第五代移动通信系统)，无线接入网技术一直处于变化之中.无线接入网的实现方式也呈现出“分合分”的表象。无线接入网的发展与演进如下图</p><p><img src="https://s2.loli.net/2022/12/18/8sveNd9LGVknxUq.png" alt="无线接入网的发展与演进"></p><h2 id="5G网元功能与接口"><a href="#5G网元功能与接口" class="headerlink" title="5G网元功能与接口"></a>5G网元功能与接口</h2><h3 id="5G移动通信整体网络架构"><a href="#5G移动通信整体网络架构" class="headerlink" title="5G移动通信整体网络架构"></a>5G移动通信整体网络架构</h3><h4 id="5G网络功能之间的信息交互可以基于两种方式表示"><a href="#5G网络功能之间的信息交互可以基于两种方式表示" class="headerlink" title="5G网络功能之间的信息交互可以基于两种方式表示:"></a>5G网络功能之间的信息交互可以基于两种方式表示:</h4><ol><li><p>基于<strong>服务</strong>表示</p></li><li><p>基于<strong>点对点</strong>表示。</p></li></ol><p>实际部署时，也可以采用两种方式<strong>相结合的</strong>表示方式。因为并不是所有的接口都适合基于服务表示，对于有些接口点对点表示方式更加适合。从图1-8可以看出，控制面内的网络功能（例如AMF)使其他授权的网络功能能够访问其服务。但是，对于接口N1和接口N2，这种表示还包括必要时的点对点表示方式。</p><p><img src="https://s2.loli.net/2022/12/19/TBM7AbUao6h12xV.png" alt="非漫游5G移动通信系统架构-SBA"></p><blockquote><p>知识点：</p><ul><li>(R)AN 无线接入网（基站）</li><li>DN 数据中心</li><li>UE 用户终端</li><li>基于网络功能虚拟化 独立功能实体</li><li>NRF 网络功能注册的实体</li><li><img src="https://s2.loli.net/2022/12/19/RwUhz9fyIepnvBG.png"><ul><li>“N＋模块名称”<strong>基于服务</strong>的接口（利用服务<strong>注册</strong>和服务<strong>发现</strong>的功能 ）【拓展性好】</li><li>”N1&#x2F;N2&#x2F;N3“<strong>基于点对点</strong>的接口【可以被服务化接口替代】</li></ul></li><li><strong>区分漫游与非漫游：归属地与拜访地地址是否相同</strong></li><li>UE-AMF  使用N1口</li><li>（R）AN-AMF  使用N2口</li></ul></blockquote><h4 id="非漫游5G移动通信系统点到点表示"><a href="#非漫游5G移动通信系统点到点表示" class="headerlink" title="非漫游5G移动通信系统点到点表示"></a>非漫游5G移动通信系统点到点表示</h4><p>如下图1-9所示:</p><p><img src="https://s2.loli.net/2022/12/19/HKsJTrtXNwUAagQ.png" alt="5G移动通信系统点到点表示"></p><h4 id="5G无线接入网的基站-gNB-x2F-en-gNB-网元功能拆分"><a href="#5G无线接入网的基站-gNB-x2F-en-gNB-网元功能拆分" class="headerlink" title="5G无线接入网的基站(gNB&#x2F;en-gNB)网元功能拆分"></a>5G无线接入网的基站(gNB&#x2F;en-gNB)网元功能拆分</h4><p>**CU(Centralized Unit，集中单元)<strong>和</strong>DU(Distributed Unit，分布单元)**5G移动通信系统NG-RAN CU与DU分离逻辑图，如下图1-10所示。</p><p><img src="https://s2.loli.net/2022/12/19/zB6FwWr1HStaE9Z.png"></p><blockquote><p>知识点：</p><ul><li>CU 中央单元：RRC,PDCP</li><li>DU 分布式单元：RLC,MAC,H_PHY</li><li>“-C” Control一般指对控制面</li><li>“-U” User一般指对用户面</li><li>Xn 接口 与其它基站交换时使用的接口</li><li>NG 接口 与和行为交换时使用的接口</li><li>CU&gt;DU&gt;AAU (前面的可以挂载多个后面的)</li></ul></blockquote><h4 id="CU-DU的划分方案"><a href="#CU-DU的划分方案" class="headerlink" title="CU DU的划分方案"></a>CU DU的划分方案</h4><p><img src="https://s2.loli.net/2022/12/19/bTwUGznWhFM2plu.png"></p><blockquote><p>知识点：</p><ul><li>CU-DU CU越靠近底层（右侧）传输带宽要求越大，要求更低时延</li><li>CU-DU CU越靠近底层（右侧）集中化程度越大</li><li>CU-DU 中传</li></ul></blockquote><ul><li><p>底层功能划分方案优点:</p><ul><li>便于控制面<strong>集中</strong>，利于无线资源干扰协调;</li><li><strong>可以采用虚拟化平台</strong>;</li></ul></li><li><p>高层功能划分方案优点:</p><ul><li>**3GPP标准确定了option2:**左侧为CU 右侧为DU<ul><li><img src="https://s2.loli.net/2022/12/19/JqWLmn6ROI1hZtM.png"></li></ul></li><li><strong>PDCP上移便于形成数据锚点，便于支持用户面的双连接&#x2F;多连接</strong></li></ul></li></ul><p>CU\DU方案策略比较：</p><p><img src="https://s2.loli.net/2022/12/19/v76JGz8CWuTpgV2.png"></p><p><strong>Option4:对传输时延要求很高,且未看到其他性能增益，后续基本不考虑该方案。</strong></p><h3 id="5G主要网元功能"><a href="#5G主要网元功能" class="headerlink" title="5G主要网元功能"></a>5G主要网元功能</h3><blockquote><ul><li>掌握主要功能</li><li>掌握协议栈</li></ul></blockquote><h4 id="5G系统的组成："><a href="#5G系统的组成：" class="headerlink" title="5G系统的组成："></a>5G系统的组成：</h4><ul><li>接入网（AN）</li><li>核心网（5GC）</li></ul><h4 id="NG-RAN与5GC的主要功能"><a href="#NG-RAN与5GC的主要功能" class="headerlink" title="NG-RAN与5GC的主要功能"></a>NG-RAN与5GC的主要功能</h4><p><img src="https://s2.loli.net/2022/12/19/jiLGu1tXo8efJ4m.png"></p><blockquote><p>知识点：</p><ul><li>无线控制放到SRB（1&#x2F;2&#x2F;3【双链接】&#x2F;0【4G】）</li><li>数据放到DRB</li><li>往下层传递 有不同承载</li><li>连接态 移动性管理</li><li>AMF&#x2F;SMF 控制面</li><li>UPF 用户面</li></ul></blockquote><h4 id="UPF（用户面功能）"><a href="#UPF（用户面功能）" class="headerlink" title="UPF（用户面功能）"></a>UPF（用户面功能）</h4><ul><li>**gNodeB间切换的本地移动锚点(适用时)*<em>【</em>】<ul><li>保证终端连接路径</li></ul></li><li><strong>连接到移动通信网络的外部PDU会话点</strong>【*】<ul><li>作为节点</li></ul></li><li>基于N接口切换过程中，数据包<strong>路由与转发</strong>【*】</li><li>数据包检查和用户面部分的策略计费</li><li>合法的监听拦截(集合)</li><li>流量使用情况报告</li><li>Uplink支持路由流量到一个数据网</li><li>分支点以支持多类的PDU会话</li><li>对用户平面的QoS处理，例如包过滤、门控、ul&#x2F;dl速率执行</li><li>Uplink流量验证(<strong>SDF到QoS流映射</strong>)【*】</li><li>上下行链路上传输级别的数据包标记</li><li>下行数据包缓冲和下行数据通知触发</li></ul><h4 id="SMF（会话管理功能）"><a href="#SMF（会话管理功能）" class="headerlink" title="SMF（会话管理功能）"></a>SMF（会话管理功能）</h4><ul><li><strong>会话的建立修改删除</strong>【*】<ul><li>发寻呼消息</li></ul></li><li>包括tunnel maintain between UPF and AN node</li><li><strong>UEIP地址的分配和管理</strong>【*】<ul><li>IP化</li></ul></li><li>DHCPv4(server and client) and DHCPv6 (server andclient) functions</li><li><strong>选择控制用户面功能</strong>【*】</li><li>QoS的策略与控制，终止策略控制。</li><li>合法监听</li><li>Termination of SM parts of NAS messages</li><li>下行数据的通知</li><li>漫游功能</li></ul><h4 id="AMF（访问和移动性管理功能）"><a href="#AMF（访问和移动性管理功能）" class="headerlink" title="AMF（访问和移动性管理功能）"></a>AMF（访问和移动性管理功能）</h4><ul><li><strong>NAS信令及信令的加密和完整性保护</strong>【*】</li><li>终止运行RAN网络接口(N2)</li><li><strong>注册管理</strong>【*】</li><li>连接管理</li><li><strong>NAS移动性管理</strong>【*】</li><li>合法的截距(用于AMF事件和对Ll系统的接口)</li><li>为在UE和SMF之间的SM消息提供传输</li><li>路由SM消息的透明代理</li><li>访问验证</li><li><strong>在UE和SMSF之间提供SMS消息的传输</strong>【*】<ul><li>透传</li></ul></li><li><strong>用户鉴权及密钥管理</strong>【*】</li><li>承载管理功能，包括专用承载建立过程</li></ul><h4 id="gNB-x2F-en-gNB"><a href="#gNB-x2F-en-gNB" class="headerlink" title="gNB&#x2F;en-gNB"></a>gNB&#x2F;en-gNB</h4><h5 id="CU-C-Central-Unit-Control-plane"><a href="#CU-C-Central-Unit-Control-plane" class="headerlink" title="CU-C (Central Unit Control plane)"></a>CU-C (Central Unit Control plane)</h5><ul><li>lnterface Management包括: <ul><li>Xn&#x2F;NG&#x2F;F1&#x2F;E1等<strong>接口链路管理</strong></li><li><strong>接口消息处理(如:NG-AP)</strong></li><li><strong>数据处理(如:GTP-u)</strong></li></ul></li><li>Connection Management包括:<ul><li>单连接</li><li>双连接</li><li>多连接</li><li>D2D</li></ul></li><li>Traffic Steering包括:系统内和系统间的<strong>负载均衡</strong></li><li>Slice Support包括:系统内和系统间的切片资源动态管理。</li></ul><h5 id="CU-U-Central-Unit-User-plane"><a href="#CU-U-Central-Unit-User-plane" class="headerlink" title="CU-U (Central Unit User plane)"></a>CU-U (Central Unit User plane)</h5><ul><li>数据包的<strong>处理和转换</strong></li></ul><h5 id="Du-Distributed-Unit"><a href="#Du-Distributed-Unit" class="headerlink" title="Du (Distributed Unit)"></a>Du (Distributed Unit)</h5><ul><li>资源的调度传输模式的转换信道<strong>映射</strong></li></ul><h5 id="AAU-RF-Radio-Frequency"><a href="#AAU-RF-Radio-Frequency" class="headerlink" title="AAU-RF(Radio Frequency)"></a>AAU-RF(Radio Frequency)</h5><ul><li><strong>信号的收发</strong>Massive MIMO天线处理频率与时间同步AAS实现机制</li></ul><h3 id="5G系统接口功能与协议"><a href="#5G系统接口功能与协议" class="headerlink" title="5G系统接口功能与协议"></a>5G系统接口功能与协议</h3><p>5G系统的接口非常多，如果考虑接口间的协同工作及相互影响，可能涉及内容更多。本节内容仅针对<strong>NG接口、Xn接口、F1接口、E1接口和Uu接口</strong>进行描述。</p><h4 id="5G系统接入网-AN-和核心网-5GC-的主要接口"><a href="#5G系统接入网-AN-和核心网-5GC-的主要接口" class="headerlink" title="5G系统接入网(AN)和核心网(5GC)的主要接口"></a>5G系统接入网(AN)和核心网(5GC)的主要接口</h4><p>如图1-13所示.</p><p><img src="https://s2.loli.net/2022/12/20/3WFoR9ucAay8T5D.png" alt="(AN)和核心网(5GC)的主要接"></p><h4 id="NG接口"><a href="#NG接口" class="headerlink" title="NG接口"></a>NG接口</h4><p><strong>NG接口是NG-RAN（无线基站）和5G核心网之间的接口</strong>，支持<strong>控制面和用户面分离</strong>，支持<strong>模式化设计</strong>。</p><p>NG接口协议栈如图1-14所示：</p><p><img src="https://s2.loli.net/2022/12/20/23ywqDBRONZcUCK.png"></p><p>其中左侧表示控制面协议栈(NG-C接口)</p><p>右图表示用户面协议栈(NG-U接口)</p><blockquote><p>知识点：</p><ul><li>发送端从上往下</li><li>接收端从下往上</li></ul></blockquote><h5 id="控制面NG-C功能："><a href="#控制面NG-C功能：" class="headerlink" title="控制面NG-C功能："></a>控制面NG-C功能：<img src="https://s2.loli.net/2022/12/20/nrAFMSZ6vhP9qky.png"></h5><h5 id="用户面NG-U功能："><a href="#用户面NG-U功能：" class="headerlink" title="用户面NG-U功能："></a>用户面NG-U功能：</h5><ul><li>NG-U接口在NG-RAN节点和UPF之间提供非保证的用户平面PDU传送</li><li>协议栈传输网络层建立在IP传输上;</li><li>GTP-U在UDP&#x2F;IP之上用于承载NG-RAN节点和UPF之间的用户面PDU。</li></ul><h4 id="Xn接口"><a href="#Xn接口" class="headerlink" title="Xn接口"></a>Xn接口</h4><p>Xn接口是<strong>NG-RAN（无线基站）之间的接口</strong>,Xn接口协议栈如下图1-15所示，</p><p><img src="https://s2.loli.net/2022/12/20/lPvBF6UODkW3R1K.png"></p><p>其中左侧表示<strong>控制面协议栈(Xn-C接口)</strong></p><p>右侧表示用户面协议栈（Xn-U接口)</p><p>在CU\DU分离的情况下，<strong>Xn-C是CU-C之间的接口</strong>，<strong>Xn-U是CU-U之间的接口</strong>.</p><h5 id="Xn-U接口的主要功能"><a href="#Xn-U接口的主要功能" class="headerlink" title="Xn-U接口的主要功能"></a>Xn-U接口的主要功能</h5><ul><li>Xn-U接口提供用户平面PDU的非保证传送，并支<strong>持分离Xn接口为无线网络功能和传输网络功能</strong>，以促进未来技术的引入;</li><li><strong>数据转发功能</strong>，允许NG-RAN节点间数据转发从而支持双连接和移动性操作;</li><li><strong>流控制功能</strong>，允许NG-RAN节点接收第二个节点的用户面数据从而提供数据流相关的反馈信息。</li></ul><h5 id="CU-DU分离场景下接口详情"><a href="#CU-DU分离场景下接口详情" class="headerlink" title="CU\DU分离场景下接口详情"></a>CU\DU分离场景下接口详情</h5><ul><li><strong>Xn-C是CU-C之间的接口</strong></li><li><strong>Xn-U是CU-U之间的接口</strong></li><li><strong>E1接口是指CU-C与CU-U之间的接口</strong></li></ul><h4 id="E1接口"><a href="#E1接口" class="headerlink" title="E1接口"></a>E1接口</h4><p>E1接口<strong>只有控制面接口（E1-C接口)<strong>。E1接口是</strong>开放接口</strong>，支<strong>持端点之间信令信息的交换</strong>，支持5G系统新服务和新功能。E1-C接口<strong>不能用于用户数据转发</strong>。E1接口协议栈如下图1-16所示:</p><p><img src="https://s2.loli.net/2022/12/20/tV6yMOQqY8lHE5U.png"></p><h5 id="E1接口的功能"><a href="#E1接口的功能" class="headerlink" title="E1接口的功能"></a>E1接口的功能</h5><ul><li>E1接口<strong>管理</strong>功能<ul><li><strong>错误指示</strong>（gNB-CU-UP或者gNB-CU-CP向gNB-CU-CP或者gNB-CU-CP发出错误指示)</li><li>复位功能用于gNB-CU-UP与gNB-CU-CP建立之后和发生故障事件之后初始化对等实体</li><li>gNB-CU-UP与gNB-CU-CP之间应用层数据的互操作</li><li>gNB-CU-UP配置更新: gNB-CU-UP将NR CGI、s - nssai、PLMN-ID和gNB-CU-UP支持的QoS信息通知给gNB-CU-CP</li></ul></li><li>E1上下文管理功能<ul><li><strong>上下文承载建立（ gNB-CU-CP )</strong> </li><li><strong>上下文承载修改与释放（可以由gNB-CU或gNB-DU发起)</strong></li><li>QoS流映射(gNB-CU执行)</li><li>下行数据通知( gNB-CU-UP发起)</li><li>承载不活动通知</li><li>数据使用情况报告（ gNB-CU-UP发起)</li></ul></li><li>**TEID分配功能(gNB-CU-UP)**（隧道标识）<ul><li>F1-U UL GTP TEID</li><li>S1-U DL GTP TEID</li><li>NG-U DL GTP TEID X2-U DL&#x2F;UL GTPTEID</li><li>Xn-U DL&#x2F;UL GTP TEID</li><li>Xn-U DL&#x2F;UL GTP TEID</li></ul></li></ul><h4 id="F1接口"><a href="#F1接口" class="headerlink" title="F1接口"></a>F1接口</h4><p>CU\DU分离场景下，<strong>F1接口是指CU与DU之间的接口</strong>，区分为<strong>用户面</strong>接口（<strong>F1-U接口</strong>）和<strong>控制面</strong>接口（F1-C接口)。F1接口支持eNB-point之间的信令交互，包括支持不同eNB-point的数据发送。F1接口协议栈如下图1-16所示</p><p><img src="https://s2.loli.net/2022/12/20/QbGfPFHTp4iNXWJ.png"></p><p>其中左侧表示控制面协议栈(F1-C接口)，右侧表示用户面协议栈(F1-U接口)。</p><h5 id="F1-C接口主要功能"><a href="#F1-C接口主要功能" class="headerlink" title="F1-C接口主要功能"></a>F1-C接口主要功能</h5><ul><li>F1<strong>接口管理</strong>功能<ul><li>错误指示<br>复位功能用于在节点建立之后和发生故障事件之后初始化对等实体</li></ul></li><li>系统信息管理功能<ul><li>系统广播信息的调度在gNB-DU中执行，gNB-DU负责NR-MIB、SIB1的编码，gNB-CU负责其他SI消息的编码。</li></ul></li><li>F1 UE上下文管理功能<ul><li>基于接纳控制准则、由gNB-CU发起并由gNB-DU接受或拒绝F1 UE上下文的建立;</li><li>UE上下文的修改(可以由gNB-CU或gNB-DU发起);</li><li>QoS流和无线承载之间的映射(gNB-CU执行);</li><li>管理建立，修改和释放DRB和SRB资源（DRB资源的建立和修改由gNB-CU触发)。</li></ul></li><li><strong>RRC消息传送</strong>功能<ul><li>RRC消息通过F1-C传送，gNB-CU负责用gNB-DU提供的辅助信息对专用RRC消息进行编码。</li></ul></li></ul><h5 id="F1-U接口主要功能"><a href="#F1-U接口主要功能" class="headerlink" title="F1-U接口主要功能"></a>F1-U接口主要功能</h5><ul><li>用户数据传输(Transfer of user data) </li><li>CU和DU之间传输用户数据</li><li>流量控制功能(Flow control function) </li><li>控制下行用户数据流向DU</li></ul><h4 id="Uu接口"><a href="#Uu接口" class="headerlink" title="Uu接口"></a>Uu接口</h4><h5 id="控制面："><a href="#控制面：" class="headerlink" title="控制面："></a>控制面：</h5><p><img src="https://s2.loli.net/2022/12/20/CEN6XizfPAGcrD1.png"></p><p><strong>控制面的主要功能</strong>:</p><ul><li>RLC和MAC层功能与用户面中的功能一致</li><li>PDCP层完成加密和完整性保护</li><li>RRC层完成广播，寻呼，RRC连接管理,资源控制，移动性管理，UE测量报告控制</li><li>NAS层完成核心网承载管理，鉴权及安全控制<ul><li>NAS层是控制面功能，位于核心网的AMF与终端之间，功能包括<strong>核心网承载管理、注册管理、连接管理、会话管理、鉴权、安全性和策略控制。</strong>基于服务的NAS接口如图1-20所示。<img src="https://s2.loli.net/2022/12/20/pyjzO4tFqGYHLI3.png"></li></ul></li></ul><h5 id="应用面："><a href="#应用面：" class="headerlink" title="应用面："></a>应用面：</h5><p><img src="https://s2.loli.net/2022/12/20/kuTZ1neyKLmAp2P.png" alt="image-20221220011103366"></p><p><strong>用户面的主要功能:</strong></p><ul><li>头压缩，加密，调度，ARQ&#x2F;HARQ</li><li>5G用户面增加新的协议层SDAP (Service DataAdaptation Protocol)，完成流(5G QoS flow)到无线承载(DRB)的QoS映射，为每个报文打上流标识(QFI: Qos flow ID )</li></ul><blockquote><p>知识点：</p><ul><li>5G用户面增加加入新的协议层SDAP，完成QoS映射功能</li></ul></blockquote><h2 id="5G网络组网部署"><a href="#5G网络组网部署" class="headerlink" title="5G网络组网部署"></a>5G网络组网部署</h2><h3 id="SA组网和NSA组网"><a href="#SA组网和NSA组网" class="headerlink" title="SA组网和NSA组网"></a>SA组网和NSA组网</h3><h4 id="5G组网的模式"><a href="#5G组网的模式" class="headerlink" title="5G组网的模式"></a>5G组网的模式</h4><p>根据3GPP定义，5G标准分为<strong>非独立组网(NSA）</strong>和<strong>独立组网(SA）</strong>两种模式。</p><ul><li>SA组网是指使能5G网络不需要其他移动通信系统的辅助可以独立进行工作。（抢占市场使用）</li><li>NSA组网是指使能5G网络需要其他移动通信系统的辅助，如果辅助缺失，那么5G网络不可以独立进行工作。（只能实现部分功能）</li></ul><p>通常而言，5G网络建设阶段，<strong>NSA组网方式是在表明5G网络的使用需要4G网络进行辅助。</strong></p><img src="https://s2.loli.net/2022/12/20/JLBvT6D43reyzMm.png" style="zoom:67%;" /><h4 id="5G移动通信系统的接入网有两种表示方式"><a href="#5G移动通信系统的接入网有两种表示方式" class="headerlink" title="5G移动通信系统的接入网有两种表示方式:"></a>5G移动通信系统的接入网有两种表示方式:</h4><ul><li><p>ng-eNB</p></li><li><p>gNB</p></li></ul><p>ng-eNB和gNB都可以<strong>独立地</strong>承担与核心网之间控制面和用户面的连接，<strong>不需要其它接入网网元辅助</strong>。</p><h4 id="SA组网方案"><a href="#SA组网方案" class="headerlink" title="SA组网方案"></a>SA组网方案</h4><p>针对5G移动通信系统，3GPP确定的SA options如下图1-21所示：</p><p><img src="https://s2.loli.net/2022/12/20/lkVDRNv8TGOqCXH.png" alt="SA组网方案"></p><p>左侧option，对应<strong>接入网使用gNB-option2</strong>【最终目标方案】</p><p>右侧option，对应<strong>接入网使用ng-eNB-option5</strong></p><h4 id="NSA组网方案"><a href="#NSA组网方案" class="headerlink" title="NSA组网方案"></a>NSA组网方案</h4><h5 id="Option3"><a href="#Option3" class="headerlink" title="Option3"></a>Option3</h5><p>3GPP确定的<strong>NSA option 3</strong>系列如下图1-22所示。</p><p><img src="https://s2.loli.net/2022/12/20/SmBAWqnbcOsk2Iv.png"></p><p>蓝色主节点，橙色辅节点</p><blockquote><p>知识点：</p><p>Option 3</p><ul><li>LTE eNB作为锚点站</li></ul><p>Option 3A&#x2F;X</p><ul><li>EPC进行分流</li></ul><p><strong>三者区别:接口区别</strong></p><ul><li>3➡eNB锚点</li><li>3A➡eNB 控制面分流</li><li>3X➡eNB 控制+用户面分流</li></ul></blockquote><p>2017年12月制定:<strong>4G基站(eNB）和5G基站(gNB)）共用4G核心网（EPC )，LTE eNB和5G gNB用户面可以直接连接到EPC</strong>，控制面则<strong>仅经由LTE eNB连接到EPC</strong>。用户面可以分别经由LTE eNB、EPC或者gNB进行分流。</p><ul><li><p>优点：不必新增5G核心网<strong>，利用运营商现有4G网络基础设施快速部署5G，</strong>抢占覆盖和热点**。</p></li><li><p>弊端：5G信令全走4G通道，<strong>有4G核心网信令过载风险</strong>，因此该阶段主<strong>要解决初期的5G覆盖</strong>。</p></li></ul><h5 id="Option7"><a href="#Option7" class="headerlink" title="Option7"></a>Option7</h5><p>3GPP确定的<strong>NSA option7</strong>系列如下图1-23所示</p><p><img src="https://s2.loli.net/2022/12/20/G4BeI5RUKdlVgOc.png"></p><p>2018年12月确定:**增强型4G基站(ng-eNB)与5G基站(gNB)共用5G核心网(5GC)**，该阶段5G核心网替代了4G核心网，</p><p>控制面则<strong>仅经由ng-eNB连接</strong>到5GC，用户面可以分别经由ng-eNB、5GC或者gNB进行分流，<strong>解决了4G核心网信令过载风险</strong>，<strong>主要面向5G容量需求。</strong></p><p>数据锚点:5G NR接入网做数据锚点<strong>支持X架构</strong>（LTE设备处理能力弱于NR，不适合做锚点)</p><h5 id="Option4"><a href="#Option4" class="headerlink" title="Option4"></a>Option4</h5><p>3GPP确定的NSA option4系列如下图1-24所示</p><p><img src="https://s2.loli.net/2022/12/20/gBXdLvANRxUZ2QK.png"></p><p>2019年12月确定:<strong>增强型4G基站(ng-eNB)与5G基站（gNB)共用5G核心网(5GC)<strong>，该阶段5</strong>G核心网替代了4G核心网</strong>，控制面则<strong>仅经由5G gNB连接到5GC</strong>，用户面可以分别经由gNB、5GC或者ng-eNB进行分流。该阶段不仅面向5G的增强型移动带宽场景(eMBB),还面向大规模网联网(mMTC)和低时延高可靠物联网(uRLLC)。<strong>是面向万物连接时代5G的多样化业务</strong>。</p><h5 id="基站的定义"><a href="#基站的定义" class="headerlink" title="基站的定义"></a>基站的定义</h5><ul><li>eNB:面向终端（UE）提供E-UTRAN用户面和控制面协议，并且通过S1接口连接到EPC的网络节点;</li><li>ng-eNB:面向终端(UE)提供E-UTRAN用户面和控制面协议，并且通过NG接口连接到5GC的网络节点;</li><li>gNB:面向终端（UE）提供NR用户面和控制面协议，并且通过NG接口连接到5GC的网络节点;</li><li>en-gNB:面向终端(UE）提供NR用户面和控制面协议，并且通过S1-U接口连接到EPC的网络节点。</li></ul><h5 id="SA与NSA组网的对比"><a href="#SA与NSA组网的对比" class="headerlink" title="SA与NSA组网的对比"></a>SA与NSA组网的对比</h5><p><img src="https://s2.loli.net/2022/12/20/InKLT1AMJjyo97t.png"></p><h3 id="MR-DC技术"><a href="#MR-DC技术" class="headerlink" title="MR-DC技术"></a>MR-DC技术</h3><h4 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h4><p><strong>MR-DC(Multi-RAT Dual Connectivity，多接入网技术双连接)<strong>是指一部终端可以</strong>同时连接4G网络和5G网络</strong>,<strong>同时使用两个网络进行业务</strong></p><p>此时终端需要具备至少<strong>两个MAC实体，支持双发双收</strong>。</p><p>对应不同的网络架构，双连接有不同的名称。不同场景下DC的名称如表1-3所示。</p><p><img src="https://s2.loli.net/2022/12/20/ew7D9yxtsapEFvS.png"></p><h4 id="以option3x组网场景为例"><a href="#以option3x组网场景为例" class="headerlink" title="以option3x组网场景为例"></a>以option3x组网场景为例</h4><p><strong>从控制面看</strong>:</p><p><strong>网络侧MN(eNB）</strong>和<strong>终端</strong>之间会建立面向核心网的控制平面连接，维护<strong>唯一的RRC</strong>状态。<strong>MN(eNB)和SN(gNB)<strong>具有各自的</strong>RRC实体</strong>，可以生成要发送到**终端的RRC PDU (Protocol Data Unit，协议数据单元)**。</p><p>NSA option 3x控制面协议栈如下图1-25所示:</p><p><img src="https://s2.loli.net/2022/12/20/nTjfvoBepUQLMay.png"></p><p><strong>从用户面看:</strong></p><p>DC场景下，UE和网络可能建立MCG Bearer、SCG Bearer和Split Bearer。NSA option 3x用户面承载概念如下图1-26所示:</p><p><img src="https://s2.loli.net/2022/12/20/WGv2t7ZCgDBqpwy.png"></p><blockquote><p>知识点：</p><ul><li>MCG 主小区组</li><li>SCG 辅小区组</li><li>小区  在蜂窝移动通信系统中，其中的一个基站或基站的一部分，与大区相对应</li></ul></blockquote><h4 id="DC与CA-Carrier-Aggregation，载波聚合）对比"><a href="#DC与CA-Carrier-Aggregation，载波聚合）对比" class="headerlink" title="DC与CA (Carrier Aggregation，载波聚合）对比"></a>DC与CA (Carrier Aggregation，载波聚合）对比</h4><p>3GPP在R10版本引入CA这一概念。<strong>CA技术</strong>中终端也会与多个接入网网元建立连接，但是<strong>控制面连接仅有一个</strong>。双连接与载波聚合的对比如下表1-4所示。</p><p><img src="https://s2.loli.net/2022/12/20/M6CQwzImXg18GdZ.png"></p><h3 id="CU-x2F-DU组网部署"><a href="#CU-x2F-DU组网部署" class="headerlink" title="CU&#x2F;DU组网部署"></a>CU&#x2F;DU组网部署</h3><p>根据不同的业务和部署场景，NR架构总体可以分为<strong>CU和DU</strong>两级，但是实际部署可以出现<strong>CU、DU和AAU分离的三级配置</strong>，也可以出现<strong>AAU直接连入中心结点</strong>。</p><p><img src="https://s2.loli.net/2022/12/20/vsWBDGNSqhKJUVa.png"></p><h4 id="eMBB"><a href="#eMBB" class="headerlink" title="eMBB"></a>eMBB</h4><p>为了支持eMBB业务的覆盖和容量需求，CU和DU需要进行分离部署，分为两种形式: <strong>Macro(宏)方式和Micro(微)方式</strong>。CU&#x2F;DU分离Macro和Micro组网部署如图1-27所示。</p><p><img src="https://s2.loli.net/2022/12/20/InCchUTDS2G8tyF.png" alt="image-20221220170026996"></p><blockquote><p>知识点：</p><ul><li><p>前传资源有限-分离（就近部署）</p></li><li><p>前传资源丰富-合设</p></li></ul></blockquote><p>当业务容量需求变高，在密集部署情况下，<strong>基于理想前传条件</strong>，<strong>多个DU可以联合部署，形成基带池</strong>，<strong>提高基站资源池的利用率</strong>，并且可以利用多小区协作传输和协作处理以<strong>提高网络的覆盖和容量</strong>。CU\DU分离DU资源池组网方式如图1-28所示:</p><p><img src="https://s2.loli.net/2022/12/20/GvuZjrfKbDWnI3a.png"></p><p><strong>CU&#x2F;DU分离</strong>针对高时延和低时延部署方式如图1-29所示。</p><p><img src="https://s2.loli.net/2022/12/20/4q3MIAPSsoziN7K.png" alt="image-20221220170342405"></p><ul><li><p>语音业务对带宽和时延要求不高，此时DU可以部署在基站侧;</p></li><li><p>对于大带宽<strong>低时延</strong>业务〈如视频或者虚拟现实)，一般需要高速传输网络或者光纤直接连接中心机房，并在中心机房部署缓存服务器，以降低时延并提升用户体验。</p></li></ul><h3 id="mMTC"><a href="#mMTC" class="headerlink" title="mMTC"></a>mMTC</h3><p>对于面向垂直行业的机器通信业务，在建设5G网络时，需要考虑机器通信的特点。</p><p><strong>【大连接】****大规模机器通信普遍对时延要求较低</strong>,其特点有2个:</p><ul><li><p>数据量少而且站点稀疏</p></li><li><p>站点数量多，且分布密集。</p></li></ul><p>CU&#x2F;DU分离针对mMTC的部署方式如图1-30所示。</p><p><img src="https://s2.loli.net/2022/12/20/WrYvXuoV6hUGRSd.png"></p><h2 id="附录"><a href="#附录" class="headerlink" title="附录"></a>附录</h2><h3 id="Option划分方案"><a href="#Option划分方案" class="headerlink" title="Option划分方案"></a>Option划分方案</h3><p><img src="https://s2.loli.net/2022/12/20/1KlxB9p8ivMWm7o.png" alt="划分方案"></p><h3 id="缩略词目录"><a href="#缩略词目录" class="headerlink" title="缩略词目录"></a>缩略词目录</h3><p><img src="https://s2.loli.net/2022/12/20/Dmirc9lMszZA4nt.png"></p>]]></content>
      
      
      <categories>
          
          <category> 学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 通信工程 </tag>
            
            <tag> 大唐杯 </tag>
            
            <tag> 5G </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>5G网络架构和组网部署-1</title>
      <link href="/2022/12/18/5G%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84%E9%A2%84%E5%A4%87%E7%9F%A5%E8%AF%86/"/>
      <url>/2022/12/18/5G%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84%E9%A2%84%E5%A4%87%E7%9F%A5%E8%AF%86/</url>
      
        <content type="html"><![CDATA[<h1 id="预备知识"><a href="#预备知识" class="headerlink" title="预备知识"></a>预备知识</h1><p>太多名词看的晕晕乎乎的这里可以让你豁然开朗</p><h2 id="名词汇总"><a href="#名词汇总" class="headerlink" title="名词汇总"></a>名词汇总</h2><h3 id="核心网与接入网"><a href="#核心网与接入网" class="headerlink" title="核心网与接入网"></a>核心网与接入网</h3><table><thead><tr><th>名词</th><th>定义</th></tr></thead><tbody><tr><td>核心网</td><td>核心网部分就是位于网络子系统内，核心网的主要作用是把A口上来的呼叫请求或数据请求，接续到不同的网络上。</td></tr><tr><td>接入网</td><td>所谓接入网是指核心网络到用户终端之间的所有设备，其长度一般为几百米到几公里，因而被形象地称为”最后一公里”。</td></tr></tbody></table><p>个人理解，核心网和接入网的定义比较好理解，就像是快递公司，会把一座城市的快递收集起来，这部分是接入网，再根据快递的信息处理其下一步应该发往哪个城市，这个快递公司的工作就是核心网。</p><h3 id="5G网络架构"><a href="#5G网络架构" class="headerlink" title="5G网络架构"></a>5G网络架构</h3><table><thead><tr><th>名词</th><th>定义</th></tr></thead><tbody><tr><td>SA组网</td><td>(Standalone)5G独立组网</td></tr><tr><td>NSA组网</td><td>(Non-Standalone)5G非独立组网</td></tr><tr><td>NB</td><td>3G基站代称</td></tr><tr><td>eNB</td><td>4G基站代称</td></tr><tr><td>gNB</td><td>5G基站代称</td></tr><tr><td>en-gNB</td><td>承载部分4G业务的5G基站代称</td></tr><tr><td>gn-eNB</td><td>承载部分5G业务的4G基站代称</td></tr><tr><td>5GC</td><td>5G核心网</td></tr><tr><td>NG-（R）AN</td><td>由多个与5GC连接的gNB组成的(无线)接入网</td></tr><tr><td>NG接口</td><td>无线接入网和5G核心网之间的接口</td></tr><tr><td>Xn接口</td><td>NG-RAN节点（gNB或ng-eNB）之间的网络接口</td></tr></tbody></table><p>学习网络就要学习他的发展过程。经济基础决定上层建筑，在建设5G的过程中不可能把3G、4G的基站全拆了换成5G。他是逐步演进逐步替换的过程。因此现在的5G组网也借助了4G的一些物理设备。有部分4G设备构成的5G网络就是NSA了。<br>从整个网络发展上看，很多新技术新协议的出现都要兼容老的一些协议，主要是我们的互联网过于庞大，想要进行迭代更新，也要考虑一些经济和一些现实问题。<br>NG接口分为NG-C接口控制面接口和NG-U接口用户面接口。<br><img src="https://s2.loli.net/2022/12/20/5HVgPoOyQdWYx2Z.png" alt="在这里插入图片描述"></p><h3 id="核心网架构演进"><a href="#核心网架构演进" class="headerlink" title="核心网架构演进"></a>核心网架构演进</h3><h4 id="2G核心网"><a href="#2G核心网" class="headerlink" title="2G核心网"></a>2G核心网</h4><table><thead><tr><th>名词</th><th>定义</th></tr></thead><tbody><tr><td>PCM</td><td>脉冲编码调制</td></tr><tr><td>TDM</td><td>时分复用技术</td></tr><tr><td>分组通信</td><td>利用无线信道以分组方式传送数据或话音信息的通信</td></tr><tr><td>PDH</td><td>准同步数字系列，美日采用μ律，欧洲和我国采用A律</td></tr><tr><td>SDH</td><td>同步数字体系，PDH改进型，速度更快，统一了光接口</td></tr><tr><td>X.25</td><td>是目前使用最广泛的分组交换协议</td></tr><tr><td>ATM</td><td>异步传递方式，采用统计时分复用</td></tr><tr><td>STM</td><td>同步传递方式，采用时分复用</td></tr></tbody></table><h4 id="3G，4G核心网"><a href="#3G，4G核心网" class="headerlink" title="3G，4G核心网"></a>3G，4G核心网</h4><table><thead><tr><th>名词</th><th>定义</th></tr></thead><tbody><tr><td>MPLS</td><td>多协议标签交换，用于不同的包转发和包交换技术，面向连接</td></tr><tr><td>SDN</td><td>软件定义网络，将数据与控制相分离</td></tr><tr><td>NFV</td><td>网络功能虚拟化</td></tr><tr><td>Open Stack</td><td>一个云计算平台项目，覆盖了网络、虚拟化、操作系统、服务器等各个方面</td></tr></tbody></table><p><img src="https://s2.loli.net/2022/12/20/EpbWXBL9YH6RVN7.png" alt="在这里插入图片描述"></p><h4 id="4G核心网架构"><a href="#4G核心网架构" class="headerlink" title="4G核心网架构"></a>4G核心网架构</h4><table><thead><tr><th>名词</th><th>定义</th></tr></thead><tbody><tr><td>LTE</td><td>长期演进技术，3G与4G技术之间的过渡</td></tr><tr><td>UE</td><td>终端</td></tr><tr><td>Uu</td><td>空中接口</td></tr><tr><td>E-UTRAN</td><td>演进的UMTS陆地无线接入网，即LTE移动通信无线网络</td></tr><tr><td>S1-U</td><td>eNodeB（基站）与 EPC（分组核心网）之间的通讯接口，-U同上表示用户数据部分</td></tr><tr><td>GW-U</td><td>Gateway是网关，百度上有GW-S表示服务网关，猜测这里表示用户(User)网关</td></tr><tr><td>SGi</td><td>与外部数据网络对接</td></tr><tr><td>HSS</td><td>归属用户服务器，负责管理用户的签约数据及移动用户的位置信息</td></tr><tr><td>MME</td><td>移动性管理实体，负责处理信令</td></tr><tr><td>SGW</td><td>服务网关，负责处理业务流</td></tr><tr><td>CG</td><td>计费网关&#x2F;计费网关，负责完成计费话单的检错、纠错和话单的合并,并完成话单格式的转换</td></tr><tr><td>PGW</td><td>分组数据网网关，负责分组数据包路由和转发；3GPP和非3GPP网络间的Anchor功能；P地址分配等</td></tr><tr><td>PCRF</td><td>策略和计费规则功能，是业务数据流和IP承载资源的策略和计费控制判决单元</td></tr></tbody></table><p>从图中可以很好的看出数据和控制分离。<br><img src="https://s2.loli.net/2022/12/20/b4oeiTJB2r3IQhq.png" alt="在这里插入图片描述"></p><h4 id="5G核心网架构"><a href="#5G核心网架构" class="headerlink" title="5G核心网架构"></a>5G核心网架构</h4><table><thead><tr><th>名词</th><th>定义</th></tr></thead><tbody><tr><td>UE</td><td>终端</td></tr><tr><td>AN</td><td>接入网</td></tr><tr><td>UPF</td><td>用户面功能</td></tr><tr><td>DN</td><td>数据中心</td></tr><tr><td>NF</td><td>网元功能体</td></tr><tr><td>NSSF</td><td>网络切片选择功能</td></tr><tr><td>NEF</td><td>网络开放功能</td></tr><tr><td>NRF</td><td>网络仓储功能，支持服务发现功能</td></tr><tr><td>PCF</td><td>策略控制功能，主要功能是使用统一的策略框架来管理网络行为</td></tr><tr><td>UDM</td><td>统一数据管理，通过生成3GPPAKA身份验证凭据，通过对SUPI的存储和管理，对用户进行识别处理，对用户进行合法性验证</td></tr><tr><td>AF</td><td>应用功能，指应用层的各种服务</td></tr><tr><td>AUSF</td><td>鉴权服务器功能，处理3GPP接入和非3GPP接入的认证请求</td></tr><tr><td>AMF</td><td>接入和移动管理功能，负责注册管理，连接管理，可达性管理，移动性管理等功能</td></tr><tr><td>SMF</td><td>会话管理功能，负责会话建立，修改和释放等</td></tr></tbody></table><p><img src="https://s2.loli.net/2022/12/20/Lhzji6lAkqQFOCw.png" alt="在这里插入图片描述"></p><h4 id="5G接入网网架构"><a href="#5G接入网网架构" class="headerlink" title="5G接入网网架构"></a>5G接入网网架构</h4><table><thead><tr><th>名词</th><th>定义</th></tr></thead><tbody><tr><td>CU</td><td>集中单元</td></tr><tr><td>DU</td><td>分布单元</td></tr></tbody></table><p><img src="https://s2.loli.net/2022/12/20/KZVFSmhsGeCLTA6.png" alt="在这里插入图片描述"></p><h4 id="主要网元功能"><a href="#主要网元功能" class="headerlink" title="主要网元功能"></a>主要网元功能</h4><table><thead><tr><th>名词</th><th>定义</th></tr></thead><tbody><tr><td>小区</td><td>在蜂窝移动通信系统中，其中的一个基站或基站的一部分，与大区相对应</td></tr><tr><td>移动锚点</td><td>当用户在不同接入系统之间移动时，可以保证该网元分配的用户地址保持不变</td></tr><tr><td>PDU</td><td>协议数据单元</td></tr><tr><td>N接口</td><td>5G网元直接的通信接口，例如N1,N22等</td></tr><tr><td>Nplink</td><td>交换机上的一种端口，在点到多点系统中，由分散点到集中点的传输链路。例如：在移动通信中，由移动台到基站的链路</td></tr><tr><td>移动台</td><td>移动终端设备</td></tr><tr><td>QoS</td><td>服务质量，虽然翻译成服务质量，但是他是用来解决网络延迟和阻塞等问题的一种技术</td></tr><tr><td>ul&#x2F;dl</td><td>up link&#x2F;down link 上行&#x2F;下行链路</td></tr><tr><td>SDF</td><td>service data flow 服务数据流</td></tr><tr><td>NAS</td><td>非接入层 作为核心网与用户设备之间的功能层。该层支持在这两者之间的信令和数据传输</td></tr><tr><td>信令</td><td>控制信号</td></tr><tr><td>SM</td><td>服务消息</td></tr><tr><td>SMS</td><td>短信消息</td></tr><tr><td>SMSF</td><td>短信消息管理功能</td></tr><tr><td>GTP</td><td>GPRS隧道协议</td></tr><tr><td>RRC</td><td>无线资源控制层</td></tr><tr><td>PDCP</td><td>分组数据汇聚协议</td></tr><tr><td>RLC</td><td>无线链路控制协议</td></tr></tbody></table><h2 id="5G主要网元功能"><a href="#5G主要网元功能" class="headerlink" title="5G主要网元功能"></a>5G主要网元功能</h2><h3 id="用户面功能UPF-User-Plane-Function"><a href="#用户面功能UPF-User-Plane-Function" class="headerlink" title="用户面功能UPF(User Plane Function)"></a>用户面功能UPF(User Plane Function)</h3><ul><li>gNodeB间切换的本地移动锚点(适用时)</li><li>连接到移动通信网络的外部PDU会话点</li><li>基于N接口切换过程中，数据包路由与转发</li><li>数据包检查和用户面部分的策略计费</li><li>合法的监听拦截(集合)</li><li>流量使用情况报告</li><li>Uplink支持路由流量到一个数据网络</li><li>分支点以支持多类的PDU会话</li><li>对用户平面的QoS处理，例如包过滤、门控、ul&#x2F;dl速率执行</li><li>Uplink流量验证(SDF到QoS流映射)</li><li>上下行链路上传输级别的数据包标记</li><li>下行数据包缓冲和下行数据通知触发</li></ul><h3 id="会话管理功能SMF-Session-Management-Function"><a href="#会话管理功能SMF-Session-Management-Function" class="headerlink" title="会话管理功能SMF(Session Management Function)"></a>会话管理功能SMF(Session Management Function)</h3><ul><li>会话的建立修改删除</li><li>包括tunnel maintain between UPF and AN node（UPF和节点之间的隧道维护）</li><li>UE IP地址的分配和管理</li><li>DHCPv4（服务器和客户端）和DHCPv6（服务器和客户端）功能</li><li>选择控制用户面功能</li><li>QoS策略与控制，终止策略与控制</li><li>合法监听</li><li>Termination of SM parts of NAS messages（终止NAS消息的SM部分）</li><li>下行数据的通知</li><li>漫游功能</li></ul><h3 id="访问和移动性管理功能AMF-Access-and-Mobility-Management-Function"><a href="#访问和移动性管理功能AMF-Access-and-Mobility-Management-Function" class="headerlink" title="访问和移动性管理功能AMF(Access and Mobility Management Function)"></a>访问和移动性管理功能AMF(Access and Mobility Management Function)</h3><ul><li>NAS信令及信令的加密和完整性保护</li><li>终止运行RAN网络接口(N2)</li><li>注册管理</li><li>连接管理</li><li>NAS移动性管理</li><li>合法的截距(用于AMF事件和对Ll系统的接口)</li><li>为在UE和SMF之间的SM消息提供传输</li><li>路由SM消息的透明代理</li><li>访问验证</li><li>在UE和SMSF之间提供SMS消息的传输</li><li>用户鉴权及密钥管理</li><li>承载管理功能，包括专用承载建立过程</li></ul><h3 id="gNB-x2F-en-gNB（基站）"><a href="#gNB-x2F-en-gNB（基站）" class="headerlink" title="gNB&#x2F;en-gNB（基站）"></a>gNB&#x2F;en-gNB（基站）</h3><ul><li>中央单元-控制面CU-C(Central Unit - Control plane)</li></ul><table><thead><tr><th>功能</th><th>解释</th></tr></thead><tbody><tr><td>接口管理(Interface Management)</td><td>包括:Xn&#x2F;NG&#x2F;F1&#x2F;E1等接口链路管理、接口消息处理(如:NG-AP)和数据处理(如:GTP-U)</td></tr><tr><td>连接管理(Connection Management)</td><td>单连接、双连接、多连接和D2D</td></tr><tr><td>流量导向(Traffic Steering)</td><td>系统内和系统间的负载均衡</td></tr><tr><td>切片支持(Slice Support)</td><td>系统内和系统间的切片资源动态管理</td></tr></tbody></table><ul><li>中央单元-用户面CU-U(Central Unit - User plane)<br>主要功能：数据包的处理和转换</li><li>分布单元(Distributed Unit)<br>主要功能：资源的调度 传输模式的转换 信道映射</li><li>有源天线处理单元 - 天线AAU-RF(Active Antenna Unit - Radio Frequency)<br>主要功能：信号的收发 Massive MIMO天线处理 频率与时间同步 AAS实现机制</li></ul><h2 id="5G接口主要功能"><a href="#5G接口主要功能" class="headerlink" title="5G接口主要功能"></a>5G接口主要功能</h2><h3 id="NG接口主要功能"><a href="#NG接口主要功能" class="headerlink" title="NG接口主要功能"></a>NG接口主要功能</h3><table><thead><tr><th>NG-C接口功能与流程</th><th>具体描述</th></tr></thead><tbody><tr><td>PDU会话管理过程</td><td>完成PDU会话的NG-RAN资源建立，释放或修改过程</td></tr><tr><td>UE上下文管理过程</td><td>完成UE上下文建立，释放或修改过程</td></tr><tr><td>NAS发送过程</td><td>完成AMF和UE间的NAS信令数据透传过程； 初始UE消息(NG-RAN node发起)、上行NAS传输(NG-RAN node发起)、上行NAS传输(NG-RAN node发起)、下行NAS传输(AMF发起)、NAS无法传输指示(NG-RAN node发起)、重新路由NAS请求(AMF发起)</td></tr><tr><td>UE移动性管理过程</td><td>完成UE移动切换的准备，执行或取消过程；切换准备、切换资源分配、切换通知、路径切换请求、上下行RAN状态转发、切换取消</td></tr><tr><td>寻呼过程</td><td>完成寻呼区域内向NG-RAN节点发送寻呼请求过程</td></tr><tr><td>AMF管理过程</td><td>完成AMF告知NG-RAN节点AMF状态和去激活与指定UE NGAP UE组合过程 ；AMF状态指示、NGAP组合去激活(FFS)</td></tr><tr><td>NG接口管理过程</td><td>完成NG接口管理过程；NG建立、NG重置、RAN配置更新、AMF配置更新、错误指示</td></tr></tbody></table><p>NG-U接口主要功能：</p><ul><li>NG-U接口在NG-RAN节点和UPF之间提供非保证的用户平面PDU传送；</li><li>协议栈传输网络层建立在lP传输上；</li><li>GTP-U在UDPIIP之上用于承载NG-RAN节点和UPF之间的用户面PDU。</li></ul><h3 id="Xn接口主要功能"><a href="#Xn接口主要功能" class="headerlink" title="Xn接口主要功能"></a>Xn接口主要功能</h3><table><thead><tr><th>Xn-C接口功能与流程</th><th>功能描述</th></tr></thead><tbody><tr><td>Xn建立功能</td><td>允许两个NG-RAN nodes间Xn接口的初始建立，包括应用层数据交互</td></tr><tr><td>差错指示功能</td><td>允许应用层上一般错误情况上报</td></tr><tr><td>Xn重置功能</td><td>允许NG-RAN node告知另一个NG-RAN node其已经从非正常失败状态恢复，第二个node内需要删除与第一个node相关的所有上下文(应用层数据除外)并释放伴生资源</td></tr><tr><td>Xn配置数据更新功能</td><td>允许两个NG-RAN nodes随时更新应用层数据</td></tr><tr><td>切换准备功能</td><td>允许源和目的NG-RAN node间的信息交互从而完成给定UE到目的NG-RAN node初始切换</td></tr><tr><td>切换取消功能</td><td>允许通知已准备好的目的NG-RAN node准备的切换不进行，同时释放切换准备期间的资源分配</td></tr><tr><td>恢复UE上下文功能</td><td>允许NG-RAN node从其他node恢复UE上下文</td></tr><tr><td>RAN寻呼功能</td><td>允许NG-RAN node初始化非激活态UE的寻呼功能</td></tr><tr><td>数据转发控制功能</td><td>允许源和目的NG-RAN nodes间用于数据转发传输承载的建立和释放</td></tr><tr><td>双链接功能</td><td>使能NG-RAN中辅助节点内额外资源的使用</td></tr></tbody></table><p>Xn-U接口主要功能：</p><ul><li>Xn-U接口提供用户平面PDU的非保证传送，并支持分离Xn接口为无线网络功能和传输网络功能，以促进未来技术的引入；</li><li>数据转发功能，允许NG-RAN节点间数据转发从而支持双连接和移动性操作；</li><li>流控制功能，允许NG-RAN节点接收第二个节点的用户面数据从而提供数据流相关的反馈信息。</li></ul><h3 id="E1接口主要功能"><a href="#E1接口主要功能" class="headerlink" title="E1接口主要功能"></a>E1接口主要功能</h3><p>E1接口管理功能：</p><ul><li>错误指示（gNB-CU-UP或者gNB-CU-CP向gNB-CU-CP或者gNB-CU-CP 发出错误指示)；</li><li>复位功能用于gNB-CU-UP与gNB-CU-CP建立之后和发生故障事件之后初始化对等实体；</li><li>gNB-CU-UP与gNB-CU-CP之间应用层数据的互操作；</li><li>gNB-CU-UP配置更新: gNB-CU-UP将NRCGl、s - nssai、PLMN-ID和gNB-CU-UP支持的QoS信息通知给gNB-CU-CP。</li></ul><p>E1上下文管理功能：</p><ul><li>上下文承载建立（ gNB-CU-CP ) ;</li><li>上下文承载修改与释放（可以由gNB-CU或gNB-DU发起)；</li><li>QoS流映射(gNB-CU执行)；</li><li>下行数据通知（ gNB-CU-UP发起)；</li><li>承载不活动通知；</li><li>数据使用情况报告（gNB-CU-UP发起)。</li></ul><p>TE ID分配功能(gNB-CU-UP)：</p><ul><li>F1-U UL GTP TEID、S1-U DL GTP TEID、NG-U DL GTP TEID X2-U DL&#x2F;UL GTP<br>TEID、Xn-D DL&#x2F;UL GTP TEID</li></ul><h3 id="F1接口主要功能"><a href="#F1接口主要功能" class="headerlink" title="F1接口主要功能"></a>F1接口主要功能</h3><p>F1接口管理功能：</p><ul><li>F1接口管理功能错误指示；</li><li>复位功能用于在节点建立之后和发生故障事件之后初始化对等实体；</li></ul><p>系统信息管理功能：</p><ul><li>系统广播信息的调度在gNB-DU中执行，gNB-DU负责NR-MIB、SIB1的编码，gNB-CU负责其他SI消息的编码。</li></ul><p>F1 UE上下文管理功能：</p><ul><li>基于接纳控制准则、由gNB-CU发起并由gNB-DU接受或拒绝F1 UE上下文的建立；</li><li>UE上下文的修改(可以由gNB-CU或gNB-DU发起)；</li><li>QoS流和无线承载之间的映射(gNB-CU执行)；</li><li>管理建立,修改和释放DRB和SRB资源（DRB资源的建立和修改由gNB-CU触发)。</li></ul><p>RRC消息传送功能：</p><ul><li>RRC消息通过F1-C传送，gNB-CU负责用gNB-DU提供的辅助信息对专用RRC消息进行编码。</li></ul><p>F1-U接口主要功能功能：</p><ul><li>用户数据传输(Transfer of user data)；</li><li>CU和DU之间传输用户数据；</li><li>流量控制功能（Flow control function)；</li><li>控制下行用户数据流向DU。</li></ul><h3 id="Uu接口主要功能"><a href="#Uu接口主要功能" class="headerlink" title="Uu接口主要功能"></a>Uu接口主要功能</h3><p><img src="https://s2.loli.net/2022/12/20/jTzo1qhRNQ8VJUK.png" alt="在这里插入图片描述"></p><p><img src="https://s2.loli.net/2022/12/20/7blWmGKVNPJqjpY.png" alt="在这里插入图片描述"></p><h2 id="SA与NSA组网"><a href="#SA与NSA组网" class="headerlink" title="SA与NSA组网"></a>SA与NSA组网</h2><h3 id="常用的NSA组网方式"><a href="#常用的NSA组网方式" class="headerlink" title="常用的NSA组网方式"></a>常用的NSA组网方式</h3><p><img src="https://s2.loli.net/2022/12/20/xa79JbA5Zc2NmrD.png" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/be2af9178110404db73660d8cb2ac4fd.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAT2JzX2N1cmU=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></p><p><img src="https://img-blog.csdnimg.cn/49ca414e857a4adc971cedc85f389493.png" alt="在这里插入图片描述"></p><h3 id="NSA与SA组网方案对比"><a href="#NSA与SA组网方案对比" class="headerlink" title="NSA与SA组网方案对比"></a>NSA与SA组网方案对比</h3><table><thead><tr><th>分类</th><th>非独立NR(NSA)架构</th><th>独立NR(SA)架构</th></tr></thead><tbody><tr><td>支持功能</td><td>仅支持eMBB</td><td>全部5G功能</td></tr><tr><td>LTE现网</td><td>需要升级LTE基站以及核心网支持NSA</td><td>不影响现网LTE</td></tr><tr><td>终端</td><td>5G NR下需要提供Customized 4G NAS UE with 5G RRC；eLTE理论支持LTE终端</td><td>5G NR下使用5G UE；LTE终端继续使用在LTE网络下</td></tr><tr><td>5G新频NR以及天线</td><td>全部新加，不管高低频</td><td>全部新加，不管高低频</td></tr><tr><td>核心网</td><td>初期只需要升级现网EPC，后期可以选择新建5G核心网支持eLTE</td><td>新加5G核心网</td></tr><tr><td>初期成本</td><td>低</td><td>高</td></tr><tr><td>后期维护成本</td><td>高（升级软件需要升级LTE基站）</td><td>低</td></tr><tr><td>组网</td><td>复杂(需要考虑到LTE的链路)</td><td>简单</td></tr><tr><td>IOT对接</td><td>不需要5GNR接入与核心网跨异厂家IOT测试LTE或eLTE跟升级后的EPC IOT需要对接验证</td><td>需要5G NR与5G核心网跨异厂家IOT测试成熟loT需要很长时间</td></tr><tr><td>演进</td><td>可以通过升级与网络调整变成SA</td><td>SA是最终模式</td></tr></tbody></table><h2 id="MR-DC技术"><a href="#MR-DC技术" class="headerlink" title="MR-DC技术"></a>MR-DC技术</h2><p>MR-DC(Multi-RAT Dual Connectivity，多接入网技术双连接)是指一部终端可以同时连接4G网络和5G网络，同时使用两个网络进行业务，此时终端需要具备至少两个MAC实体，支持双发双收。对应不同的网络架构，双连接有不同的名称。</p><table><thead><tr><th align="left">核心网</th><th align="left">主节点</th><th align="left">辅节点</th><th>名称</th></tr></thead><tbody><tr><td align="left">EPC</td><td align="left">E-UTRA</td><td align="left">E-UTRA</td><td>DC</td></tr><tr><td align="left">EPC</td><td align="left">E-UTRA</td><td align="left">NR</td><td>EN-DC</td></tr><tr><td align="left">5GC</td><td align="left">NG-RAN E-UTRA</td><td align="left">NR</td><td>NGEN-DC</td></tr><tr><td align="left">5GC</td><td align="left">NR</td><td align="left">E-UTRA</td><td>NE-DC</td></tr><tr><td align="left">5GC</td><td align="left">NR</td><td align="left">NR</td><td>NR-DC</td></tr></tbody></table><h2 id="参考文章"><a href="#参考文章" class="headerlink" title="参考文章"></a>参考文章</h2><ul><li><a href="https://blog.csdn.net/Obs_cure/article/details/122732359">CSDN某大佬的笔记</a></li></ul><ul><li><a href="https://blog.csdn.net/weixin_45022086/article/details/108751296">5GC中名词解释_蟹老板不会CPP的博客</a></li><li><a href="https://zhuanlan.zhihu.com/p/86143276">5G系统中无线接入网中接口的定义和功能</a></li><li><a href="https://blog.csdn.net/dingyun00196932/article/details/46548699">LTE网络主要接口信息</a></li><li><a href="https://blog.csdn.net/LaoYuanPython/article/details/105394978">老猿学5G随笔：RAN、RAT以及anchor移动性锚点的概念</a></li><li><a href="https://zhuanlan.zhihu.com/p/158742066">5G网络结构核心网侧接口介绍</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> 学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 通信工程 </tag>
            
            <tag> 大唐杯 </tag>
            
            <tag> 5G </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>AlexNet-3</title>
      <link href="/2022/12/16/AlexNet%E5%AE%9E%E8%B7%B5%E7%BB%83%E4%B9%A0/"/>
      <url>/2022/12/16/AlexNet%E5%AE%9E%E8%B7%B5%E7%BB%83%E4%B9%A0/</url>
      
        <content type="html"><![CDATA[<h1 id="AlexNet实践练习"><a href="#AlexNet实践练习" class="headerlink" title="AlexNet实践练习"></a>AlexNet实践练习</h1><h2 id="代码部分"><a href="#代码部分" class="headerlink" title="代码部分"></a>代码部分</h2><h3 id="文件预处理"><a href="#文件预处理" class="headerlink" title="文件预处理"></a>文件预处理</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> shutil <span class="keyword">import</span> copy, rmtree</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">mk_file</span>(<span class="params">file_path: <span class="built_in">str</span></span>):</span><br><span class="line">    <span class="keyword">if</span> os.path.exists(file_path):</span><br><span class="line">        <span class="comment"># 如果文件夹存在，则先删除原文件夹在重新创建</span></span><br><span class="line">        rmtree(file_path)</span><br><span class="line">    os.makedirs(file_path)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    <span class="comment"># 保证随机可复现</span></span><br><span class="line">    random.seed(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 将数据集中10%的数据划分到验证集中</span></span><br><span class="line">    split_rate = <span class="number">0.1</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 指向你解压后的flower_photos文件夹</span></span><br><span class="line">    cwd = os.getcwd()</span><br><span class="line">    data_root = os.path.join(cwd, <span class="string">&quot;flower_data&quot;</span>)</span><br><span class="line">    origin_flower_path = os.path.join(data_root, <span class="string">&quot;flower_photos&quot;</span>)</span><br><span class="line">    <span class="keyword">assert</span> os.path.exists(origin_flower_path), <span class="string">&quot;path &#x27;&#123;&#125;&#x27; does not exist.&quot;</span>.<span class="built_in">format</span>(origin_flower_path)</span><br><span class="line"></span><br><span class="line">    flower_class = [cla <span class="keyword">for</span> cla <span class="keyword">in</span> os.listdir(origin_flower_path)</span><br><span class="line">                    <span class="keyword">if</span> os.path.isdir(os.path.join(origin_flower_path, cla))]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 建立保存训练集的文件夹</span></span><br><span class="line">    train_root = os.path.join(data_root, <span class="string">&quot;train&quot;</span>)</span><br><span class="line">    mk_file(train_root)</span><br><span class="line">    <span class="keyword">for</span> cla <span class="keyword">in</span> flower_class:</span><br><span class="line">        <span class="comment"># 建立每个类别对应的文件夹</span></span><br><span class="line">        mk_file(os.path.join(train_root, cla))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 建立保存验证集的文件夹</span></span><br><span class="line">    val_root = os.path.join(data_root, <span class="string">&quot;val&quot;</span>)</span><br><span class="line">    mk_file(val_root)</span><br><span class="line">    <span class="keyword">for</span> cla <span class="keyword">in</span> flower_class:</span><br><span class="line">        <span class="comment"># 建立每个类别对应的文件夹</span></span><br><span class="line">        mk_file(os.path.join(val_root, cla))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> cla <span class="keyword">in</span> flower_class:</span><br><span class="line">        cla_path = os.path.join(origin_flower_path, cla)</span><br><span class="line">        images = os.listdir(cla_path)</span><br><span class="line">        num = <span class="built_in">len</span>(images)</span><br><span class="line">        <span class="comment"># 随机采样验证集的索引</span></span><br><span class="line">        eval_index = random.sample(images, k=<span class="built_in">int</span>(num*split_rate))</span><br><span class="line">        <span class="keyword">for</span> index, image <span class="keyword">in</span> <span class="built_in">enumerate</span>(images):</span><br><span class="line">            <span class="keyword">if</span> image <span class="keyword">in</span> eval_index:</span><br><span class="line">                <span class="comment"># 将分配至验证集中的文件复制到相应目录</span></span><br><span class="line">                image_path = os.path.join(cla_path, image)</span><br><span class="line">                new_path = os.path.join(val_root, cla)</span><br><span class="line">                copy(image_path, new_path)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="comment"># 将分配至训练集中的文件复制到相应目录</span></span><br><span class="line">                image_path = os.path.join(cla_path, image)</span><br><span class="line">                new_path = os.path.join(train_root, cla)</span><br><span class="line">                copy(image_path, new_path)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;\r[&#123;&#125;] processing [&#123;&#125;/&#123;&#125;]&quot;</span>.<span class="built_in">format</span>(cla, index+<span class="number">1</span>, num), end=<span class="string">&quot;&quot;</span>)  <span class="comment"># processing bar</span></span><br><span class="line">        <span class="built_in">print</span>()</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;processing done!&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    main()</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="model-py"><a href="#model-py" class="headerlink" title="model.py"></a>model.py</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#导入包</span></span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="comment">#创建网络</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">AlexNet</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, num_classes=<span class="number">1000</span>, init_weights=<span class="literal">False</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(AlexNet, self).__init__()</span><br><span class="line">        <span class="comment"># 用nn.Sequential()将网络打包成一个模块，精简代码</span></span><br><span class="line">        <span class="comment"># &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="comment"># 为了加快训练，代码只使用了一半的网络参数，相当于只用了原论文中网络结构的一半部分（正好原论文中用的双GPU，我的电脑只有一块GPU）</span></span><br><span class="line">        <span class="comment"># 后来我又用完整网络跑了遍，发现一半参数跟完整参数的训练结果acc相差无几）</span></span><br><span class="line">        <span class="comment"># &#x27;&#x27;&#x27;</span></span><br><span class="line">        self.features = nn.Sequential(  <span class="comment"># 卷积层提取图像特征</span></span><br><span class="line">            nn.Conv2d(<span class="number">3</span>, <span class="number">48</span>, kernel_size=<span class="number">11</span>, stride=<span class="number">4</span>, padding=<span class="number">2</span>),  <span class="comment"># input[3, 224, 224]  output[48, 55, 55]</span></span><br><span class="line">            <span class="comment"># &#x27;&#x27;&#x27;</span></span><br><span class="line">            <span class="comment"># 此处paddding=2 是将四周补上2列0；</span></span><br><span class="line">            <span class="comment"># padding=（a,b）a代表上下补0行数，b代表左右补0列数；</span></span><br><span class="line">            <span class="comment"># 若要实现论文中padding效果 可以使用nn.ZeroPad(a,b,c,d)上下左右</span></span><br><span class="line">            <span class="comment"># &#x27;&#x27;&#x27;</span></span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),  <span class="comment"># 直接修改覆盖原值，节省运算内存</span></span><br><span class="line">            nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>),  <span class="comment"># output[48, 27, 27]</span></span><br><span class="line">            nn.Conv2d(<span class="number">48</span>, <span class="number">128</span>, kernel_size=<span class="number">5</span>, padding=<span class="number">2</span>),  <span class="comment"># output[128, 27, 27]</span></span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>),  <span class="comment"># output[128, 13, 13]</span></span><br><span class="line">            nn.Conv2d(<span class="number">128</span>, <span class="number">192</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>),  <span class="comment"># output[192, 13, 13]</span></span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.Conv2d(<span class="number">192</span>, <span class="number">192</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>),  <span class="comment"># output[192, 13, 13]</span></span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.Conv2d(<span class="number">192</span>, <span class="number">128</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>),  <span class="comment"># output[128, 13, 13]</span></span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>),  <span class="comment"># output[128, 6, 6]</span></span><br><span class="line">        )</span><br><span class="line">        self.classifier = nn.Sequential(  <span class="comment"># 全连接层对图像分类</span></span><br><span class="line">            nn.Dropout(p=<span class="number">0.5</span>),  <span class="comment"># Dropout 随机失活神经元，默认比例为0.5</span></span><br><span class="line">            nn.Linear(<span class="number">128</span> * <span class="number">6</span> * <span class="number">6</span>, <span class="number">2048</span>),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.Dropout(p=<span class="number">0.5</span>),</span><br><span class="line">            nn.Linear(<span class="number">2048</span>, <span class="number">2048</span>),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.Linear(<span class="number">2048</span>, num_classes),<span class="comment">#num_classes 最后类别个数</span></span><br><span class="line">        )</span><br><span class="line">        <span class="comment">#卷积池化层提取图像特征，全连接层进行图像分类，代码中写成两个模块，方便调用</span></span><br><span class="line">        <span class="keyword">if</span> init_weights:<span class="comment">#初始化权重</span></span><br><span class="line">            self._initialize_weights()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 前向传播过程</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = self.features(x)</span><br><span class="line">        x = torch.flatten(x, start_dim=<span class="number">1</span>)  <span class="comment"># 展平后再传入全连接层</span></span><br><span class="line">        x = self.classifier(x)</span><br><span class="line">        <span class="keyword">return</span> x<span class="comment">#返回预测输出</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 网络权重初始化，实际上 pytorch 在构建网络时会自动初始化权重</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_initialize_weights</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">for</span> m <span class="keyword">in</span> self.modules():<span class="comment">#继承自父类nn.modules 遍历所有结构</span></span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">isinstance</span>(m, nn.Conv2d):  <span class="comment"># 若是卷积层</span></span><br><span class="line">                nn.init.kaiming_normal_(m.weight, mode=<span class="string">&#x27;fan_out&#x27;</span>,  <span class="comment"># 用（何）kaiming_normal_法初始化权重w</span></span><br><span class="line">                                        nonlinearity=<span class="string">&#x27;relu&#x27;</span>)</span><br><span class="line">                <span class="keyword">if</span> m.bias <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                    nn.init.constant_(m.bias, <span class="number">0</span>)  <span class="comment"># 初始化偏重为0</span></span><br><span class="line">            <span class="keyword">elif</span> <span class="built_in">isinstance</span>(m, nn.Linear):  <span class="comment"># 若是全连接层</span></span><br><span class="line">                nn.init.normal_(m.weight, <span class="number">0</span>, <span class="number">0.01</span>)  <span class="comment"># 正态分布初始化，方差=0.01</span></span><br><span class="line">                nn.init.constant_(m.bias, <span class="number">0</span>)  <span class="comment"># 初始化偏重为0</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="train-py"><a href="#train-py" class="headerlink" title="train.py"></a>train.py</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#导入包</span></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms, datasets, utils</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> model <span class="keyword">import</span> AlexNet</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    <span class="comment"># 运算资源调度</span></span><br><span class="line">    device = torch.device(<span class="string">&quot;cuda:0&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)<span class="comment">#调用 第一块 gpu</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;using &#123;&#125; device.&quot;</span>.<span class="built_in">format</span>(device))</span><br><span class="line">    <span class="comment">#数据处理</span></span><br><span class="line">    data_transform = &#123;</span><br><span class="line">        <span class="comment">#训练集处理</span></span><br><span class="line">        <span class="string">&quot;train&quot;</span>: transforms.Compose([transforms.RandomResizedCrop(<span class="number">224</span>),<span class="comment"># 随机裁剪，再缩放成 224×224</span></span><br><span class="line">                                     transforms.RandomHorizontalFlip(),<span class="comment"># 水平方向随机翻转，概率为 0.5, 即一半的概率翻转, 一半的概率不翻转</span></span><br><span class="line">                                     transforms.ToTensor(),<span class="comment">#标准化格式转换 ToTensor将文件高*宽*深度转换诶 深度*高*宽</span></span><br><span class="line">                                     transforms.Normalize((<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>), (<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>))]),<span class="comment">#标准化</span></span><br><span class="line">        <span class="comment">#验证集处理</span></span><br><span class="line">        <span class="string">&quot;val&quot;</span>: transforms.Compose([transforms.Resize((<span class="number">224</span>, <span class="number">224</span>)),  <span class="comment"># cannot 224, must (224, 224)</span></span><br><span class="line">                                   transforms.ToTensor(),</span><br><span class="line">                                   transforms.Normalize((<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>), (<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>))])&#125;</span><br><span class="line"></span><br><span class="line">    data_root = os.path.abspath(os.path.join(os.getcwd(), <span class="string">&quot;../..&quot;</span>))  <span class="comment"># 获取数据集根目录；&quot;../..&quot;返回上上层目录</span></span><br><span class="line">    image_path = os.path.join(data_root, <span class="string">&quot;data_set&quot;</span>, <span class="string">&quot;flower_data&quot;</span>)  <span class="comment"># flower data set path</span></span><br><span class="line">    <span class="keyword">assert</span> os.path.exists(image_path), <span class="string">&quot;&#123;&#125; path does not exist.&quot;</span>.<span class="built_in">format</span>(image_path)<span class="comment">#报错</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">#加载训练集路径以及处理</span></span><br><span class="line">    train_dataset = datasets.ImageFolder(root=os.path.join(image_path, <span class="string">&quot;train&quot;</span>),<span class="comment">#获取所需训练集路径</span></span><br><span class="line">                                         transform=data_transform[<span class="string">&quot;train&quot;</span>])<span class="comment">#预处理模式选择</span></span><br><span class="line">    train_num = <span class="built_in">len</span>(train_dataset)<span class="comment">#获取数量</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># &#123;&#x27;daisy&#x27;:0, &#x27;dandelion&#x27;:1, &#x27;roses&#x27;:2, &#x27;sunflower&#x27;:3, &#x27;tulips&#x27;:4&#125;</span></span><br><span class="line">    flower_list = train_dataset.class_to_idx<span class="comment">#对应索引结构</span></span><br><span class="line">    cla_dict = <span class="built_in">dict</span>((val, key) <span class="keyword">for</span> key, val <span class="keyword">in</span> flower_list.items())<span class="comment">#遍历并反转键值对</span></span><br><span class="line">    <span class="comment"># 此时为&#123;0:&#x27;daisy&#x27;, 1:&#x27;dandelion&#x27;, 2:&#x27;roses&#x27;, 3:&#x27;sunflower&#x27;, 4:&#x27;tulips&#x27;&#125;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 存储索引字典为json格式</span></span><br><span class="line">    json_str = json.dumps(cla_dict, indent=<span class="number">4</span>)</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;class_indices.json&#x27;</span>, <span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> json_file:</span><br><span class="line">        json_file.write(json_str)</span><br><span class="line">    <span class="comment"># 定义数据集大小</span></span><br><span class="line">    batch_size = <span class="number">32</span></span><br><span class="line">    <span class="comment"># 选定加载所使用线程个数</span></span><br><span class="line">    nw = <span class="built_in">min</span>([os.cpu_count(), batch_size <span class="keyword">if</span> batch_size &gt; <span class="number">1</span> <span class="keyword">else</span> <span class="number">0</span>, <span class="number">8</span>])  <span class="comment"># number of workers</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Using &#123;&#125; dataloader workers every process&#x27;</span>.<span class="built_in">format</span>(nw))</span><br><span class="line">    <span class="comment"># 加载训练集</span></span><br><span class="line">    train_loader = torch.utils.data.DataLoader(train_dataset,<span class="comment">#数据集选择</span></span><br><span class="line">                                               batch_size=batch_size,<span class="comment">#数据集大小</span></span><br><span class="line">                                               shuffle=<span class="literal">True</span>,<span class="comment">#随机打乱</span></span><br><span class="line">                                               num_workers=nw)</span><br><span class="line">    <span class="comment">#加载验证集路径以及处理</span></span><br><span class="line">    validate_dataset = datasets.ImageFolder(root=os.path.join(image_path, <span class="string">&quot;val&quot;</span>),<span class="comment">#获取所需验证集路径</span></span><br><span class="line">                                            transform=data_transform[<span class="string">&quot;val&quot;</span>])<span class="comment">#验证集处理方式</span></span><br><span class="line">    val_num = <span class="built_in">len</span>(validate_dataset)<span class="comment">#获取数量</span></span><br><span class="line">    <span class="comment">#加载验证集</span></span><br><span class="line">    validate_loader = torch.utils.data.DataLoader(validate_dataset,  <span class="comment"># 导入的验证集</span></span><br><span class="line">                                                  batch_size=batch_size,</span><br><span class="line">                                                  shuffle=<span class="literal">True</span>,</span><br><span class="line">                                                  num_workers=nw)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;using &#123;&#125; images for training, &#123;&#125; images for validation.&quot;</span>.<span class="built_in">format</span>(train_num,</span><br><span class="line">                                                                           val_num))</span><br><span class="line">    <span class="comment"># #输出测试</span></span><br><span class="line">    <span class="comment"># test_data_iter=iter(validate_loader)</span></span><br><span class="line">    <span class="comment"># test_image,test_label=test_data_iter.__next__()#.next在部分版本不可以解决方案__next__</span></span><br><span class="line">    <span class="comment">#</span></span><br><span class="line">    <span class="comment"># def imshow(img):</span></span><br><span class="line">    <span class="comment">#     img = img / 2 + 0.5  # unnormalize</span></span><br><span class="line">    <span class="comment">#     npimg = img.numpy()</span></span><br><span class="line">    <span class="comment">#     plt.imshow(np.transpose(npimg, (1, 2, 0)))</span></span><br><span class="line">    <span class="comment">#     plt.show()</span></span><br><span class="line">    <span class="comment">#</span></span><br><span class="line">    <span class="comment"># print(&#x27; &#x27;.join(&#x27;%5s&#x27; % cla_dict[test_label[j].item()] for j in range(4)))</span></span><br><span class="line">    <span class="comment"># imshow(utils.make_grid(test_image))</span></span><br><span class="line"></span><br><span class="line">    net = AlexNet(num_classes=<span class="number">5</span>, init_weights=<span class="literal">True</span>)<span class="comment"># 实例化网络（输出类型为5，初始化权重）</span></span><br><span class="line"></span><br><span class="line">    net.to(device)<span class="comment"># 分配网络到指定的设备（GPU/CPU）训练</span></span><br><span class="line">    loss_function = nn.CrossEntropyLoss()<span class="comment">#定义损失函数交叉熵损失</span></span><br><span class="line">    <span class="comment"># pata = list(net.parameters())#查看模型参数</span></span><br><span class="line">    optimizer = optim.Adam(net.parameters(), lr=<span class="number">0.0002</span>)<span class="comment">#优化参数；学习率0.002</span></span><br><span class="line"></span><br><span class="line">    epochs = <span class="number">10</span><span class="comment">#迭代次数</span></span><br><span class="line">    save_path = <span class="string">&#x27;./AlexNet.pth&#x27;</span><span class="comment">#保存权重</span></span><br><span class="line">    best_acc = <span class="number">0.0</span><span class="comment">#最佳准确率</span></span><br><span class="line">    train_steps = <span class="built_in">len</span>(train_loader)</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(epochs):</span><br><span class="line">        <span class="comment"># 开始训练</span></span><br><span class="line">        net.train()<span class="comment">#让训练时使用dropout方法而预测时不使用</span></span><br><span class="line">        running_loss = <span class="number">0.0</span><span class="comment">#统计平均损失</span></span><br><span class="line">        train_bar = tqdm(train_loader, file=sys.stdout)<span class="comment">#进度条模块</span></span><br><span class="line">        <span class="keyword">for</span> step, data <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_bar):</span><br><span class="line">            images, labels = data</span><br><span class="line">            optimizer.zero_grad()<span class="comment">#清空梯度</span></span><br><span class="line">            outputs = net(images.to(device))<span class="comment"># 正向传播</span></span><br><span class="line">            loss = loss_function(outputs, labels.to(device))<span class="comment">#计算损失</span></span><br><span class="line">            loss.backward()<span class="comment">#反向传播</span></span><br><span class="line">            optimizer.step()<span class="comment"># 优化器更新参数</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># 打印训练进度（使训练过程可视化）</span></span><br><span class="line">            running_loss += loss.item()</span><br><span class="line"></span><br><span class="line">            train_bar.desc = <span class="string">&quot;train epoch[&#123;&#125;/&#123;&#125;] loss:&#123;:.3f&#125;&quot;</span>.<span class="built_in">format</span>(epoch + <span class="number">1</span>,</span><br><span class="line">                                                                     epochs,</span><br><span class="line">                                                                     loss)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 开始验证</span></span><br><span class="line">        net.<span class="built_in">eval</span>()<span class="comment"># 验证过程中关闭 Dropout</span></span><br><span class="line">        acc = <span class="number">0.0</span>  <span class="comment"># accumulate accurate number / epoch</span></span><br><span class="line">        <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">            val_bar = tqdm(validate_loader, file=sys.stdout)</span><br><span class="line">            <span class="keyword">for</span> val_data <span class="keyword">in</span> val_bar:</span><br><span class="line">                val_images, val_labels = val_data</span><br><span class="line">                outputs = net(val_images.to(device))</span><br><span class="line">                predict_y = torch.<span class="built_in">max</span>(outputs, dim=<span class="number">1</span>)[<span class="number">1</span>]<span class="comment"># 以output中值最大位置对应的索引（标签）作为预测输出</span></span><br><span class="line">                acc += torch.eq(predict_y, val_labels.to(device)).<span class="built_in">sum</span>().item()<span class="comment">#预测正确个数统计</span></span><br><span class="line"></span><br><span class="line">        val_accurate = acc / val_num<span class="comment">#计算准确率</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;[epoch %d] train_loss: %.3f  val_accuracy: %.3f&#x27;</span> %</span><br><span class="line">              (epoch + <span class="number">1</span>, running_loss / train_steps, val_accurate))</span><br><span class="line">        <span class="comment"># 保存准确率最高的那次网络参数</span></span><br><span class="line">        <span class="keyword">if</span> val_accurate &gt; best_acc:</span><br><span class="line">            best_acc = val_accurate</span><br><span class="line">            torch.save(net.state_dict(), save_path)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Finished Training&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    main()</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="predict-py"><a href="#predict-py" class="headerlink" title="predict.py"></a>predict.py</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> model <span class="keyword">import</span> AlexNet</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line"><span class="comment"># 预处理</span></span><br><span class="line">data_transform = transforms.Compose(</span><br><span class="line">    [transforms.Resize((<span class="number">224</span>, <span class="number">224</span>)),</span><br><span class="line">     transforms.ToTensor(),</span><br><span class="line">     transforms.Normalize((<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>), (<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>))])</span><br><span class="line"></span><br><span class="line"><span class="comment"># load image</span></span><br><span class="line">img = Image.<span class="built_in">open</span>(<span class="string">&quot;totest.jpg&quot;</span>)</span><br><span class="line">plt.imshow(img)<span class="comment">#展示测试图片</span></span><br><span class="line"><span class="comment"># [N, C, H, W]</span></span><br><span class="line">img = data_transform(img)</span><br><span class="line"><span class="comment"># expand batch dimension</span></span><br><span class="line">img = torch.unsqueeze(img, dim=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># read class_indict</span></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    json_file = <span class="built_in">open</span>(<span class="string">&#x27;./class_indices.json&#x27;</span>, <span class="string">&#x27;r&#x27;</span>)</span><br><span class="line">    class_indict = json.load(json_file)</span><br><span class="line"><span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">    <span class="built_in">print</span>(e)</span><br><span class="line">    exit(-<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># create model</span></span><br><span class="line">model = AlexNet(num_classes=<span class="number">5</span>)</span><br><span class="line"><span class="comment"># load model weights</span></span><br><span class="line">model_weight_path = <span class="string">&quot;./AlexNet.pth&quot;</span><span class="comment">#加载训练好的模型权重</span></span><br><span class="line">model.load_state_dict(torch.load(model_weight_path))</span><br><span class="line"></span><br><span class="line">model.<span class="built_in">eval</span>()<span class="comment"># 关闭 Dropout</span></span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    <span class="comment"># predict class</span></span><br><span class="line">    output = torch.squeeze(model(img))     <span class="comment"># 将输出压缩，即压缩掉 batch 这个维度</span></span><br><span class="line">    predict = torch.softmax(output, dim=<span class="number">0</span>)</span><br><span class="line">    predict_cla = torch.argmax(predict).numpy()</span><br><span class="line"><span class="built_in">print</span>(class_indict[<span class="built_in">str</span>(predict_cla)], predict[predict_cla].item())</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><h2 id="遇到问题以及解决方法"><a href="#遇到问题以及解决方法" class="headerlink" title="遇到问题以及解决方法"></a>遇到问题以及解决方法</h2><h3 id="数据集下载以及加载"><a href="#数据集下载以及加载" class="headerlink" title="数据集下载以及加载"></a>数据集下载以及加载</h3><ol><li><p><a href="http://download.tensorflow.org/example_images/flower_photos.tgz">数据集下载</a></p></li><li><p><a href="https://github.com/WZMIAOMIAO/deep-learning-for-image-processing/blob/master/data_set/README.md">数据集分割</a>部分数据集需要自行分割出训练集，验证集，测试集</p></li><li><p>加载路径</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data_root = os.path.abspath(os.path.join(os.getcwd(), <span class="string">&quot;../..&quot;</span>))  <span class="comment"># 获取数据集根目录；&quot;../..&quot;返回上上层目录</span></span><br></pre></td></tr></table></figure></li></ol><h3 id="奇怪的报错"><a href="#奇怪的报错" class="headerlink" title="奇怪的报错"></a>奇怪的报错</h3><h4 id="AttributeError-‘-MultiProcessingDataLoaderIter‘-object-has-no-attribute-‘next‘-问题解决"><a href="#AttributeError-‘-MultiProcessingDataLoaderIter‘-object-has-no-attribute-‘next‘-问题解决" class="headerlink" title="AttributeError: ‘_MultiProcessingDataLoaderIter‘ object has no attribute ‘next‘ 问题解决"></a>AttributeError: ‘_MultiProcessingDataLoaderIter‘ object has no attribute ‘next‘ 问题解决</h4><p>表示找不到这个方法</p><p>问题原因：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">test_image,test_label=test_data_iter.<span class="built_in">next</span>()</span><br></pre></td></tr></table></figure><p>这句中**.next<strong>找不到 改为</strong>.__next__**即可</p>]]></content>
      
      
      <categories>
          
          <category> 学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 人工智能 </tag>
            
            <tag> AlexNet </tag>
            
            <tag> 数据集预处理 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>AlexNet-2</title>
      <link href="/2022/12/15/AlexNet%E8%AE%BA%E6%96%87%E7%A0%94%E8%AF%BB/"/>
      <url>/2022/12/15/AlexNet%E8%AE%BA%E6%96%87%E7%A0%94%E8%AF%BB/</url>
      
        <content type="html"><![CDATA[<h1 id="AlexNet研读"><a href="#AlexNet研读" class="headerlink" title="AlexNet研读"></a>AlexNet研读</h1><p><a href="https://dl.acm.org/doi/pdf/10.1145/3065386">ImageNet Classification with Deep Convolutional Neural Networks</a>,【<a href="https://blog.csdn.net/weixin_36670529/article/details/99976379">中文翻译</a>】</p><h2 id="网络优点"><a href="#网络优点" class="headerlink" title="网络优点"></a>网络优点</h2><h3 id="ReLU非线性单元"><a href="#ReLU非线性单元" class="headerlink" title="ReLU非线性单元"></a><strong>ReLU非线性单元</strong></h3><p>AlexNet使用的神经元激活函数是ReLU激活函数 f(x)&#x3D;max(0,x) ，相比于饱和非线性函数如Sigmoid和tanh函数，不饱和非线性函数如ReLU在梯度下降时具有<strong>更快的收敛速度</strong>，更快地学习，在大型网络中训练大量数据具有非常好的效果。作者通过在CIFAR-10数据集上做的实验证明了此论点。如下图，实线表示使用ReLUs的CNN，虚线表示使用tanh函数的CNN，可以看出使用ReLUs的CNN能更快地把训练错误率降低到25%（迭代次数比tanh的CNN快约5倍）。</p><p>ReLU是本文作者Hinton在2010年提出来改善RBM性能的，把ReLU引入深度CNN中，使得ReLU成为以后深度网络普遍使用的非线性函数，从而在这个领域替代经典的sigmoid、tanh函数。ReLU有三个好处：</p><ol><li><strong>简单的max计算，大大减少了计算量</strong>，可以提高训练速度；</li><li>梯度在ReLU中是直接传递的，鉴于深度网络的梯度衰减现象，<strong>ReLU可以保持梯度，减缓梯度衰减</strong>的趋势；</li><li><strong>bp过程中没有了梯度换算的操作</strong>，加快了训练。</li></ol><h3 id="跨GPU并行化操作"><a href="#跨GPU并行化操作" class="headerlink" title="跨GPU并行化操作"></a><strong>跨GPU并行化操作</strong></h3><p>一个GTX580的内存只有3GB，有限的内存限制了可以在GPU上训练的最大网络。目前的GPU很适合于跨GPU并行化操作，故作者把网络一分为二，分配到2个GPU上，通过并行计算来解决，不用通过主机的缓存，当前GPU相互间可以很好进行读写操作。</p><p>这里作者有一个小技巧，GPU相互“沟通”：例如，网络中layer-3的filter把layer-2的所有特征图作为输入，而其它卷积层，只从同一个GPU内的上一层特征图作为输入。为什么layer-3把layer-2的全部特征图作为输入而其它层却不这样，这个作者并没有解释理论依据，通过交叉验证实验得来的。最终的结构有点类似Cresian提出的多列卷积网络，但是本文的网络不是完全独立的，这种方式可以提高1.2%的准确率。</p><h3 id="局部响应归一化层（Local-Response-Normalization）"><a href="#局部响应归一化层（Local-Response-Normalization）" class="headerlink" title="局部响应归一化层（Local Response Normalization）"></a>局部响应归一化层（Local Response Normalization）</h3><p>LRN（Local Response Normalization）层是用来做归一化的。ReLU函数不需要归一化来防止饱和现象，即对于很大的输入x，ReLU仍然可以有效的学习，但是作者发现即使这样，对数据进行局部归一化对于学习来说还是有帮助的，可以增强模型的泛化能力。</p><p>局部响应归一化公式：</p><p><img src="https://pic3.zhimg.com/80/v2-3c5c3702c0ca1d00a6af49ed306f4d0a_1440w.webp" alt="img"></p><p>具体方式：</p><p>选取临近的n个特征图，在特征图的同一个空间位置（x,y）依次平方，然后求和，在乘以α，在加上 k。这个局部归一化方式与论文“What is the best multi-stage architecture for Object Recognition”中的局部归一化方法不同：本文的归一化只是多个特征图同一个位置上的归一化，属于特征图之间的局部归一化（属于纵向归一化），作者命名为亮度归一化；“what……”论文中在特征图之间基础上还有同一特征图内邻域位置像素的归一化（横向、纵向归一化结合）；“what……”归一化方法计算复杂，但是没有本文中 α、k、n 等参数，本文通过交叉验证来确定这三个参数；此外，本文的<strong>归一化方法没有减去均值</strong>，感觉是因为ReLU只对正值部分产生学习，如果减去均值会丢失掉很多信息。</p><p>简言之，LRN是“What is the best multi-stage architecture for Object Recognition”论文使用的方法，本文简化改进了该归一化方法，将<strong>模型错误率降低1.2%左右</strong>。</p><h5 id="为什么要引入LRN层？"><a href="#为什么要引入LRN层？" class="headerlink" title="为什么要引入LRN层？"></a>为什么要引入LRN层？</h5><p>首先要引入一个神经生物学的概念：<strong>侧抑制（lateral inhibitio），即指被激活的神经元抑制相邻的神经元。</strong>归一化（normaliazation）的目的就是<strong>“抑制”</strong>,LRN就是借鉴这种侧抑制来实现局部抑制，尤其是我们使用RELU的时候，这种“侧抑制”很有效 ，因而在alexnet里使用有较好的效果。</p><h5 id="归一化有什么好处？"><a href="#归一化有什么好处？" class="headerlink" title="归一化有什么好处？"></a>归一化有什么好处？</h5><p><strong>1.归一化有助于快速收敛；<br> 2.对局部神经元的活动创建竞争机制，使得其中响应比较大的值变得相对更大，并抑制其他反馈较小的神经元，增强了模型的泛化能力。</strong><br> 【补充：神经网络学习过程本质就是为了学习数据分布，一旦训练数据与测试数据的分布不同，那么网络的<strong>泛化能力</strong>也大大降低；另外一方面，一旦每批训练数据的分布各不相同(batch 梯度下降)，那么网络就要在每次迭代都去学习适应不同的分布，这样将会大大降低网络的训练速度，这也正是为什么我们需要对数据都要做一个归一化预处理的原因。<br> 深度网络的训练是复杂的过程，只要网络的前面几层发生微小的改变，那么后面几层就会被累积放大下去。一旦网络某一层的输入数据的分布发生改变，那么这一层网络就需要去适应学习这个新的数据分布，所以如果训练过程中，训练数据的分布一直在发生变化，那么将会影响网络的训练速度。】</p><p>作者：LiBiscuit<br>链接：<a href="https://www.jianshu.com/p/c014f81242e7">https://www.jianshu.com/p/c014f81242e7</a><br>来源：简书<br>著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。</p><h3 id="重叠池化"><a href="#重叠池化" class="headerlink" title="重叠池化"></a><strong>重叠池化</strong></h3><p>正常池化是<strong>步长 &#x3D; 窗口尺寸</strong>如步长s&#x3D;2、窗口z&#x3D;2，重叠池化是指<strong>步长＜窗口尺寸</strong>如步长s&#x3D;2、窗口z&#x3D;3。</p><p>Pooling层一般用于降维，将一个 k × k 的区域内取平均或取最大值，作为这一个小区域内的特征，传递到下一层。传统的Pooling层是不重叠的，而本论文提出使Pooling层重叠可以降低错误率，而且对防止过拟合有一定的效果。</p><p>个人理解，使Pooling层重叠，可以<strong>减少信息的损失</strong>，所以<strong>错误率会下降</strong>。但是对防止过拟合的效果，文章也只是说slightly，目测<strong>意义不大。</strong></p><h3 id="Dropout"><a href="#Dropout" class="headerlink" title="Dropout"></a><strong>Dropout</strong></h3><p>Dropout是Hinton在2012年提出以改善深度网络泛化能力的。文中采用Dropout技术，在每次训练网络时，每个神经元都会以0.5的概率“丢失”，丢失的神经元不参与前向传播和反向传播，但是神经元的权值在每次训练时都是共享的。这个技术降低了神经元之间的联合适应性，从而学习更具鲁棒性的特征。在测试阶段，神经网络会使用所有的神经元，但每个神经元的输出会乘以0.5。Dropout技术用在前两个全连接层中，<strong>会减少过拟合</strong></p><p>缺点：就是会使最终网络收敛所需要的<strong>迭代次数翻倍</strong>。</p>]]></content>
      
      
      <categories>
          
          <category> 学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 人工智能 </tag>
            
            <tag> AlexNet </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>AlexNet-1</title>
      <link href="/2022/12/14/AlexNet%E7%BB%93%E6%9E%84%E7%90%86%E8%AE%BA/"/>
      <url>/2022/12/14/AlexNet%E7%BB%93%E6%9E%84%E7%90%86%E8%AE%BA/</url>
      
        <content type="html"><![CDATA[<h1 id="AlexNet网络结构详解"><a href="#AlexNet网络结构详解" class="headerlink" title="AlexNet网络结构详解"></a>AlexNet网络结构详解</h1><p>AlexNet 是2012年 ISLVRC ( ImageNet Large Scale Visual Recognition Challenge)竞赛的冠军网络，分类准确率由传统的70%+提升到80%+。它是由Hinton和他的学生Alex Krizhevsky设计的。 也是在那年之后，深度学习开始迅速发展。</p><p>注：作者使用了两块GPU，所以网络模型变成上下两块</p><p><img src="https://s2.loli.net/2022/12/16/A2CNEHGXlaUwKDY.png"><br>使用Dropout的方式在网络正向传播过程中随机失活一部分神经元，以减少过拟合Conv1</p><p><img src="https://s2.loli.net/2022/12/16/u2UnJ97s4WaX6oj.png" alt="在这里插入图片描述"></p><p><img src="https://s2.loli.net/2022/12/16/EChYiBVGXSRczwM.png" alt="在这里插入图片描述"></p><p><img src="https://s2.loli.net/2022/12/16/IVN9LnhORWS2uMt.png" alt="在这里插入图片描述"></p><h2 id="结构分析"><a href="#结构分析" class="headerlink" title="结构分析"></a>结构分析</h2><h3 id="Conv1"><a href="#Conv1" class="headerlink" title="Conv1"></a>Conv1</h3><p><strong>注意：原作者实验时用了两块GPU并行计算，上下两组图的结构是一样的。</strong></p><ul><li>输入：input_size &#x3D; [224, 224, 3]</li><li>卷积层：<ul><li>kernels &#x3D; 48 * 2 &#x3D; 96 组卷积核</li><li>kernel_size &#x3D; 11</li><li>padding &#x3D; [1, 2] （左，上围加1列圈0，右下围加2列圈0）</li><li>stride &#x3D; 4</li></ul></li><li>输出：output_size &#x3D; [55, 55, 96]<br><img src="https://s2.loli.net/2022/12/16/LkfhXqJ6SpEWBtb.png"></li></ul><h3 id="Maxpool1"><a href="#Maxpool1" class="headerlink" title="Maxpool1"></a>Maxpool1</h3><p><img src="https://s2.loli.net/2022/12/16/U58BtidnLCIF1GN.png" alt="在这里插入图片描述"></p><ul><li>输入：input_size &#x3D; [55, 55, 96]</li><li>池化层：（只改变尺寸，不改变深度channel）<ul><li>kernel_size &#x3D; 3</li><li>padding &#x3D; 0</li><li>stride &#x3D; 2</li></ul></li><li>输出：output_size &#x3D; [27, 27, 96]</li></ul><p>经 Maxpool1 后的输出层尺寸为：</p><p><img src="https://s2.loli.net/2022/12/16/V3d8sCLn6SMTp9D.png"></p><h3 id="Conv2"><a href="#Conv2" class="headerlink" title="Conv2"></a>Conv2</h3><p><img src="https://s2.loli.net/2022/12/16/kRoAEqgCz17r36K.png" alt="在这里插入图片描述"></p><ul><li>输入：input_size &#x3D; [27, 27, 96]</li><li>卷积层：<ul><li>kernels &#x3D; 128 * 2 &#x3D; 256 组卷积核</li><li>kernel_size &#x3D; 5</li><li>padding &#x3D; [2, 2]</li><li>stride &#x3D; 1</li></ul></li><li>输出：output_size &#x3D; [27, 27, 256]</li></ul><p>经 Conv2 卷积后的输出层尺寸为：<br><img src="https://s2.loli.net/2022/12/16/V3d8sCLn6SMTp9D.png"></p><h3 id="Maxpool2"><a href="#Maxpool2" class="headerlink" title="Maxpool2"></a>Maxpool2</h3><p><img src="https://s2.loli.net/2022/12/16/JlIaUDjTzdLxymW.png" alt="在这里插入图片描述"></p><ul><li>输入：input_size &#x3D; [27, 27, 256]</li><li>池化层：（只改变尺寸，不改变深度channel）<ul><li>kernel_size &#x3D; 3</li><li>padding &#x3D; 0</li><li>stride &#x3D; 2</li></ul></li><li>输出：output_size &#x3D; [13, 13, 256]</li></ul><p>经 Maxpool2 后的输出层尺寸为：<br><img src="https://s2.loli.net/2022/12/16/k4LnWYOri7bvKsF.png"></p><h3 id="Conv3"><a href="#Conv3" class="headerlink" title="Conv3"></a>Conv3</h3><p><img src="https://s2.loli.net/2022/12/16/zn87fvVEL6CUjQw.png" alt="在这里插入图片描述"></p><ul><li>输入：input_size &#x3D; [13, 13, 256]</li><li>卷积层：<ul><li>kernels &#x3D; 192* 2 &#x3D; 384 组卷积核</li><li>kernel_size &#x3D; 3</li><li>padding &#x3D; [1, 1]</li><li>stride &#x3D; 1</li></ul></li><li>输出：output_size &#x3D; [13, 13, 384]</li></ul><p><img src="https://s2.loli.net/2022/12/16/dKcpH9Y4qD6bvgs.png"></p><h3 id="Conv4"><a href="#Conv4" class="headerlink" title="Conv4"></a>Conv4</h3><p><img src="https://s2.loli.net/2022/12/16/iuDHn3KVcNlkQPg.png" alt="在这里插入图片描述"></p><ul><li>输入：input_size &#x3D; [13, 13, 384]</li><li>卷积层：<ul><li>kernels &#x3D; 192* 2 &#x3D; 384 组卷积核</li><li>kernel_size &#x3D; 3</li><li>padding &#x3D; [1, 1]</li><li>stride &#x3D; 1</li></ul></li><li>输出：output_size &#x3D; [13, 13, 384]</li></ul><p><img src="https://s2.loli.net/2022/12/16/mH47a9upRSGCZy3.png"></p><h3 id="Conv5"><a href="#Conv5" class="headerlink" title="Conv5"></a>Conv5</h3><p><img src="https://s2.loli.net/2022/12/16/6yTadbEBt7K4AF3.png" alt="在这里插入图片描述"></p><ul><li>输入：input_size &#x3D; [13, 13, 384]</li><li>卷积层：<ul><li>kernels &#x3D; 128* 2 &#x3D; 256 组卷积核</li><li>kernel_size &#x3D; 3</li><li>padding &#x3D; [1, 1]</li><li>stride &#x3D; 1</li></ul></li><li>输出：output_size &#x3D; [13, 13, 256]</li></ul><p><img src="https://s2.loli.net/2022/12/16/wM3TYJk2X6iBupz.png"></p><h3 id="Maxpool3"><a href="#Maxpool3" class="headerlink" title="Maxpool3"></a>Maxpool3</h3><p><img src="https://s2.loli.net/2022/12/16/f6EI3LTg4lNkXWo.png" alt="在这里插入图片描述"></p><ul><li>输入：input_size &#x3D; [13, 13, 256]</li><li>池化层：（只改变尺寸，不改变深度channel）<ul><li>kernel_size &#x3D; 3</li><li>padding &#x3D; 0</li><li>stride &#x3D; 2</li></ul></li><li>输出：output_size &#x3D; [6, 6, 256]</li></ul><p><img src="https://s2.loli.net/2022/12/16/lm9GxnbNzdjUiLW.png"></p><h3 id="FC1、FC2、FC3"><a href="#FC1、FC2、FC3" class="headerlink" title="FC1、FC2、FC3"></a>FC1、FC2、FC3</h3><p>Maxpool3 → (6<em>6</em>256) → FC1 → 2048 → FC2 → 2048 → FC3 → 1000<br><strong>最终的1000可以根据数据集的类别数进行修改。</strong></p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p><img src="https://s2.loli.net/2022/12/16/CtqvVzZaSipXolM.png" alt="在这里插入图片描述"><br>分析可以发现，除 Conv1 外，AlexNet 的其余卷积层都是在改变特征矩阵的深度，而池化层则只改变（减小)其尺寸。</p>]]></content>
      
      
      <categories>
          
          <category> 学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 人工智能 </tag>
            
            <tag> AlexNet </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>LeNet-2</title>
      <link href="/2022/12/12/Pytorch_Demo/"/>
      <url>/2022/12/12/Pytorch_Demo/</url>
      
        <content type="html"><![CDATA[<h1 id="Pytorch官网入门Demo——实现一个图像分类器"><a href="#Pytorch官网入门Demo——实现一个图像分类器" class="headerlink" title="Pytorch官网入门Demo——实现一个图像分类器"></a>Pytorch官网入门Demo——实现一个图像分类器</h1><p>参考：</p><ol><li><a href="https://www.bilibili.com/video/BV187411T7Ye">哔哩哔哩：pytorch官方demo(Lenet)</a></li><li><a href="https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html#">pytorch官网demo</a>（<a href="https://pytorch.apachecn.org/#/docs/1.4/4">中文版戳这里</a>）</li><li><a href="https://blog.csdn.net/qq_37541097/article/details/102926037">pytorch中的卷积操作详解</a></li><li><a href="https://blog.csdn.net/m0_37867091/article/details/107136477">Fan的CSDN笔记</a></li></ol><h2 id="代码部分"><a href="#代码部分" class="headerlink" title="代码部分"></a>代码部分</h2><p>Model 模型构建</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">LeNet</span>(nn.Module):                     <span class="comment"># 继承于nn.Module这个父类</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):                     <span class="comment"># 初始化网络结构</span></span><br><span class="line">        <span class="built_in">super</span>(LeNet, self).__init__()       <span class="comment"># 多继承需用到super函数</span></span><br><span class="line">        self.conv1 = nn.Conv2d(<span class="number">3</span>, <span class="number">16</span>, <span class="number">5</span>)    <span class="comment">#构建卷积层1，深度3，卷积核个数为16，核大小为5*5 输出深度为卷积核个数</span></span><br><span class="line">        self.pool1 = nn.MaxPool2d(<span class="number">2</span>, <span class="number">2</span>)     <span class="comment">#构建池化层（下采样层）1，核大小为2*2，步长为2</span></span><br><span class="line">        self.conv2 = nn.Conv2d(<span class="number">16</span>, <span class="number">32</span>, <span class="number">5</span>)   <span class="comment">#构建卷积层2，深度16，卷积核个数为32，核大小为5*5</span></span><br><span class="line">        self.pool2 = nn.MaxPool2d(<span class="number">2</span>, <span class="number">2</span>)     <span class="comment">#构建池化层（下采样层）2，核大小为2*2，步长为2</span></span><br><span class="line">        self.fc1 = nn.Linear(<span class="number">32</span>*<span class="number">5</span>*<span class="number">5</span>, <span class="number">120</span>)   <span class="comment">#构建池全连接层1，输入为32*5*5，输出为120</span></span><br><span class="line">        self.fc2 = nn.Linear(<span class="number">120</span>, <span class="number">84</span>)       <span class="comment">#构建池全连接层2，输入为120，输出为84</span></span><br><span class="line">        self.fc3 = nn.Linear(<span class="number">84</span>, <span class="number">10</span>)        <span class="comment">#构建全连接层3，输入为84，输出为10</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):            <span class="comment"># 正向传播过程</span></span><br><span class="line">        x = F.relu(self.conv1(x))    <span class="comment"># input(3, 32, 32) output(16, 28, 28)</span></span><br><span class="line">        x = self.pool1(x)            <span class="comment"># output(16, 14, 14)</span></span><br><span class="line">        x = F.relu(self.conv2(x))    <span class="comment"># output(32, 10, 10)</span></span><br><span class="line">        x = self.pool2(x)            <span class="comment"># output(32, 5, 5)</span></span><br><span class="line">        x = x.view(-<span class="number">1</span>, <span class="number">32</span>*<span class="number">5</span>*<span class="number">5</span>)       <span class="comment"># output(32*5*5) 展开为一维数据</span></span><br><span class="line">        x = F.relu(self.fc1(x))      <span class="comment"># output(120)</span></span><br><span class="line">        x = F.relu(self.fc2(x))      <span class="comment"># output(84)</span></span><br><span class="line">        x = self.fc3(x)              <span class="comment"># output(10)</span></span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"><span class="comment"># import torch</span></span><br><span class="line"><span class="comment"># input1 = torch.rand([32,3,32,32])</span></span><br><span class="line"><span class="comment"># model = LeNet()</span></span><br><span class="line"><span class="comment"># print(model) #输出LeNet神经网络架构</span></span><br><span class="line"><span class="comment"># output = model(input1)</span></span><br></pre></td></tr></table></figure><p>Train训练（下载cifar-10官方训练集和测试集）</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">from</span> model <span class="keyword">import</span> LeNet</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="keyword">import</span> torchvision.transforms <span class="keyword">as</span> transforms</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    transform = transforms.Compose(</span><br><span class="line">        [transforms.ToTensor(),</span><br><span class="line">         transforms.Normalize((<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>), (<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>))])</span><br><span class="line"><span class="comment"># ToTensor将文件高*宽*深度转换诶 深度*高*宽 Normalize标准化 使用均值和标准差 标准化图像</span></span><br><span class="line">    <span class="comment"># 50000张训练图片</span></span><br><span class="line">    <span class="comment"># 第一次使用时要将download设置为True才会自动去下载数据集</span></span><br><span class="line">    train_set = torchvision.datasets.CIFAR10(root=<span class="string">&#x27;./data&#x27;</span>, train=<span class="literal">True</span>,</span><br><span class="line">                                             download=<span class="literal">False</span>, transform=transform) <span class="comment">#此行download改为True为下载数据集合，transform为预处理</span></span><br><span class="line"><span class="comment">#torchvision.datasets. 可以用于查看pytorch官方数据集</span></span><br><span class="line">    train_loader = torch.utils.data.DataLoader(train_set, batch_size=<span class="number">36</span>,</span><br><span class="line">                                               shuffle=<span class="literal">True</span>, num_workers=<span class="number">0</span>)<span class="comment">#shuffle为是否打乱数据集</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 10000张验证图片</span></span><br><span class="line">    <span class="comment"># 第一次使用时要将download设置为True才会自动去下载数据集</span></span><br><span class="line">    val_set = torchvision.datasets.CIFAR10(root=<span class="string">&#x27;./data&#x27;</span>, train=<span class="literal">False</span>,</span><br><span class="line">                                           download=<span class="literal">True</span>, transform=transform)</span><br><span class="line">    val_loader = torch.utils.data.DataLoader(val_set, batch_size=<span class="number">5000</span>,</span><br><span class="line">                                             shuffle=<span class="literal">False</span>, num_workers=<span class="number">0</span>)<span class="comment">#预览时可以把batchsize调低用于查看</span></span><br><span class="line">    val_data_iter = <span class="built_in">iter</span>(val_loader)<span class="comment">#转换为可迭代的迭代器</span></span><br><span class="line">    val_image, val_label = <span class="built_in">next</span>(val_data_iter)<span class="comment">#获取一批图像并赋值</span></span><br><span class="line"></span><br><span class="line">    classes = (<span class="string">&#x27;plane&#x27;</span>, <span class="string">&#x27;car&#x27;</span>, <span class="string">&#x27;bird&#x27;</span>, <span class="string">&#x27;cat&#x27;</span>,</span><br><span class="line">               <span class="string">&#x27;deer&#x27;</span>, <span class="string">&#x27;dog&#x27;</span>, <span class="string">&#x27;frog&#x27;</span>, <span class="string">&#x27;horse&#x27;</span>, <span class="string">&#x27;ship&#x27;</span>, <span class="string">&#x27;truck&#x27;</span>)<span class="comment">#导入标签</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># # 输出图像的函数</span></span><br><span class="line">    <span class="comment"># def imshow(img):</span></span><br><span class="line">    <span class="comment">#     img = img / 2 + 0.5  # unnormalize反标准化</span></span><br><span class="line">    <span class="comment">#     npimg = img.numpy() #转化为numpy格式</span></span><br><span class="line">    <span class="comment">#     plt.imshow(np.transpose(npimg, (1, 2, 0)))</span></span><br><span class="line">    <span class="comment">#     # 反标准化为原始格式高，款，深度</span></span><br><span class="line">    <span class="comment">#     plt.show()</span></span><br><span class="line">    <span class="comment"># # 打印图片标签</span></span><br><span class="line">    <span class="comment"># print(&#x27; &#x27;.join(&#x27;%5s&#x27; % classes[val_label[j]] for j in range(4)))</span></span><br><span class="line">    <span class="comment"># # 显示图片</span></span><br><span class="line">    <span class="comment"># imshow(torchvision.utils.make_grid(val_image))</span></span><br><span class="line"></span><br><span class="line">    net = LeNet()</span><br><span class="line">    loss_function = nn.CrossEntropyLoss()<span class="comment">#定义损失函数  包含softmax函数</span></span><br><span class="line">    optimizer = optim.Adam(net.parameters(), lr=<span class="number">0.001</span>)<span class="comment">#Adam优化器；net.parameters()将网络中所有可训练参数进行训练；lr(learning rate)学习率</span></span><br><span class="line">    <span class="comment">#以下为训练过程</span></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>):  <span class="comment"># loop over the dataset multiple times；epoch训练集迭代次数</span></span><br><span class="line"></span><br><span class="line">        running_loss = <span class="number">0.0</span><span class="comment">#累加损失</span></span><br><span class="line">        <span class="comment">#以下迭代损失</span></span><br><span class="line">        <span class="keyword">for</span> step, data <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_loader, start=<span class="number">0</span>):</span><br><span class="line">            <span class="comment"># get the inputs; data is a list of [inputs, labels] 获取输入 enumerate返回data和data的步数</span></span><br><span class="line">            inputs, labels = data</span><br><span class="line"></span><br><span class="line">            <span class="comment"># zero the parameter gradients 历史损失梯度清零</span></span><br><span class="line">            optimizer.zero_grad()</span><br><span class="line">            <span class="comment"># forward + backward + optimize</span></span><br><span class="line">            outputs = net(inputs)</span><br><span class="line">            loss = loss_function(outputs, labels)<span class="comment">#损失计算</span></span><br><span class="line">            loss.backward()<span class="comment">#反向传播</span></span><br><span class="line">            optimizer.step()<span class="comment">#利用优化器进行参数更新</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># print statistics</span></span><br><span class="line">            running_loss += loss.item()</span><br><span class="line">            <span class="keyword">if</span> step % <span class="number">500</span> == <span class="number">499</span>:    <span class="comment"># print every 500 mini-batches 每隔500步打印一次</span></span><br><span class="line">                <span class="keyword">with</span> torch.no_grad():<span class="comment">#减少计算损失梯度</span></span><br><span class="line">                    outputs = net(val_image)  <span class="comment"># [batch, 10]</span></span><br><span class="line">                    predict_y = torch.<span class="built_in">max</span>(outputs, dim=<span class="number">1</span>)[<span class="number">1</span>]<span class="comment">#在输出10个节点找到最大值 获得标签</span></span><br><span class="line">                    accuracy = torch.eq(predict_y, val_label).<span class="built_in">sum</span>().item() / val_label.size(<span class="number">0</span>)<span class="comment">#输出预测对了多少个样本，获得测试准确率</span></span><br><span class="line"></span><br><span class="line">                    <span class="built_in">print</span>(<span class="string">&#x27;[%d, %5d] train_loss: %.3f  test_accuracy: %.3f&#x27;</span> %</span><br><span class="line">                          (epoch + <span class="number">1</span>, step + <span class="number">1</span>, running_loss / <span class="number">500</span>, accuracy))<span class="comment">#打印训练轮数，训练多少步，累加误差，获得训练误差</span></span><br><span class="line">                    running_loss = <span class="number">0.0</span><span class="comment">#清零</span></span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Finished Training&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    save_path = <span class="string">&#x27;./Lenet.pth&#x27;</span><span class="comment">#保存参数和模型</span></span><br><span class="line">    torch.save(net.state_dict(), save_path)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    main()</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>输出结果：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">Files already downloaded and verified</span><br><span class="line">[1,   500] train_loss: 1.747  test_accuracy: 0.459</span><br><span class="line">[1,  1000] train_loss: 1.445  test_accuracy: 0.510</span><br><span class="line">[2,   500] train_loss: 1.230  test_accuracy: 0.575</span><br><span class="line">[2,  1000] train_loss: 1.173  test_accuracy: 0.601</span><br><span class="line">[3,   500] train_loss: 1.034  test_accuracy: 0.612</span><br><span class="line">[3,  1000] train_loss: 1.035  test_accuracy: 0.629</span><br><span class="line">[4,   500] train_loss: 0.941  test_accuracy: 0.645</span><br><span class="line">[4,  1000] train_loss: 0.928  test_accuracy: 0.649</span><br><span class="line">[5,   500] train_loss: 0.846  test_accuracy: 0.666</span><br><span class="line">[5,  1000] train_loss: 0.866  test_accuracy: 0.670</span><br><span class="line">Finished Training</span><br></pre></td></tr></table></figure><p>预测模块</p><p>输入图片</p><p><img src="https://s2.loli.net/2022/12/10/hloJP1QY3FDdcaK.jpg" alt="totest"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torchvision.transforms <span class="keyword">as</span> transforms</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> model <span class="keyword">import</span> LeNet</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    transform = transforms.Compose(</span><br><span class="line">        [transforms.Resize((<span class="number">32</span>, <span class="number">32</span>)),<span class="comment">#缩放图片</span></span><br><span class="line">         transforms.ToTensor(),</span><br><span class="line">         transforms.Normalize((<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>), (<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>))])</span><br><span class="line"></span><br><span class="line">    classes = (<span class="string">&#x27;plane&#x27;</span>, <span class="string">&#x27;car&#x27;</span>, <span class="string">&#x27;bird&#x27;</span>, <span class="string">&#x27;cat&#x27;</span>,</span><br><span class="line">               <span class="string">&#x27;deer&#x27;</span>, <span class="string">&#x27;dog&#x27;</span>, <span class="string">&#x27;frog&#x27;</span>, <span class="string">&#x27;horse&#x27;</span>, <span class="string">&#x27;ship&#x27;</span>, <span class="string">&#x27;truck&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    net = LeNet()</span><br><span class="line">    net.load_state_dict(torch.load(<span class="string">&#x27;Lenet.pth&#x27;</span>))</span><br><span class="line"></span><br><span class="line">    im = Image.<span class="built_in">open</span>(<span class="string">&#x27;totest.jpg&#x27;</span>)</span><br><span class="line">    im = transform(im)  <span class="comment"># [C, H, W]</span></span><br><span class="line">    im = torch.unsqueeze(im, dim=<span class="number">0</span>)  <span class="comment"># [N, C, H, W]增加维度 batch</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        outputs = net(im)</span><br><span class="line">        predict = torch.<span class="built_in">max</span>(outputs, dim=<span class="number">1</span>)[<span class="number">1</span>].numpy()</span><br><span class="line">    <span class="built_in">print</span>(classes[<span class="built_in">int</span>(predict)])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    main()</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>输出结果</p><pre><code>plane</code></pre><h2 id="学习"><a href="#学习" class="headerlink" title="学习"></a>学习</h2><h3 id="Demo流程"><a href="#Demo流程" class="headerlink" title="Demo流程"></a>Demo流程</h3><ol><li>model.py ——定义LeNet网络模型</li><li>train.py ——加载数据集并训练，训练集计算loss，测试集计算accuracy，保存训练好的网络参数</li><li>predict.py——得到训练好的网络参数后，用自己找的图像进行分类测试</li></ol><h3 id="model-py"><a href="#model-py" class="headerlink" title="model.py"></a>model.py</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">LeNet</span>(nn.Module):                     <span class="comment"># 继承于nn.Module这个父类</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):                     <span class="comment"># 初始化网络结构</span></span><br><span class="line">        <span class="built_in">super</span>(LeNet, self).__init__()       <span class="comment"># 多继承需用到super函数</span></span><br><span class="line">        self.conv1 = nn.Conv2d(<span class="number">3</span>, <span class="number">16</span>, <span class="number">5</span>)    <span class="comment">#构建卷积层1，深度3，卷积核个数为16，核大小为5*5 输出深度为卷积核个数</span></span><br><span class="line">        self.pool1 = nn.MaxPool2d(<span class="number">2</span>, <span class="number">2</span>)     <span class="comment">#构建池化层（下采样层）1，核大小为2*2，步长为2</span></span><br><span class="line">        self.conv2 = nn.Conv2d(<span class="number">16</span>, <span class="number">32</span>, <span class="number">5</span>)   <span class="comment">#构建卷积层2，深度16，卷积核个数为32，核大小为5*5</span></span><br><span class="line">        self.pool2 = nn.MaxPool2d(<span class="number">2</span>, <span class="number">2</span>)     <span class="comment">#构建池化层（下采样层）2，核大小为2*2，步长为2</span></span><br><span class="line">        self.fc1 = nn.Linear(<span class="number">32</span>*<span class="number">5</span>*<span class="number">5</span>, <span class="number">120</span>)   <span class="comment">#构建池全连接层1，输入为32*5*5，输出为120</span></span><br><span class="line">        self.fc2 = nn.Linear(<span class="number">120</span>, <span class="number">84</span>)       <span class="comment">#构建池全连接层2，输入为120，输出为84</span></span><br><span class="line">        self.fc3 = nn.Linear(<span class="number">84</span>, <span class="number">10</span>)        <span class="comment">#构建全连接层3，输入为84，输出为10</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):            <span class="comment"># 正向传播过程</span></span><br><span class="line">        x = F.relu(self.conv1(x))    <span class="comment"># input(3, 32, 32) output(16, 28, 28)</span></span><br><span class="line">        x = self.pool1(x)            <span class="comment"># output(16, 14, 14)</span></span><br><span class="line">        x = F.relu(self.conv2(x))    <span class="comment"># output(32, 10, 10)</span></span><br><span class="line">        x = self.pool2(x)            <span class="comment"># output(32, 5, 5)</span></span><br><span class="line">        x = x.view(-<span class="number">1</span>, <span class="number">32</span>*<span class="number">5</span>*<span class="number">5</span>)       <span class="comment"># output(32*5*5) 展开为一维数据</span></span><br><span class="line">        x = F.relu(self.fc1(x))      <span class="comment"># output(120)</span></span><br><span class="line">        x = F.relu(self.fc2(x))      <span class="comment"># output(84)</span></span><br><span class="line">        x = self.fc3(x)              <span class="comment"># output(10)</span></span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure><p><strong>Tips</strong>：</p><ul><li>pytorch中的卷积、池化、输入输出层中参数的含义与位置，可配合下图一起食用：</li></ul><p><img src="https://s2.loli.net/2022/12/10/vbmuFMxjCrGXWLO.png"></p><h4 id="卷积-Conv2d"><a href="#卷积-Conv2d" class="headerlink" title="卷积 Conv2d"></a>卷积 Conv2d</h4><p>我们常用的卷积（Conv2d）在pytorch中对应的函数是：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=<span class="number">1</span>, padding=<span class="number">0</span>, dilation=<span class="number">1</span>, groups=<span class="number">1</span>, bias=<span class="literal">True</span>, padding_mode=<span class="string">&#x27;zeros&#x27;</span>)</span><br></pre></td></tr></table></figure><p>一般使用时关注以下几个参数即可：</p><ul><li><strong>in_channels</strong>：输入特征矩阵的深度。如输入一张RGB彩色图像，那in_channels&#x3D;3</li><li><strong>out_channels</strong>：输入特征矩阵的深度。也等于卷积核的个数，使用n个卷积核输出的特征矩阵深度就是n</li><li><strong>kernel_size</strong>：卷积核的尺寸。可以是int类型，如3 代表卷积核的height&#x3D;width&#x3D;3，也可以是tuple类型如(3, 5)代表卷积核的height&#x3D;3，width&#x3D;5</li><li><strong>stride</strong>：卷积核的步长。默认为1，和kernel_size一样输入可以是int型，也可以是tuple类型</li><li><strong>padding</strong>：补零操作，默认为0。可以为int型如1即补一圈0，如果输入为tuple型如(2, 1) 代表在上下补2行，左右补1列。</li></ul><blockquote><p>附上pytorch官网上的公式：<img src="https://s2.loli.net/2022/12/10/Zp84TjmrdkEex3B.png"></p></blockquote><ul><li><img src="https://s2.loli.net/2022/12/10/MGygxue5QlJskb9.png"></li></ul><p>注：当通过<strong>N &#x3D; (W − F + 2P ) &#x2F; S + 1</strong>计算式得到的输出尺寸非整数时，会通过删除多余的行和列来保证卷积的输出尺寸为整数。</p><h4 id="池化-MaxPool2d"><a href="#池化-MaxPool2d" class="headerlink" title="池化 MaxPool2d"></a>池化 MaxPool2d</h4><p>最大池化（MaxPool2d）在 pytorch 中对应的函数是：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">MaxPool2d(kernel_size, stride) <span class="comment">#核大小;步长</span></span><br></pre></td></tr></table></figure><h4 id="Tensor的展平：view"><a href="#Tensor的展平：view" class="headerlink" title="Tensor的展平：view()"></a>Tensor的展平：view()</h4><p>注意到，在经过第二个池化层后，数据还是一个三维的Tensor (32, 5, 5)，需要先经过展平后(32*5*5)再传到全连接层：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">x = self.pool2(x)            <span class="comment"># output(32, 5, 5)</span></span><br><span class="line">x = x.view(-<span class="number">1</span>, <span class="number">32</span>*<span class="number">5</span>*<span class="number">5</span>)       <span class="comment"># output(32*5*5)</span></span><br><span class="line">x = F.relu(self.fc1(x))      <span class="comment"># output(120)</span></span><br></pre></td></tr></table></figure><h4 id="全连接-Linear"><a href="#全连接-Linear" class="headerlink" title="全连接 Linear"></a>全连接 Linear</h4><p>全连接（ Linear）在 pytorch 中对应的函数是：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Linear(in_features, out_features, bias=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><p><img src="https://s2.loli.net/2022/12/10/zENetyB4dPjvinO.png"></p><h3 id="Train-py"><a href="#Train-py" class="headerlink" title="Train.py"></a>Train.py</h3><h4 id="导入数据集"><a href="#导入数据集" class="headerlink" title="导入数据集"></a>导入数据集</h4><p>导入包</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">from</span> model <span class="keyword">import</span> LeNet</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="keyword">import</span> torchvision.transforms <span class="keyword">as</span> transforms</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> time</span><br></pre></td></tr></table></figure><p>####数据预处理</p><p>对输入的图像数据做预处理，即由shape (H x W x C) in the range [0, 255] → shape (C x H x W) in the range [0.0, 1.0]</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">transform = transforms.Compose(</span><br><span class="line">    [transforms.ToTensor(),</span><br><span class="line">     transforms.Normalize((<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>), (<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>))])</span><br></pre></td></tr></table></figure><h4 id="数据集介绍"><a href="#数据集介绍" class="headerlink" title="数据集介绍"></a>数据集介绍</h4><p>利用<code>torchvision.datasets</code>函数可以在线导入pytorch中的数据集，包含一些常见的数据集如MNIST等<br><img src="https://s2.loli.net/2022/12/10/3qdHunSgXamG5YJ.png"><br>此demo用的是CIFAR10数据集，也是一个很经典的图像分类数据集，由 Hinton 的学生 Alex Krizhevsky 和 Ilya Sutskever 整理的一个用于识别普适物体的小型数据集，一共包含 10 个类别的 RGB 彩色图片。<br><img src="https://s2.loli.net/2022/12/10/Ws63JIl1NgoafDn.png"></p><h4 id="导入、加载-训练集"><a href="#导入、加载-训练集" class="headerlink" title="导入、加载 训练集"></a>导入、加载 训练集</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 导入50000张训练图片</span></span><br><span class="line">train_set = torchvision.datasets.CIFAR10(root=<span class="string">&#x27;./data&#x27;</span>,  <span class="comment"># 数据集存放目录</span></span><br><span class="line"> train=<span class="literal">True</span>, <span class="comment"># 表示是数据集中的训练集</span></span><br><span class="line">                                        download=<span class="literal">True</span>,   <span class="comment"># 第一次运行时为True，下载数据集，下载完成后改为False</span></span><br><span class="line">                                        transform=transform) <span class="comment"># 预处理过程</span></span><br><span class="line"><span class="comment"># 加载训练集，实际过程需要分批次（batch）训练                                        </span></span><br><span class="line">train_loader = torch.utils.data.DataLoader(train_set,   <span class="comment"># 导入的训练集</span></span><br><span class="line">   batch_size=<span class="number">50</span>, <span class="comment"># 每批训练的样本数</span></span><br><span class="line">                                          shuffle=<span class="literal">False</span>,  <span class="comment"># 是否打乱训练集</span></span><br><span class="line">                                          num_workers=<span class="number">0</span>)  <span class="comment"># 使用线程数，在windows下设置为0</span></span><br></pre></td></tr></table></figure><h4 id="导入、加载-测试集"><a href="#导入、加载-测试集" class="headerlink" title="导入、加载 测试集"></a>导入、加载 测试集</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 导入10000张测试图片</span></span><br><span class="line">test_set = torchvision.datasets.CIFAR10(root=<span class="string">&#x27;./data&#x27;</span>, </span><br><span class="line">train=<span class="literal">False</span>,<span class="comment"># 表示是数据集中的测试集</span></span><br><span class="line">                                        download=<span class="literal">False</span>,transform=transform)</span><br><span class="line"><span class="comment"># 加载测试集</span></span><br><span class="line">test_loader = torch.utils.data.DataLoader(test_set, </span><br><span class="line">  batch_size=<span class="number">10000</span>, <span class="comment"># 每批用于验证的样本数</span></span><br><span class="line">  shuffle=<span class="literal">False</span>, num_workers=<span class="number">0</span>)</span><br><span class="line"><span class="comment"># 获取测试集中的图像和标签，用于accuracy计算</span></span><br><span class="line">test_data_iter = <span class="built_in">iter</span>(test_loader)</span><br><span class="line">test_image, test_label = test_data_iter.<span class="built_in">next</span>()</span><br><span class="line"><span class="number">1234567891011</span></span><br></pre></td></tr></table></figure><h4 id="训练过程"><a href="#训练过程" class="headerlink" title="训练过程"></a>训练过程</h4><table><thead><tr><th>名词</th><th>定义</th></tr></thead><tbody><tr><td>epoch</td><td>对训练集的全部数据进行一次完整的训练，称为 一次 epoch</td></tr><tr><td>batch</td><td>由于硬件算力有限，实际训练时将训练集分成多个批次训练，每批数据的大小为 batch_size</td></tr><tr><td>iteration 或 step</td><td>对一个batch的数据训练的过程称为 一个 iteration 或 step</td></tr></tbody></table><p>以本demo为例，训练集一共有50000个样本，batch_size&#x3D;50，那么完整的训练一次样本：iteration或step&#x3D;1000，epoch&#x3D;1</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">net = LeNet()  <span class="comment"># 定义训练的网络模型</span></span><br><span class="line">loss_function = nn.CrossEntropyLoss() <span class="comment"># 定义损失函数为交叉熵损失函数 </span></span><br><span class="line">optimizer = optim.Adam(net.parameters(), lr=<span class="number">0.001</span>)  <span class="comment"># 定义优化器（训练参数，学习率）</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>):  <span class="comment"># 一个epoch即对整个训练集进行一次训练</span></span><br><span class="line">    running_loss = <span class="number">0.0</span></span><br><span class="line">    time_start = time.perf_counter()</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> step, data <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_loader, start=<span class="number">0</span>):   <span class="comment"># 遍历训练集，step从0开始计算</span></span><br><span class="line">        inputs, labels = data <span class="comment"># 获取训练集的图像和标签</span></span><br><span class="line">        optimizer.zero_grad()   <span class="comment"># 清除历史梯度</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># forward + backward + optimize</span></span><br><span class="line">        outputs = net(inputs)    <span class="comment"># 正向传播</span></span><br><span class="line">        loss = loss_function(outputs, labels) <span class="comment"># 计算损失</span></span><br><span class="line">        loss.backward()   <span class="comment"># 反向传播</span></span><br><span class="line">        optimizer.step()   <span class="comment"># 优化器更新参数</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 打印耗时、损失、准确率等数据</span></span><br><span class="line">        running_loss += loss.item()</span><br><span class="line">        <span class="keyword">if</span> step % <span class="number">1000</span> == <span class="number">999</span>:    <span class="comment"># print every 1000 mini-batches，每1000步打印一次</span></span><br><span class="line">            <span class="keyword">with</span> torch.no_grad(): <span class="comment"># 在以下步骤中（验证过程中）不用计算每个节点的损失梯度，防止内存占用</span></span><br><span class="line">                outputs = net(test_image)  <span class="comment"># 测试集传入网络（test_batch_size=10000），output维度为[10000,10]</span></span><br><span class="line">                predict_y = torch.<span class="built_in">max</span>(outputs, dim=<span class="number">1</span>)[<span class="number">1</span>] <span class="comment"># 以output中值最大位置对应的索引（标签）作为预测输出</span></span><br><span class="line">                accuracy = (predict_y == test_label).<span class="built_in">sum</span>().item() / test_label.size(<span class="number">0</span>)</span><br><span class="line">                </span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&#x27;[%d, %5d] train_loss: %.3f  test_accuracy: %.3f&#x27;</span> %  <span class="comment"># 打印epoch，step，loss，accuracy</span></span><br><span class="line">                      (epoch + <span class="number">1</span>, step + <span class="number">1</span>, running_loss / <span class="number">500</span>, accuracy))</span><br><span class="line">                </span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&#x27;%f s&#x27;</span> % (time.perf_counter() - time_start))        <span class="comment"># 打印耗时</span></span><br><span class="line">                running_loss = <span class="number">0.0</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Finished Training&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 保存训练得到的参数</span></span><br><span class="line">save_path = <span class="string">&#x27;./Lenet.pth&#x27;</span></span><br><span class="line">torch.save(net.state_dict(), save_path)</span><br></pre></td></tr></table></figure><p>打印信息如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[<span class="number">1</span>,  <span class="number">1000</span>] train_loss: <span class="number">1.537</span>  test_accuracy: <span class="number">0.541</span></span><br><span class="line"><span class="number">35.345407</span> s</span><br><span class="line">[<span class="number">2</span>,  <span class="number">1000</span>] train_loss: <span class="number">1.198</span>  test_accuracy: <span class="number">0.605</span></span><br><span class="line"><span class="number">40.532376</span> s</span><br><span class="line">[<span class="number">3</span>,  <span class="number">1000</span>] train_loss: <span class="number">1.048</span>  test_accuracy: <span class="number">0.641</span></span><br><span class="line"><span class="number">44.144097</span> s</span><br><span class="line">[<span class="number">4</span>,  <span class="number">1000</span>] train_loss: <span class="number">0.954</span>  test_accuracy: <span class="number">0.647</span></span><br><span class="line"><span class="number">41.313228</span> s</span><br><span class="line">[<span class="number">5</span>,  <span class="number">1000</span>] train_loss: <span class="number">0.882</span>  test_accuracy: <span class="number">0.662</span></span><br><span class="line"><span class="number">41.860646</span> s</span><br><span class="line">Finished Training</span><br></pre></td></tr></table></figure><h4 id="使用GPU-x2F-CPU训练"><a href="#使用GPU-x2F-CPU训练" class="headerlink" title="使用GPU&#x2F;CPU训练"></a>使用GPU&#x2F;CPU训练</h4><p>使用下面语句可以在有GPU时使用GPU，无GPU时使用CPU进行训练</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">device = torch.device(<span class="string">&quot;cuda&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(device)</span><br></pre></td></tr></table></figure><p>也可以直接指定</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">device = torch.device(<span class="string">&quot;cuda&quot;</span>)</span><br><span class="line"><span class="comment"># 或者</span></span><br><span class="line"><span class="comment"># device = torch.device(&quot;cpu&quot;)</span></span><br></pre></td></tr></table></figure><p>对应的，需要用<code>to()</code>函数来将Tensor在CPU和GPU之间相互移动，分配到指定的device中计算</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">net = LeNet()</span><br><span class="line">net.to(device) <span class="comment"># 将网络分配到指定的device中</span></span><br><span class="line">loss_function = nn.CrossEntropyLoss() </span><br><span class="line">optimizer = optim.Adam(net.parameters(), lr=<span class="number">0.001</span>) </span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>): </span><br><span class="line"></span><br><span class="line">    running_loss = <span class="number">0.0</span></span><br><span class="line">    time_start = time.perf_counter()<span class="comment">#添加计时器</span></span><br><span class="line">    <span class="keyword">for</span> step, data <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_loader, start=<span class="number">0</span>):</span><br><span class="line">        inputs, labels = data</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        outputs = net(inputs.to(device))  <span class="comment"># 将inputs分配到指定的device中</span></span><br><span class="line">        loss = loss_function(outputs, labels.to(device))  <span class="comment"># 将labels分配到指定的device中</span></span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line">        running_loss += loss.item()</span><br><span class="line">        <span class="keyword">if</span> step % <span class="number">1000</span> == <span class="number">999</span>:    </span><br><span class="line">            <span class="keyword">with</span> torch.no_grad(): </span><br><span class="line">                outputs = net(test_image.to(device)) <span class="comment"># 将test_image分配到指定的device中</span></span><br><span class="line">                predict_y = torch.<span class="built_in">max</span>(outputs, dim=<span class="number">1</span>)[<span class="number">1</span>]</span><br><span class="line">                accuracy = (predict_y == test_label.to(device)).<span class="built_in">sum</span>().item() / test_label.size(<span class="number">0</span>) <span class="comment"># 将test_label分配到指定的device中</span></span><br><span class="line"></span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&#x27;[%d, %5d] train_loss: %.3f  test_accuracy: %.3f&#x27;</span> %</span><br><span class="line">                      (epoch + <span class="number">1</span>, step + <span class="number">1</span>, running_loss / <span class="number">1000</span>, accuracy))</span><br><span class="line"></span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&#x27;%f s&#x27;</span> % (time.perf_counter() - time_start))</span><br><span class="line">                running_loss = <span class="number">0.0</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Finished Training&#x27;</span>)</span><br><span class="line"></span><br><span class="line">save_path = <span class="string">&#x27;./Lenet.pth&#x27;</span></span><br><span class="line">torch.save(net.state_dict(), save_path)</span><br></pre></td></tr></table></figure><p>打印信息如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">cuda</span><br><span class="line">[<span class="number">1</span>,  <span class="number">1000</span>] train_loss: <span class="number">1.569</span>  test_accuracy: <span class="number">0.527</span></span><br><span class="line"><span class="number">18.727597</span> s</span><br><span class="line">[<span class="number">2</span>,  <span class="number">1000</span>] train_loss: <span class="number">1.235</span>  test_accuracy: <span class="number">0.595</span></span><br><span class="line"><span class="number">17.367685</span> s</span><br><span class="line">[<span class="number">3</span>,  <span class="number">1000</span>] train_loss: <span class="number">1.076</span>  test_accuracy: <span class="number">0.623</span></span><br><span class="line"><span class="number">17.654908</span> s</span><br><span class="line">[<span class="number">4</span>,  <span class="number">1000</span>] train_loss: <span class="number">0.984</span>  test_accuracy: <span class="number">0.639</span></span><br><span class="line"><span class="number">17.861825</span> s</span><br><span class="line">[<span class="number">5</span>,  <span class="number">1000</span>] train_loss: <span class="number">0.917</span>  test_accuracy: <span class="number">0.649</span></span><br><span class="line"><span class="number">17.733115</span> s</span><br><span class="line">Finished Training</span><br></pre></td></tr></table></figure><p>可以看到，用GPU训练时，速度提升明显，耗时缩小。</p><hr><h3 id="Predict-py"><a href="#Predict-py" class="headerlink" title="Predict.py"></a>Predict.py</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 导入包</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torchvision.transforms <span class="keyword">as</span> transforms</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">from</span> model <span class="keyword">import</span> LeNet</span><br><span class="line"></span><br><span class="line"><span class="comment"># 数据预处理</span></span><br><span class="line">transform = transforms.Compose(</span><br><span class="line">    [transforms.Resize((<span class="number">32</span>, <span class="number">32</span>)), <span class="comment"># 首先需resize成跟训练集图像一样的大小</span></span><br><span class="line">     transforms.ToTensor(),</span><br><span class="line">     transforms.Normalize((<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>), (<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>))])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 导入要测试的图像（自己找的，不在数据集中），放在源文件目录下</span></span><br><span class="line">im = Image.<span class="built_in">open</span>(<span class="string">&#x27;horse.jpg&#x27;</span>)</span><br><span class="line">im = transform(im)  <span class="comment"># [C, H, W]</span></span><br><span class="line">im = torch.unsqueeze(im, dim=<span class="number">0</span>)  <span class="comment"># 对数据增加一个新维度，因为tensor的参数是[batch, channel, height, width] </span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 实例化网络，加载训练好的模型参数</span></span><br><span class="line">net = LeNet()</span><br><span class="line">net.load_state_dict(torch.load(<span class="string">&#x27;Lenet.pth&#x27;</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 预测</span></span><br><span class="line">classes = (<span class="string">&#x27;plane&#x27;</span>, <span class="string">&#x27;car&#x27;</span>, <span class="string">&#x27;bird&#x27;</span>, <span class="string">&#x27;cat&#x27;</span>,</span><br><span class="line">           <span class="string">&#x27;deer&#x27;</span>, <span class="string">&#x27;dog&#x27;</span>, <span class="string">&#x27;frog&#x27;</span>, <span class="string">&#x27;horse&#x27;</span>, <span class="string">&#x27;ship&#x27;</span>, <span class="string">&#x27;truck&#x27;</span>)</span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    outputs = net(im)</span><br><span class="line">    predict = torch.<span class="built_in">max</span>(outputs, dim=<span class="number">1</span>)[<span class="number">1</span>].data.numpy()</span><br><span class="line"><span class="built_in">print</span>(classes[<span class="built_in">int</span>(predict)])</span><br></pre></td></tr></table></figure><p>输出即为预测的标签。</p><p>其实预测结果也可以用 <strong>softmax</strong> 表示，输出10个概率：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    outputs = net(im)</span><br><span class="line">    predict = torch.softmax(outputs, dim=<span class="number">1</span>)</span><br><span class="line"><span class="built_in">print</span>(predict)</span><br></pre></td></tr></table></figure><p>输出结果中最大概率值对应的索引即为 预测标签 的索引。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tensor([[<span class="number">2.2782e-06</span>, <span class="number">2.1008e-07</span>, <span class="number">1.0098e-04</span>, <span class="number">9.5135e-05</span>, <span class="number">9.3220e-04</span>, <span class="number">2.1398e-04</span>,</span><br><span class="line">         <span class="number">3.2954e-08</span>, <span class="number">9.9865e-01</span>, <span class="number">2.8895e-08</span>, <span class="number">2.8820e-07</span>]])</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 人工智能 </tag>
            
            <tag> LeNet </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Pytorch的安装指南</title>
      <link href="/2022/12/10/How%20to%20install%20Pytorch/"/>
      <url>/2022/12/10/How%20to%20install%20Pytorch/</url>
      
        <content type="html"><![CDATA[<h1 id="Pytorch的安装指南"><a href="#Pytorch的安装指南" class="headerlink" title="Pytorch的安装指南"></a>Pytorch的安装指南</h1><h2 id="视频教程"><a href="#视频教程" class="headerlink" title="视频教程"></a>视频教程</h2><p><a href="https://www.bilibili.com/video/BV1ov41137Z8">环境配置</a></p><p>PS：嫌麻烦anaconda在base环境就行，不需要再建立一个新环境，以防萌新环境混乱。</p><h2 id="一堆官网"><a href="#一堆官网" class="headerlink" title="一堆官网"></a>一堆官网</h2><p>CUDA：<a href="https://developer.nvidia.com/zh-cn/cuda-toolkit">https://developer.nvidia.com/zh-cn/cuda-toolkit</a></p><p>Cudnn：<a href="https://developer.nvidia.com/rdp/cudnn-archive">https://developer.nvidia.com/rdp/cudnn-archive</a></p><p>Pytorch：<a href="https://pytorch.org/">https://pytorch.org/</a></p><h3 id="个人版本："><a href="#个人版本：" class="headerlink" title="个人版本："></a>个人版本：</h3><p>CUDA：</p><figure class="highlight http"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">https://developer.nvidia.com/cuda-11-7-1-download-archive</span><br></pre></td></tr></table></figure><p>Cudnn：</p><figure class="highlight http"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">https://developer.nvidia.com/compute/cudnn/secure/8.6.0/local_installers/11.8/cudnn-windows-x86_64-8.6.0.163_cuda11-archive.zip</span><br></pre></td></tr></table></figure><p>Pytorch：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda install pytorch torchvision torchaudio pytorch-cuda=<span class="number">11.7</span> -c pytorch -c nvidia</span><br></pre></td></tr></table></figure><p>前两个下载后一个在base环境安装</p><h2 id="一点提示"><a href="#一点提示" class="headerlink" title="一点提示"></a>一点提示</h2><h3 id="在pycharm中terminal直接启用anaconda-base环境的方法"><a href="#在pycharm中terminal直接启用anaconda-base环境的方法" class="headerlink" title="在pycharm中terminal直接启用anaconda-base环境的方法"></a>在pycharm中terminal直接启用anaconda-base环境的方法</h3><ol><li><p>找到该文件右击属性<img src="https://s2.loli.net/2022/12/10/4pC58E2IL9xqHwU.png" style="zoom:80%;" /></p></li><li><p>复制目标路径“cmd”开始所有内容</p><img src="https://s2.loli.net/2022/12/10/21sHhJmaxO9b3CS.png" style="zoom: 80%;" /></li><li><p>settings-tools-terminal-Shell path粘贴你复制的内容 点击OK 重启pycharm<img src="https://s2.loli.net/2022/12/10/m3EGIKWzU59AMb7.png"></p><h3 id="Anaconda中conda更新"><a href="#Anaconda中conda更新" class="headerlink" title="Anaconda中conda更新"></a>Anaconda中conda更新</h3><p>我们用<code>conda install xxx</code>来安装包时，经常会遇到如下问题：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">failed <span class="keyword">with</span> initial frozen solve. Retrying <span class="keyword">with</span> flexible solve.</span><br><span class="line">Solving environment: failed <span class="keyword">with</span> repodata <span class="keyword">from</span> current_repodata.json, will retry <span class="keyword">with</span> <span class="built_in">next</span> repodata source.</span><br><span class="line"><span class="number">12</span></span><br></pre></td></tr></table></figure><p>这其实是conda的环境不适配，我们需要将对环境进行更新，通过如下几个步骤：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看版本</span></span><br><span class="line">conda -V</span><br><span class="line"><span class="comment"># 更新conda环境</span></span><br><span class="line">conda update -n base conda</span><br><span class="line"><span class="comment"># 更新conda的所有包</span></span><br><span class="line">conda update --<span class="built_in">all</span></span><br><span class="line"><span class="number">123456</span></span><br></pre></td></tr></table></figure><p>做完这些之后，再用<code>conda install xxx</code>就不会有上面的问题了。</p></li></ol>]]></content>
      
      
      <categories>
          
          <category> 学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 人工智能 </tag>
            
            <tag> 学习资源 </tag>
            
            <tag> 安装指南 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>LeNet-1</title>
      <link href="/2022/12/10/LeNet%E7%BB%93%E6%9E%84%E5%8F%8A%E7%A0%94%E8%AF%BB/"/>
      <url>/2022/12/10/LeNet%E7%BB%93%E6%9E%84%E5%8F%8A%E7%A0%94%E8%AF%BB/</url>
      
        <content type="html"><![CDATA[<h1 id="Lenet结构及研读"><a href="#Lenet结构及研读" class="headerlink" title="Lenet结构及研读"></a>Lenet结构及研读</h1><p>论文原文下载 <a href="https://link.zhihu.com/?target=http://lushuangning.oss-cn-beijing.aliyuncs.com/CNN%25E5%25AD%25A6%25E4%25B9%25A0%25E7%25B3%25BB%25E5%2588%2597/Gradient-Based_Learning_Applied_to_Document_Recognition.pdf">《Gradient-Based Learning Applied to Document Recognition》</a></p><p><img src="https://s2.loli.net/2022/12/15/z9TWXaBcl6ewj2p.png"></p><p><img src="https://s2.loli.net/2022/12/15/4oq52dXg8zbmFlI.png"></p><h2 id="论文研读以及理解"><a href="#论文研读以及理解" class="headerlink" title="论文研读以及理解"></a>论文研读以及理解</h2><p>使用梯度下降算法的多层网络能够从大量样本中学习到复杂、高维、非线性的映射关系，这使得它们能够用于图像识别任务。在传统的模式识别模型中，手工设计的特征提取器用于从输入数据中提取相关信息并且消除不相关的变量。然后用一个可训练的分类器将结果特征向量分类成对应类别。在该方案中，一个标准的、全连接的多层网络用于当作分类器。一个更有意思的模式是特征提取器能够进行自我学习。在该字符识别任务中，<strong>原始输入的图像即可用于特征提取及分类（标准大小的图像）。虽然可以通过普通的全连接前馈网络成功完成字符识别等任务，但在部分方面仍存在问题。</strong></p><p>第一，<strong>图像比较大</strong>，通常包含几百个像素(pixels)。第一层包含上百个隐藏神经元的全连接层，会包含成千上万的权重。如此大量的参数提高了系统的识别能力，但也导致了需要大量的训练集。并且，存储如此大量的权重超出了当前的硬件承载能力。但是，对于图像或者语音应用而言，缺乏结构性的网络最大不足在于不具备平移、形变扭曲的不变性。在输入到固定大小的网络之前，字符图像或者其他的2D、1D信号必须经过大小的标准化和数据的归一化。不幸的是，没有一种预处理是完美的：手写数字一般在字符层面进行规范化，会导致每个字符的大小，倾斜，位置发生形变，外加上书写风格的差异，会导致输入对象中特征位置的显著变化。原则上，足够大小的全连接网络能够对这些变化具有鲁棒性。可是，这样的任务训练会导致多个具有相似权重模式的神经元位于输入的不同位置，便于检测输入中出现的任何不同特征。需要大量的训练样例来学习这些权重设置从而能够覆盖可能的变量空间。在下文所讨论的卷积网络中，平移不变性能够通过跨空间的权重复制（即权重共享）自动实现。</p><p>第二，<strong>全连接架构的一个不足在于输入的拓扑结构被完全忽略。</strong>输入变量可以以任何（固定）顺序呈现，而不会影响训练结果。与之相对的是，图像（或者语音的时间序列表示）具有健壮的2D局部结构：空间相邻的像素具有高度相关性。局部相关性对于提取局部特征来说具有巨大优势，因为相邻像素的权重可以分类为几类（比如：边，角等）。卷积神经网络通过限制感受野的隐藏神经元为局部大小从而强制提取局部特征。</p><h3 id="Convolutional-Networks-卷积网络"><a href="#Convolutional-Networks-卷积网络" class="headerlink" title="Convolutional Networks 卷积网络"></a><strong>Convolutional Networks 卷积网络</strong></h3><p>卷积网络通过三种架构思想（<strong>局部感受野(local receptive fields)<strong>、</strong>权重共享(shared weights)<strong>、下采样(sub-sampling)）来保证平移、尺度、和形变的不变性。图2中所展示的LeNet-5就是典型的用于字符识别的卷积网络。原始的字符输入图像是经过大小规范化和数据归一化的。局部感受野的连接神经元的理念可追溯到60年代早期的感知机理论，并且几乎与Hubel和Wiesel在猫的视觉系统中发现局部敏感、定向选择性神经元同时发生。局部连接在视觉学习的神经元模型中广泛使用。通过局部感受野，神经元能够提取初级的视觉特征，比如边缘、定点、角点（或者像语音频谱图相似的其他信号特征）。这些特征在接下来的层中能够用于提取高级特征。正如之前所言，输入的平移或者形变会导致特征位置的显著变化。此外，图像的局部特征检测器还可作用于整张图像。这种技术实现可通过强制整张图像不同地方的局部感受野拥有相同的权重向量（即权值共享）。通过这些神经元进行特征提取的输出结果称为特征图（feature map）。特征图的每一神经元都是通过前一层不同位置经过相同计算得来的。一个完整的卷积层是通过几个特征图联合组成的（通过不同的权重向量），因此可以在每个局部位置形成多重特征。图2中展现一个LeNet输入的完整的样本。首层拥有6张由隐藏神经元提取的特征图。特征图的每个神经元计算来自输入中5x5大小总共25个输入计算，这称之为神经元的感受野。每个神经元</strong>通过25个输入乘以25个可训练变量加上一个偏置</strong>得来。特征图中的连续单元的感受野以前一层中相应的连续单元为中心，所以相邻单元的感受野是重叠的。举个例子，在LeNet-5中的首个隐藏层，水平连续单元的感受野重叠5行4列。正如之前所提，特征图中的每个神经元共享相同的25个权重和一个偏置，从而使得输入图像的所有相似的局部特征。在同一层中的其他特征图使用不同的权重和偏置集合，因此能够提取不同类型的局部特征。在LeNet-5中，每一个输入位置，6张特征图都由同一位置的6种神经元组合进行提取。<strong>特征图的一系列实现通过感受野大小扫描输入图片的每一个位置，然后将结果保存在特征图的相同位置。这种操作等同于卷积，外接一个额外的偏置和压缩方法，因此命名为卷积网络(convolutional network)。</strong>卷积核是特征图中神经元所使用的权重结合。卷积层的一个有趣的特征是如果输入图像发生平移，特征图也会发生同样的平移，否则特征图图保持不变。这个特性是CNN对位移和形变保持鲁棒的基础。</p><p><img src="https://s2.loli.net/2022/12/15/kJN2YufDiH8mnPG.png"></p><p>一旦一个特征被提取，它的其他局部就变得不重要了。相对于其他特征的相关位置才是更相关的。举个例子，我们知道左上角区域输入图像包含一个水平线段的端点，右上角区域包括一个角点，下方垂直区域包含一个端点，我们就能得出输入图像为7。这些特征位置的精确对识别没什么帮助，反而不利于不同字符的识别。在特征图中降低精确位置信息的简单方式是通过<strong>降低空间分辨率(spatial resolution)。</strong>这可通过<strong>下采样层(sub-sampling layers)<strong>来达到目标。</strong>下采样层通过局部平均来降低特征图的分辨率</strong>，并且降低输出对平移、形变的敏感度。LeNet-5的第二个隐藏层即为下采样层。这层包含6张特征图，每一张特征图都对应前一层的每张特征图。每个神经元的感受野大小为2x2，每个神经元通过4个输入取平均，然后<strong>乘以一个可训练的参数外加一个偏置</strong>，最后通过一个<strong>sigmoid函数进行激活</strong>。连续单元具有不重叠的感受野。最后，经过<strong>下采样的特征图含有前一层特征图的一半大小的行和列</strong>。一个可训练的参数和偏置影响着最后的sigmoid非线性。如果系数过小，下采样层神经元相当于对输入做了模糊处理，相当于线性。如果系数较大，根据偏置的值下采样层可看成是“或”或者“与”操作。卷积层和下采样层的交替衔接，就形成了一种“金字塔”架构：在每一层，特征图的分辨率逐渐降低，而数量逐渐增加。在图2中的第三层隐藏层的每个神经元的计算来自于上一层的多个特征图的相关神经元计算。卷积和下采样结合的灵感来源于Hubel和Wiesel的“简单”和“复杂”细胞概念，虽然那个时候没有像反向传播算法一样的全局监督学习过程。下采样层结合多个特征图的丰富表达可以<strong>大大提高网络对几何变换的不变性</strong>。</p><p>自从所有权重可通过反向传播算法学习以后，卷积网络能够被视为可自我学习的特征提取器。权重共享的技术能够大大减少参数的使用量，并且该技术降低了机器的“能力”，同时该技术还减小了测试误差和训练误差之间的差距。图2中的网络包含340908个连接，但通过权值共享后，只需要60000个可训练参数。</p><p>固定大小的卷积网络已经适用于各种应用，包括手写识别任务、机打字符识别、在线手写识别以及人脸识别等。**在单个时间维度进行权值共享的固定大小的卷积网络称之为延时神经网络(TDNNs)**，TDNNs已经用于场景识别（没有下采样），语音字符识别（有下采样），独立的手写体字符识别以及手势验证。</p><h3 id="LeNet-5"><a href="#LeNet-5" class="headerlink" title="LeNet-5"></a><strong>LeNet-5</strong></h3><p>LeNet-5模型主要是针对灰度设计的，由Yann LeCun教授于1998年提出来的，它是第一个成功应用于数字识别问题的卷积神经网络。在MNIST数据中，它的准确率达到大约99.2%。典型的LeNet-5结构包含CONV layer，POOL layer和FC layer，顺序一般是 <strong>CONV layer-&gt;POOL layer-&gt;CONV layer-&gt;POOL layer-&gt;FC layer-&gt;FC layer-&gt;OUTPUT layer</strong>，即 y ^ \hat{y}y^​。下图所示的是一个数字识别的LeNet-5的模型结构：<br><img src="https://s2.loli.net/2022/12/15/HBzFcgRyKNUVI7Y.png"></p><p>该LeNet模型总共包含了大约6万个参数。值得一提的是，当时Yann LeCun提出的LeNet-5模型池化层使用的是average pool，而且各层激活函数一般是Sigmoid和tanh。现在，我们可以根据需要，做出改进，使用max pool和激活函数ReLU。</p><p><img src="https://s2.loli.net/2022/12/15/rlFvBmdcMtqzIVn.png"></p><p>这个网络虽然很小，但是它包含了<a href="http://cuijiahua.com/blog/tag/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a>的基本模块：卷积层，池化层，<a href="https://so.csdn.net/so/search?q=%E5%85%A8%E8%BF%9E%E6%8E%A5%E5%B1%82&spm=1001.2101.3001.7020">全连接层</a>。是其他深度学习模型的基础， 这里我们对LeNet-5进行深入分析。同时，通过实例分析，加深对与卷积层和池化层的理解。</p><p><img src="https://s2.loli.net/2022/12/15/fzksIaO4Vv2Dm75.png"></p><p>​    LeNet-5共<strong>有7层</strong>，不包含输入，每层都包含可训练参数；每个层有<strong>多个Feature Map</strong>，每个FeatureMap通过一种卷积滤波器提取输入的一种特征，然后每个FeatureMap有<strong>多个神经元。</strong></p><p><strong>各层参数详解：</strong></p><h4 id="1、INPUT层-输入层"><a href="#1、INPUT层-输入层" class="headerlink" title="1、INPUT层-输入层"></a>1、INPUT层-输入层</h4><p>​    首先是数据 INPUT 层，输入图像的尺寸统一归一化为32*32。</p><p>​    <strong>注意：本层不算LeNet-5的网络结构，传统上，不将输入层视为网络层次结构之一。</strong></p><h4 id="2、C1层-卷积层"><a href="#2、C1层-卷积层" class="headerlink" title="2、C1层-卷积层"></a>2、C1层-卷积层</h4><p>   输入图片：32*32</p><p>   卷积核大小：5*5</p><p>   卷积核种类：6</p><p>   输出featuremap大小：28*28 （32-5+1）&#x3D;28</p><p>   神经元数量：28<em>28</em>6</p><p>   可训练参数：（5<em>5+1) * 6（每个滤波器5</em>5&#x3D;25个unit参数和一个bias参数，一共6个滤波器）</p><p>   连接数：（5<em>5+1）</em>6<em>28</em>28&#x3D;122304</p><p>   <strong>详细说明：</strong>对输入图像进行第一次卷积运算（使用 6 个大小为 5<em>5 的卷积核），得到6个C1特征图（6个大小为28</em>28的 feature maps, 32-5+1&#x3D;28）。我们再来看看需要多少个参数，卷积核的大小为5<em>5，总共就有6</em>（5<em>5+1）&#x3D;156个参数，其中+1是表示一个核有一个bias。对于卷积层C1，C1内的每个像素都与输入图像中的5</em>5个像素和1个bias有连接，所以总共有156<em>28</em>28&#x3D;122304个连接（connection）。有122304个连接，但是我们只需要学习156个参数，主要是通过权值共享实现的。</p><h4 id="3、S2层-池化层（下采样层）"><a href="#3、S2层-池化层（下采样层）" class="headerlink" title="3、S2层-池化层（下采样层）"></a>3、S2层-池化层（下采样层）</h4><p>   输入：28*28</p><p>   采样区域：2*2</p><p>   采样方式：4个输入相加，乘以一个可训练参数，再加上一个可训练偏置。结果通过sigmoid</p><p>   采样种类：6</p><p>   输出featureMap大小：14*14（28&#x2F;2）</p><p>   神经元数量：14<em>14</em>6</p><p>   可训练参数：2*6（和的权+偏置）</p><p>   连接数：（2<em>2+1）</em>6<em>14</em>14</p><p>   S2中每个特征图的大小是C1中特征图大小的1&#x2F;4。</p><p>​    <strong>详细说明：</strong>第一次卷积之后紧接着就是池化运算，使用 2<em>2核 进行池化，于是得到了S2，6个14</em>14的 特征图（28&#x2F;2&#x3D;14）。S2这个pooling层是对C1中的2*2区域内的像素求和乘以一个权值系数再加上一个偏置，然后将这个结果再做一次映射。于是每个池化核有两个训练参数，所以共有2x6&#x3D;12个训练参数，但是有5x14x14x6&#x3D;5880个连接。</p><h4 id="4、C3层-卷积层"><a href="#4、C3层-卷积层" class="headerlink" title="4、C3层-卷积层"></a>4、C3层-卷积层</h4><p>​    输入：S2中所有6个或者几个特征map组合</p><p>   卷积核大小：5*5</p><p>   卷积核种类：16</p><p>   输出featureMap大小：10*10 (14-5+1)&#x3D;10</p><p>   C3中的每个特征map是连接到S2中的所有6个或者几个特征map的，表示本层的特征map是上一层提取到的特征map的不同组合。</p><p>​    存在的一个方式是：C3的前6个特征图以S2中3个相邻的特征图子集为输入。接下来6个特征图以S2中4个相邻特征图子集为输入。然后的3个以不相邻的4个特征图子集为输入。最后一个将S2中所有特征图为输入。则：可训练参数：6*(3<em>5</em>5+1)+6*(4<em>5</em>5+1)+3*(4<em>5</em>5+1)+1*(6<em>5</em>5+1)&#x3D;1516</p><p>​    连接数：10<em>10</em>1516&#x3D;151600</p><p>​    <strong>详细说明：</strong>第一次池化之后是第二次卷积，第二次卷积的输出是C3，16个10x10的特征图，卷积核大小是 5<em>5. 我们知道S2 有6个 14</em>14 的特征图，怎么从6 个特征图得到 16个特征图了？ 这里是通过对S2 的特征图特殊组合计算得到的16个特征图。具体如下：</p><p><img src="https://s2.loli.net/2022/12/15/bzQLhDZu7PrTqMe.png" alt="image-20221215224359251"></p><p>​    C3的前6个feature map（对应上图第一个红框的6列）与S2层相连的3个feature map相连接（上图第一个红框），后面6个feature map与S2层相连的4个feature map相连接（上图第二个红框），后面3个feature map与S2层部分不相连的4个feature map相连接，最后一个与S2层的所有feature map相连。卷积核大小依然为5<em>5，所以总共有6</em>(3<em>5</em>5+1)+6*(4<em>5</em>5+1)+3*(4<em>5</em>5+1)+1*(6<em>5</em>5+1)&#x3D;1516个参数。而图像大小为10*10，所以共有151600个连接。</p><p><img src="https://s2.loli.net/2022/12/15/hjOm5ZatkoErS39.png" alt="image-20221215224609718"></p><p>​    C3与S2中前3个图相连的卷积结构如下图所示：</p><p><img src="https://s2.loli.net/2022/12/15/DsCLyKd1uFVgUqt.png"></p><p>​    上图对应的参数为 3<em>5</em>5+1，一共进行6次卷积得到6个特征图，所以有6<em>（3</em>5*5+1）参数。 为什么采用上述这样的组合了？论文中说有两个原因：1）减少参数，2）这种不对称的组合连接的方式有利于提取多种组合特征。</p><h4 id="5、S4层-池化层（下采样层）"><a href="#5、S4层-池化层（下采样层）" class="headerlink" title="5、S4层-池化层（下采样层）"></a>5、S4层-池化层（下采样层）</h4><p>​    输入：10*10</p><p>​    采样区域：2*2</p><p>   采样方式：4个输入相加，乘以一个可训练参数，再加上一个可训练偏置。结果通过sigmoid</p><p>   采样种类：16</p><p>   输出featureMap大小：5*5（10&#x2F;2）</p><p>   神经元数量：5<em>5</em>16&#x3D;400</p><p>   可训练参数：2*16&#x3D;32（和的权+偏置）</p><p>   连接数：16<em>（2</em>2+1）<em>5</em>5&#x3D;2000</p><p>   S4中每个特征图的大小是C3中特征图大小的1&#x2F;4</p><p>   <strong>详细说明：</strong>S4是pooling层，窗口大小仍然是2*2，共计16个feature map，C3层的16个10x10的图分别进行以2x2为单位的池化得到16个5x5的特征图。这一层有2x16共32个训练参数，5x5x5x16&#x3D;2000个连接。连接的方式与S2层类似。</p><h4 id="6、C5层-卷积层"><a href="#6、C5层-卷积层" class="headerlink" title="6、C5层-卷积层"></a>6、C5层-卷积层</h4><p>   输入：S4层的全部16个单元特征map（与s4全相连）</p><p>   卷积核大小：5*5</p><p>   卷积核种类：120</p><p>   输出featureMap大小：1*1（5-5+1）</p><p>   可训练参数&#x2F;连接：120<em>（16</em>5*5+1）&#x3D;48120</p><p>   <strong>详细说明：</strong>C5层是一个卷积层。由于S4层的16个图的大小为5x5，与卷积核的大小相同，所以卷积后形成的图的大小为1x1。这里形成120个卷积结果。每个都与上一层的16个图相连。所以共有(5x5x16+1)x120 &#x3D; 48120个参数，同样有48120个连接。C5层的网络结构如下：</p><p><img src="https://s2.loli.net/2022/12/15/ue49pVs68dxlCkh.png"></p><h4 id="7、F6层-全连接层"><a href="#7、F6层-全连接层" class="headerlink" title="7、F6层-全连接层"></a>7、F6层-全连接层</h4><p>   输入：c5 120维向量</p><p>   计算方式：计算输入向量和权重向量之间的点积，再加上一个偏置，结果通过sigmoid函数输出。</p><p>   可训练参数:84*(120+1)&#x3D;10164</p><p>   <strong>详细说明：</strong>6层是全连接层。F6层有84个节点，对应于一个7x12的比特图，-1表示白色，1表示黑色，这样每个符号的比特图的黑白色就对应于一个编码。该层的训练参数和连接数是(120 + 1)x84&#x3D;10164。ASCII编码图如下：</p><p><img src="https://s2.loli.net/2022/12/15/JiD9HlmRLqKzGF6.png"></p><p>   F6层的连接方式如下：</p><p><img src="https://s2.loli.net/2022/12/15/EZHMmayxz2QgwcV.png"></p><h4 id="8、Output层-全连接层"><a href="#8、Output层-全连接层" class="headerlink" title="8、Output层-全连接层"></a>8、Output层-全连接层</h4><p>​    Output层也是全连接层，共有10个节点，分别代表数字0到9，且如果节点i的值为0，则网络识别的结果是数字i。采用的是径向基函数（RBF）的网络连接方式。假设x是上一层的输入，y是RBF的输出，则RBF输出的计算方式是：</p><p><img src="https://s2.loli.net/2022/12/15/HZL3t5vycbSVKfd.png"></p><p>   上式w_ij 的值由i的比特图编码确定，i从0到9，j取值从0到7*12-1。RBF输出的值越接近于0，则越接近于i，即越接近于i的ASCII编码图，表示当前网络输入的识别结果是字符i。该层有84x10&#x3D;840个参数和连接。</p><p><img src="https://s2.loli.net/2022/12/15/pdVS2koYELIah57.png"></p><p>上图是LeNet-5识别数字3的过程。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><ul><li>LeNet-5是一种用于手写体字符识别的非常高效的卷积神经网络。</li><li>卷积神经网络能够很好的利用图像的结构信息。</li><li>卷积层的参数较少，这也是由卷积层的主要特性即<strong>局部连接</strong>和<strong>共享权重</strong>所决定。</li></ul>]]></content>
      
      
      <categories>
          
          <category> 学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 人工智能 </tag>
            
            <tag> LeNet </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>贪吃蛇大作战分析</title>
      <link href="/2022/12/09/%E8%B4%AA%E5%90%83%E8%9B%87%E5%A4%A7%E4%BD%9C%E6%88%98%E5%88%86%E6%9E%90/"/>
      <url>/2022/12/09/%E8%B4%AA%E5%90%83%E8%9B%87%E5%A4%A7%E4%BD%9C%E6%88%98%E5%88%86%E6%9E%90/</url>
      
        <content type="html"><![CDATA[<h1 id="与对象玩游戏的思考-1"><a href="#与对象玩游戏的思考-1" class="headerlink" title="与对象玩游戏的思考-1"></a>与对象玩游戏的思考-1</h1><img src="https://s2.loli.net/2022/12/10/UxC3Bh7DOsmAtMK.png" alt="贪吃蛇大作战LOGO" style="zoom:33%;" /><p>贪吃蛇大作战是一款对象爱玩的游戏，我也经常陪她一起玩，一开始觉得这个游戏些许幼稚，但一段时间发先此游戏确实有些独特之处，我仅站在我的角度对此款游戏进行分析。</p><h2 id="游戏操作"><a href="#游戏操作" class="headerlink" title="游戏操作"></a>游戏操作</h2><p>作为一款IO型游戏（.io域名网页移植型游戏）它必定轻量化且易上手。左侧摇杆进行方向控制，右侧控制加速按钮和道具&#x2F;技能按钮。玩家通过操控贪吃蛇食取地图上的粒子和大粒子以及道具，延长自身长度。通过灵活操作让别的贪吃蛇撞到自身身体部分达成击杀。对象作为一个讨厌复杂操作的游戏玩家很容易掌握，其上手门槛极低，老少咸宜。</p><h2 id="游戏模式"><a href="#游戏模式" class="headerlink" title="游戏模式"></a>游戏模式</h2><p>实际上分为两类：</p><ul><li>人机模式（无尽模式及其衍生）</li><li>PvP模式（团战模式，击杀模式）</li></ul><p>前者对应了需要打发时间的休闲玩家，后者对应了有对战需求的竞技玩家。其各个模式都含有玩家的排行榜，鼓励玩家游玩。</p><h2 id="运营思路"><a href="#运营思路" class="headerlink" title="运营思路"></a>运营思路</h2><p>作为一款运营6年的游戏，微派网络的运营显然是成功的。但于此同时，观察微派网络官方的产品介绍，微派至今未能拿出较为重量的游戏产品…</p><p>贪吃蛇的运营思路：广告＋效果付费+礼物</p><p>对于免费玩家，通过看广告奖励游戏道具创收。对于付费玩家，通过游戏皮肤，击杀效果等场上道具，以及社群属性的赠送礼物，以及诸多例如show值，魅力值等系统排行展示，诱导消费。</p><h2 id="游戏弊端"><a href="#游戏弊端" class="headerlink" title="游戏弊端"></a>游戏弊端</h2><p>游戏的弊端大多存在于PvP模式下。</p><ul><li><p>网络平衡和链接稳定性差：网络稳定性是作为IO游戏能愉快游玩的关键因素，在不同网络条件下，同一局能一起愉快游玩必须做好网络平衡，否则对部分玩家，体验极差。然而贪吃蛇大作战的解决方案既不是增加链接更近的服务器，降低网络延迟。也不是交出满意的游戏网络平衡方案。而是通过减少网络质量差玩家的加速按钮使用来控制。不止到读者是否遇到加速按钮按不动没有效果的情况，极其影响竞技体验。（补充：同样的网络环境跑腾讯系游戏40ms EA平台94ms 但在贪吃蛇游戏中要么140+ 要么就是绿色信号的但卡按钮）</p></li><li><p>游戏皮肤平衡未完善；游戏皮肤不应该成为影响竞技体验的要素，但经过较长时间的游玩发现，不同皮肤的头部碰撞箱判定是不同的，导致对无皮肤玩家的不公平。</p></li><li><p>游戏判定问题：完全正碰无法计算。随机给一方？</p></li><li><p>游戏机型优化：苹果系设备在promotion高刷支持下游戏对局流畅度明显高于安卓机型，此外在PvP模式下此类特殊优化体验甚至高于网络优化令人唏嘘。</p></li></ul>]]></content>
      
      
      <categories>
          
          <category> 杂谈 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 贪吃蛇大作战 </tag>
            
            <tag> 游戏分析 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>神经网络基础模型学习资源</title>
      <link href="/2022/12/08/%E8%B5%84%E6%BA%90%E5%88%97%E8%A1%A8/"/>
      <url>/2022/12/08/%E8%B5%84%E6%BA%90%E5%88%97%E8%A1%A8/</url>
      
        <content type="html"><![CDATA[<h1 id="神经网络基础模型学习资源"><a href="#神经网络基础模型学习资源" class="headerlink" title="神经网络基础模型学习资源"></a>神经网络基础模型学习资源</h1><h2 id="视频课"><a href="#视频课" class="headerlink" title="视频课"></a>视频课</h2><ul><li><p><a href="https://space.bilibili.com/18161609/"><strong>霹雳吧啦Wz基础教程</strong></a></p></li><li><p><a href="https://space.bilibili.com/21241234"><strong>刘二大人</strong></a></p></li></ul><h2 id="博客笔记"><a href="#博客笔记" class="headerlink" title="博客笔记"></a>博客笔记</h2><ul><li><p><a href="https://blog.csdn.net/m0_37867091?type=blog"><strong>CSDN神经网络</strong></a></p></li><li><p><a href="https://redstonewill.com/category/ai-notes/"><strong>红色石头</strong></a></p></li><li><p><a href="http://www.ai-start.com/"><strong>吴恩达笔记</strong></a></p></li></ul><h2 id="可视化"><a href="#可视化" class="headerlink" title="可视化"></a>可视化</h2><p>部分摘自<a href="https://cloud.tencent.com/developer/article/1882674">数据studio</a>，部分自行收集</p><h3 id="1、PlotNeuralNet"><a href="#1、PlotNeuralNet" class="headerlink" title="1、PlotNeuralNet"></a><strong>1、PlotNeuralNet</strong></h3><p>使用<strong>Latex</strong>绘制神经网络。传送门：<a href="https://github.com/HarisIqbal88/PlotNeuralNet">https://github.com/HarisIqbal88/PlotNeuralNet</a></p><p><img src="https://s2.loli.net/2022/12/10/zCPAx53wpQiryVj.png"></p><p>FCN-8模型</p><p>overleaf上Latex代码：<a href="https://www.overleaf.com/read/kkqntfxnvbsk">https://www.overleaf.com/read/kkqntfxnvbsk</a></p><p><img src="https://s2.loli.net/2022/12/10/Qy4pCEc7GMR6jnP.png"></p><p>FCN-32模型</p><p>overleaf上Latex代码：<a href="https://www.overleaf.com/read/wsxpmkqvjnbs">https://www.overleaf.com/read/wsxpmkqvjnbs</a></p><p><img src="https://s2.loli.net/2022/12/10/Izuf4rYX8WbwaCj.png"></p><p>Holistically-Nested Edge Detection</p><p>overleaf上Latex代码：<a href="https://www.overleaf.com/read/jxhnkcnwhfxp">https://www.overleaf.com/read/jxhnkcnwhfxp</a></p><hr><h3 id="2、Matlab"><a href="#2、Matlab" class="headerlink" title="2、Matlab"></a><strong>2、Matlab</strong></h3><p><a href="https://www.mathworks.com/help/deeplearning/ref/view.html;jsessionid=bd77484ba149c98d4d410abed983">https://www.mathworks.com/help/deeplearning/ref/view.html;jsessionid=bd77484ba149c98d4d410abed983</a></p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[x,t] = iris_dataset;</span><br><span class="line">net = patternnet;</span><br><span class="line">net = <span class="title function_">configure</span>(net,x,t);</span><br><span class="line"><span class="title function_">view</span>(net)</span><br></pre></td></tr></table></figure><p>复制</p><p><img src="https://s2.loli.net/2022/12/10/y1eJVsHdMI2mDUA.png"></p><hr><h3 id="3、NN-SVG"><a href="#3、NN-SVG" class="headerlink" title="3、NN-SVG"></a><strong>3、NN-SVG</strong></h3><p>一个在线工具，点点就阔以了：<a href="http://alexlenail.me/NN-SVG/LeNet.html">http://alexlenail.me/NN-SVG/LeNet.html</a></p><p><img src="https://s2.loli.net/2022/12/10/8Xfd1VzRA3iI5gG.png"></p><p>AlexNet模型</p><p><img src="https://s2.loli.net/2022/12/10/A5TNwfOHscE4yBr.png"></p><p>LeNet模型</p><hr><h3 id="4、graphcore"><a href="#4、graphcore" class="headerlink" title="4、graphcore"></a><strong>4、graphcore</strong></h3><p>回到神经网络最初的地方，<strong>像生物细胞神经元neurons一样展示神经网络</strong>。<a href="https://www.graphcore.ai/posts/what-does-machine-learning-look-like">https://www.graphcore.ai/posts/what-does-machine-learning-look-like</a></p><p><img src="https://s2.loli.net/2022/12/10/t4LcPpaTgr7doCk.png"></p><p>生物细胞神经元模式图</p><p>AlexNet模型</p><p><img src="https://s2.loli.net/2022/12/10/MFJdwH2nvSX3RIb.png"></p><p>Resnet 50模型</p><hr><h3 id="5、graphviz"><a href="#5、graphviz" class="headerlink" title="5、graphviz"></a><strong>5、graphviz</strong></h3><p><a href="http://www.graphviz.org/">http://www.graphviz.org/</a></p><p>之前介绍过一个类似绘制网络关系的工具👉<a href="https://mp.weixin.qq.com/s?__biz=MzUwOTg0MjczNw==&mid=2247492450&idx=1&sn=045f3fad7573bef525c972b4e91e76c3&chksm=f90ea73cce792e2a92430c0eff73415380efce970f2641814f321fc2260a70ea686369925f3c&token=1079425073&lang=zh_CN&scene=21#wechat_redirect"><strong>盘一盘社交网络分析常用networks</strong></a></p><p><img src="https://s2.loli.net/2022/12/10/GZtAEw8HQUjRNeC.png"></p><p>4层网络</p><hr><h3 id="6、Keras"><a href="#6、Keras" class="headerlink" title="6、Keras"></a><strong>6、Keras</strong></h3><p><strong>深度学习框架Keras</strong>下的一个小模块，</p><p><a href="https://keras.io/api/utils/model_plotting_utils/">https://keras.io/api/utils/model_plotting_utils/</a></p><p><img src="https://s2.loli.net/2022/12/10/u9INipoZPFWMv37.png"></p><hr><h3 id="7、neataptic"><a href="#7、neataptic" class="headerlink" title="7、neataptic"></a><strong>7、neataptic</strong></h3><p><a href="https://github.com/wagenaartje/neataptic">https://github.com/wagenaartje/neataptic</a></p><p><img src="https://s2.loli.net/2022/12/10/M4s7r1JSgIKnFVf.png"></p><hr><h3 id="8、Quiver"><a href="#8、Quiver" class="headerlink" title="8、Quiver"></a><strong>8、Quiver</strong></h3><p><a href="https://github.com/keplr-io/quiver">https://github.com/keplr-io/quiver</a></p><p><img src="https://s2.loli.net/2022/12/10/klFsLSt7u4OfiXP.png"></p><hr><h3 id="9、Keras-js"><a href="#9、Keras-js" class="headerlink" title="9、Keras.js"></a><strong>9、Keras.js</strong></h3><p>在线工具</p><p><a href="https://transcranial.github.io/keras-js/#/inception-v3">https://transcranial.github.io/keras-js/#/inception-v3</a></p><p><img src="https://s2.loli.net/2022/12/10/lDbWQ4d7kZsVoRe.png"></p><p><img src="https://s2.loli.net/2022/12/10/XuzvrIKjty7lF6E.png"></p><hr><h3 id="10、Netscope-CNN-Analyzer"><a href="#10、Netscope-CNN-Analyzer" class="headerlink" title="10、Netscope CNN Analyzer"></a><strong>10、Netscope CNN Analyzer</strong></h3><p><a href="http://dgschwend.github.io/netscope/quickstart.html">http://dgschwend.github.io/netscope/quickstart.html</a></p><p><img src="https://s2.loli.net/2022/12/10/l2tK6oys9UZgOan.png"></p><hr><h3 id="11、keras-sequential-ascii"><a href="#11、keras-sequential-ascii" class="headerlink" title="11、keras-sequential-ascii"></a><strong>11、keras-sequential-ascii</strong></h3><p><a href="https://github.com/stared/keras-sequential-ascii/">https://github.com/stared/keras-sequential-ascii/</a></p><p>VGG 16 Architecture</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line">     <span class="variable constant_">OPERATION</span>           <span class="variable constant_">DATA</span> <span class="variable constant_">DIMENSIONS</span>   <span class="title function_">WEIGHTS</span>(N)   <span class="title function_">WEIGHTS</span>(%)</span><br><span class="line"></span><br><span class="line">        <span class="title class_">Input</span>   #####      <span class="number">3</span>  <span class="number">224</span>  <span class="number">224</span></span><br><span class="line">   <span class="title class_">InputLayer</span>     |   -------------------         <span class="number">0</span>     <span class="number">0.0</span>%</span><br><span class="line">                #####      <span class="number">3</span>  <span class="number">224</span>  <span class="number">224</span></span><br><span class="line"><span class="title class_">Convolution2D</span>    \|/  -------------------      <span class="number">1792</span>     <span class="number">0.0</span>%</span><br><span class="line">         relu   #####     <span class="number">64</span>  <span class="number">224</span>  <span class="number">224</span></span><br><span class="line"><span class="title class_">Convolution2D</span>    \|/  -------------------     <span class="number">36928</span>     <span class="number">0.0</span>%</span><br><span class="line">         relu   #####     <span class="number">64</span>  <span class="number">224</span>  <span class="number">224</span></span><br><span class="line"> <span class="title class_">MaxPooling2D</span>   Y max -------------------         <span class="number">0</span>     <span class="number">0.0</span>%</span><br><span class="line">                #####     <span class="number">64</span>  <span class="number">112</span>  <span class="number">112</span></span><br><span class="line"><span class="title class_">Convolution2D</span>    \|/  -------------------     <span class="number">73856</span>     <span class="number">0.1</span>%</span><br><span class="line">         relu   #####    <span class="number">128</span>  <span class="number">112</span>  <span class="number">112</span></span><br><span class="line"><span class="title class_">Convolution2D</span>    \|/  -------------------    <span class="number">147584</span>     <span class="number">0.1</span>%</span><br><span class="line">         relu   #####    <span class="number">128</span>  <span class="number">112</span>  <span class="number">112</span></span><br><span class="line"> <span class="title class_">MaxPooling2D</span>   Y max -------------------         <span class="number">0</span>     <span class="number">0.0</span>%</span><br><span class="line">                #####    <span class="number">128</span>   <span class="number">56</span>   <span class="number">56</span></span><br><span class="line"><span class="title class_">Convolution2D</span>    \|/  -------------------    <span class="number">295168</span>     <span class="number">0.2</span>%</span><br><span class="line">         relu   #####    <span class="number">256</span>   <span class="number">56</span>   <span class="number">56</span></span><br><span class="line"><span class="title class_">Convolution2D</span>    \|/  -------------------    <span class="number">590080</span>     <span class="number">0.4</span>%</span><br><span class="line">         relu   #####    <span class="number">256</span>   <span class="number">56</span>   <span class="number">56</span></span><br><span class="line"><span class="title class_">Convolution2D</span>    \|/  -------------------    <span class="number">590080</span>     <span class="number">0.4</span>%</span><br><span class="line">         relu   #####    <span class="number">256</span>   <span class="number">56</span>   <span class="number">56</span></span><br><span class="line"> <span class="title class_">MaxPooling2D</span>   Y max -------------------         <span class="number">0</span>     <span class="number">0.0</span>%</span><br><span class="line">                #####    <span class="number">256</span>   <span class="number">28</span>   <span class="number">28</span></span><br><span class="line"><span class="title class_">Convolution2D</span>    \|/  -------------------   <span class="number">1180160</span>     <span class="number">0.9</span>%</span><br><span class="line">         relu   #####    <span class="number">512</span>   <span class="number">28</span>   <span class="number">28</span></span><br><span class="line"><span class="title class_">Convolution2D</span>    \|/  -------------------   <span class="number">2359808</span>     <span class="number">1.7</span>%</span><br><span class="line">         relu   #####    <span class="number">512</span>   <span class="number">28</span>   <span class="number">28</span></span><br><span class="line"><span class="title class_">Convolution2D</span>    \|/  -------------------   <span class="number">2359808</span>     <span class="number">1.7</span>%</span><br><span class="line">         relu   #####    <span class="number">512</span>   <span class="number">28</span>   <span class="number">28</span></span><br><span class="line"> <span class="title class_">MaxPooling2D</span>   Y max -------------------         <span class="number">0</span>     <span class="number">0.0</span>%</span><br><span class="line">                #####    <span class="number">512</span>   <span class="number">14</span>   <span class="number">14</span></span><br><span class="line"><span class="title class_">Convolution2D</span>    \|/  -------------------   <span class="number">2359808</span>     <span class="number">1.7</span>%</span><br><span class="line">         relu   #####    <span class="number">512</span>   <span class="number">14</span>   <span class="number">14</span></span><br><span class="line"><span class="title class_">Convolution2D</span>    \|/  -------------------   <span class="number">2359808</span>     <span class="number">1.7</span>%</span><br><span class="line">         relu   #####    <span class="number">512</span>   <span class="number">14</span>   <span class="number">14</span></span><br><span class="line"><span class="title class_">Convolution2D</span>    \|/  -------------------   <span class="number">2359808</span>     <span class="number">1.7</span>%</span><br><span class="line">         relu   #####    <span class="number">512</span>   <span class="number">14</span>   <span class="number">14</span></span><br><span class="line"> <span class="title class_">MaxPooling2D</span>   Y max -------------------         <span class="number">0</span>     <span class="number">0.0</span>%</span><br><span class="line">                #####    <span class="number">512</span>    <span class="number">7</span>    <span class="number">7</span></span><br><span class="line">      <span class="title class_">Flatten</span>   ||||| -------------------         <span class="number">0</span>     <span class="number">0.0</span>%</span><br><span class="line">                #####       <span class="number">25088</span></span><br><span class="line">        <span class="title class_">Dense</span>   <span class="variable constant_">XXXXX</span> ------------------- <span class="number">102764544</span>    <span class="number">74.3</span>%</span><br><span class="line">         relu   #####        <span class="number">4096</span></span><br><span class="line">        <span class="title class_">Dense</span>   <span class="variable constant_">XXXXX</span> -------------------  <span class="number">16781312</span>    <span class="number">12.1</span>%</span><br><span class="line">         relu   #####        <span class="number">4096</span></span><br><span class="line">        <span class="title class_">Dense</span>   <span class="variable constant_">XXXXX</span> -------------------   <span class="number">4097000</span>     <span class="number">3.0</span>%</span><br><span class="line">      softmax   #####        <span class="number">1000</span></span><br></pre></td></tr></table></figure><p>复制</p><hr><h3 id="12、TensorBoard"><a href="#12、TensorBoard" class="headerlink" title="12、TensorBoard"></a><strong>12、TensorBoard</strong></h3><p>一个评估<strong>深度学习框架TensorFlow</strong>模型的强力工具。</p><p><a href="https://www.tensorflow.org/tensorboard/graphs">https://www.tensorflow.org/tensorboard/graphs</a></p><p><img src="https://s2.loli.net/2022/12/10/2t4CA6bsEfDwJrP.png"></p><hr><h3 id="13、Caffe"><a href="#13、Caffe" class="headerlink" title="13、Caffe"></a><strong>13、Caffe</strong></h3><p>同样是<strong>深度学习框架Caffe</strong>下的一个小工具，</p><p><a href="https://github.com/BVLC/caffe/blob/master/python/caffe/draw.py">https://github.com/BVLC/caffe/blob/master/python/caffe/draw.py</a></p><p><img src="https://s2.loli.net/2022/12/10/FCp5ri67XHos8kd.png"></p><hr><h3 id="14、TensorSpace"><a href="#14、TensorSpace" class="headerlink" title="14、TensorSpace"></a><strong>14、TensorSpace</strong></h3><p><strong>3D模式展示神经网络</strong>，</p><p><a href="https://tensorspace.org/">https://tensorspace.org/</a></p><p><img src="https://s2.loli.net/2022/12/10/sH7plYeB3qMA982.png"></p><hr><h3 id="15、CNN-Explainer"><a href="#15、CNN-Explainer" class="headerlink" title="15、CNN Explainer"></a><strong>15、CNN Explainer</strong></h3><p>CNN解释器是 CNN可视化的工具，对于小白而言，CNN可视化对于理解CNN有非常的帮助，因此，花了几天的时间，将CNN解释器网站做了一个翻译，还包括安装CNN解释器的过程和相关资料。<br>CNN解释器地址：<a href="https://poloclub.github.io/cnn-explainer">CNN Explainer</a></p><p>CNN解释器文献：<a href="https://arxiv.org/abs/2004.15004">CNN Explainer: Learning Convolutional Neural Networks with Interactive Visualization</a></p><p>CNN github地址：<a href="https://github.com/poloclub/cnn-explainer">https://github.com/poloclub/cnn-explainer</a></p><p>CNN解释器安装：<a href="https://zhuanlan.zhihu.com/p/141537738">https://zhuanlan.zhihu.com/p/141537738</a> </p><p><img src="https://s2.loli.net/2022/12/10/IXrZRDbckK71hW6.png"></p><h3 id="16、基本操作-人工智能的诞生"><a href="#16、基本操作-人工智能的诞生" class="headerlink" title="16、基本操作-人工智能的诞生"></a><strong>16、基本操作-人工智能的诞生</strong></h3><p>交互视频课程，极其适合初学者，就是有点贵，运营歪屁股<br><a href="https://jibencaozuo.com/zh-Hans/videoSeries/1/episode/0">人工智能的诞生</a></p><p><img src="https://s2.loli.net/2022/12/10/MsajcZUqnVoYAHd.png"></p>]]></content>
      
      
      <categories>
          
          <category> 学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 人工智能 </tag>
            
            <tag> 学习资源 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CNN</title>
      <link href="/2022/12/08/CNN%E5%9F%BA%E7%A1%80/"/>
      <url>/2022/12/08/CNN%E5%9F%BA%E7%A1%80/</url>
      
        <content type="html"><![CDATA[<h1 id="CNN基础"><a href="#CNN基础" class="headerlink" title="CNN基础"></a>CNN基础</h1><h2 id="计算机视觉"><a href="#计算机视觉" class="headerlink" title="计算机视觉"></a>计算机视觉</h2><ol><li><p><strong>图像分类（Image Classification）</strong></p></li><li><p><strong>目标识别（Object detection）</strong></p></li><li><p><strong>神经风格转换（Neural Style Transfer）</strong></p></li></ol><p><strong>使用传统神经网络处理机器视觉的一个主要问题是输入层维度很大</strong>。如果图片尺寸较大，例如一张1000x1000x3的图片，神经网络输入层的维度将达到3百万，使得<strong>网络权重W非常庞大</strong>。这样会造成两个后果，一是神经网络结构复杂，数据量相对不够，容易出现过拟合；二是所需内存、计算量较大。<strong>解决这一问题的方法就是使用卷积神经网络（CNN）。</strong></p><p><strong>CNN做的事情其实是，来简化这个neural network的架构，我们根据自己的知识和对图像处理的理解，一开始就把某些实际上用不到的参数给过滤掉</strong>，我们一开始就想一些办法，不要用fully connected network，而是用比较少的参数，来做图像处理这件事情，所以CNN其实是比一般的DNN还要更简单的。</p><hr><h2 id="卷积操作：以边缘检测举例"><a href="#卷积操作：以边缘检测举例" class="headerlink" title="卷积操作：以边缘检测举例"></a>卷积操作：以边缘检测举例</h2><p>（Edge Detection）</p><p>图片边缘检测的方式</p><ol><li>垂直边缘检测（Vertical edges）</li><li>水平边缘检测（Horizontal edges）</li></ol><p><img src="https://s2.loli.net/2022/12/07/ADTrBFMpjeycq4l.png"></p><p>边缘检测通过相应的滤波器（卷积核）卷积实现。</p><h3 id="【示例】垂直检测"><a href="#【示例】垂直检测" class="headerlink" title="【示例】垂直检测"></a>【示例】垂直检测</h3><p><img src="http://www.ai-start.com/dl2017/images/9aa008335e8a229d3818a61aaccc7173.png" alt="垂直检测1"></p><p><img src="https://img-blog.csdnimg.cn/2020042210323963.png#pic_center" alt="垂直检测2"></p><p>图片的边缘检测可以通过与相应滤波器进行卷积来实现。以垂直边缘检测为例，原始图片尺寸为6×6，滤波器filter尺寸为3×3，卷积后的图片尺寸为4×4</p><p>其中 *****代表卷积 上图只显示了卷积后的第一个值和最后一个值，其余值可自行计算。</p><h2 id="边缘检测补充"><a href="#边缘检测补充" class="headerlink" title="边缘检测补充"></a>边缘检测补充</h2><p>图像边缘有两种渐变方式，一种是由明变暗，另一种是由暗变明。以垂直边缘检测为例，下图展示了两种方式的区别。实际应用中，这两种渐变方式并不影响边缘检测结果，可以对输出图像取绝对值操作，得到同样的结果。</p><p><img src="https://img-blog.csdnimg.cn/20200422104421714.png#pic_center" alt="在这里插入图片描述"><br>下图展示一个水平边缘检测的例子：</p><p><img src="https://img-blog.csdnimg.cn/20200422104724389.png#pic_center" alt="在这里插入图片描述"></p><p>垂直边缘检测和水平边缘检测的滤波器<a href="https://so.csdn.net/so/search?q=%E7%AE%97%E5%AD%90&spm=1001.2101.3001.7020">算子</a>如下所示：</p><p><img src="https://img-blog.csdnimg.cn/20200422104617695.png#pic_center" alt="在这里插入图片描述"><br>除了上面提到的这种简单的Vertical、Horizontal滤波器之外，还有其它常用的filters，例如Sobel filter和Scharr filter。这两种滤波器的特点是增加图片中心区域的权重。（下图展示的是垂直边缘检测算子，水平边缘检测算子只需将上图顺时针翻转90度即可。）</p><p><img src="https://img-blog.csdnimg.cn/20200422105237527.png#pic_center" alt="在这里插入图片描述"><br>在深度学习中，如果我们想检测图像的各种边缘特征，而不仅限于垂直边缘和水平边缘，那么 filter 的数值一般需要通过模型训练得到，类似于标准神经网络中的权重 w ww 一样由反向传播算法迭代求得。CNN的主要目的就是计算出这些 filter 的数值。确定得到了这些 filter 后，CNN浅层网络也就实现了对图片所有边缘特征的检测。<br><img src="https://img-blog.csdnimg.cn/2020042210550658.png#pic_center" alt="在这里插入图片描述"></p><h2 id="Padding"><a href="#Padding" class="headerlink" title="Padding"></a>Padding</h2><p>按照我们上面讲的图片卷积，如果原始图片尺寸为 n × n，filter尺寸为 f × f，则卷积后的图片尺寸为 ( n − f + 1 ) × ( n − f + 1 ) ，注意 f 一般为奇数。这样会带来两个问题：</p><ol><li>卷积运算后，输出图片尺寸缩小</li><li>原始图片边缘信息对输出贡献得少，输出图片丢失边缘信息</li></ol><p>为了解决图片缩小的问题，可以 <strong>使用padding方法，即把原始图片尺寸进行扩展，扩展区域补零</strong>，用 p pp 来表示每个方向扩展的宽度。<br><img src="https://img-blog.csdnimg.cn/20200422110159369.png#pic_center" alt="在这里插入图片描述"><br>经过padding之后:</p><table><thead><tr><th>原始图像padding后尺寸</th><th>filter尺寸</th><th>卷积后的图像尺寸</th></tr></thead><tbody><tr><td>( n + 2 p ) × ( n + 2 p )</td><td>f × f</td><td>( n + 2 p − f + 1 ) × ( n + 2 p − f + 1 )</td></tr></tbody></table><p>稍作总结：</p><ul><li>无padding操作，p &#x3D; 0，我们称之为 <strong>Valid convolutions</strong> （不填充）</li><li>有padding操作，$\ p&#x3D;\frac{f-1}{2}$我们称之为 <strong>Same convolutions</strong> （填充，输入输出大小相等）</li></ul><hr><h2 id="卷积步长"><a href="#卷积步长" class="headerlink" title="卷积步长"></a>卷积步长</h2><p><img src="https://img-blog.csdnimg.cn/20200422111528803.png#pic_center" alt="卷积步长"></p><p>我们用s 表示stride长度，p 表示padding长度，如果原始图片尺寸为 n × n，filter（卷积核）尺寸为 f × f ，则卷积后的图片尺寸为：</p><p><img src="https://s2.loli.net/2022/12/07/HwfI68tMDunColL.png"></p><p>注：商不是整数的情况下，向下取整</p><h3 id="数学上卷积与人工智能卷积的区别："><a href="#数学上卷积与人工智能卷积的区别：" class="headerlink" title="数学上卷积与人工智能卷积的区别："></a>数学上卷积与人工智能卷积的区别：</h3><ul><li>数学意义上的卷积（<strong>convolutions</strong>））运算会先将filter绕其中心旋转180度，然后再将旋转后的filter在原始图片上进行滑动计算。filter旋转如下所示：<br><img src="https://img-blog.csdnimg.cn/20200422112729414.png#pic_center" alt="在这里插入图片描述"></li><li>人工智能意义上卷积：相关系数（<strong>cross-correlations</strong>）的计算过程则不会对filter进行旋转，而是直接在原始图片上进行滑动计算。</li></ul><p><strong>总的来说，忽略旋转运算可以大大提高CNN网络运算速度，而且不影响模型性能。</strong></p><p>注：卷积运算服从结合率不服从交换律</p><hr><h2 id="三维卷积"><a href="#三维卷积" class="headerlink" title="三维卷积"></a>三维卷积</h2><p>同二维卷积多了一个维度</p><ul><li><p>卷积核 channel（深度&#x2F;通道数）与输入特征层 的channel 相同</p></li><li><p>输出的特征矩阵channel与卷积核个数相同</p></li></ul><p>（Convolutions over volumes）</p><p>对于3通道的RGB图像，其对应的滤波器算子同样也是3通道的。例如一个图像是6 x 6 x 3，分别表示图像的高度（height）、宽度（weight）和通道（channel）。</p><p>3通道图像的卷积运算与单通道图像的卷积运算基本一致。过程是将每个单通道（R，G，B）与对应的filter进行卷积运算求和，然后再<strong>将3通道的和相加</strong>，得到输出图像的<strong>一个</strong>像素值。</p><p><img src="https://img-blog.csdnimg.cn/20200422113610810.png#pic_center" alt="在这里插入图片描述"><br>不同通道的滤波算子可以不相同。例如R通道filter实现垂直边缘检测，G和B通道不进行边缘检测，全部置零，或者将R，G，B三通道filter全部设置为水平边缘检测。</p><p>为了实现更多边缘检测，可以增加更多的滤波器组，进行多个卷积运算。例如设置第一个滤波器组实现垂直边缘检测，第二个滤波器组实现水平边缘检测。这样，不同滤波器组卷积得到不同的输出，个数由滤波器组决定。</p><p><img src="https://img-blog.csdnimg.cn/20200422113807669.png#pic_center" alt="在这里插入图片描述"></p><p><img src="https://s2.loli.net/2022/12/07/sBoEdSWhqKINkc4.png"></p><h2 id="单层卷积网络"><a href="#单层卷积网络" class="headerlink" title="单层卷积网络"></a>单层卷积网络</h2><p>卷积神经网络的单层结构如下所示：<br><img src="https://img-blog.csdnimg.cn/20200422151012841.png#pic_center" alt="卷积神经网络的单层结构如下所示："></p><p><img src="https://s2.loli.net/2022/12/07/BkVoKx69ZDuY8PF.png"></p><p>总结</p><p><img src="https://s2.loli.net/2022/12/07/tXxq1EfkgDBvYeT.png"></p>]]></content>
      
      
      <categories>
          
          <category> 学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 人工智能 </tag>
            
            <tag> CNN </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
